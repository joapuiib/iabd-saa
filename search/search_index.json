{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"SAA \u2013 Sistemes d'Aprenentatge Autom\u00e0tic","text":"<p>Benvinguts als apunts del M\u00f2dul Professional Sistemes d'Aprenentatge Autom\u00e0tic que pertany al Curs d'Especialitzaci\u00f3 IABD: Intel\u00b7lig\u00e8ncia Artificial i Big Data.</p> <p>En aquest lloc web podeu trobar:</p> <ul> <li>Programacions Did\u00e0ctiques del m\u00f2dul.</li> <li>Apunts de les diferents unitats del m\u00f2dul, aix\u00ed com els exercicis i pr\u00e0ctiques.</li> </ul>"},{"location":"apunts/","title":"Apunts","text":"<p>Aquest m\u00f2dul est\u00e0 dividit en les seg\u00fcents unitats did\u00e0ctiques:</p> <ul> <li>UD1: Introducci\u00f3 a la Intel\u00b7lig\u00e8ncia Artificial</li> <li>UD2: Estad\u00edstica</li> <li>UD3: Manipulaci\u00f3 i visualitzaci\u00f3 de dades</li> <li>UD4: Regressi\u00f3</li> <li>UD5: Preprocessament de dades</li> <li>UD6: Classificaci\u00f3</li> </ul>"},{"location":"apunts/01_introduccio/01_conceptes_generals/","title":"Introducci\u00f3 a la Intel\u00b7lig\u00e8ncia Artificial","text":"","tags":["aprenentatge autom\u00e0tic","aprenentatge supervisat","aprenentatge no supervisat","intel\u00b7lig\u00e8ncia artificial (IA)","IA feble","IA forta","machine learning (ML)","overfitting","underfitting"]},{"location":"apunts/01_introduccio/01_conceptes_generals/#que-es-la-intelligencia-artificial","title":"Qu\u00e8 \u00e9s la Intel\u00b7lig\u00e8ncia Artificial?","text":"<p>La Intel\u00b7lig\u00e8ncia Artificial (IA) consisteix en un programa inform\u00e0tic capa\u00e7 d'executar tasques i processos que tradicionalment requerien d'una intel\u00b7lig\u00e8ncia humana. En molts casos, aquests programes s\u00f3n capa\u00e7os de realitzar les tasques de forma m\u00e9s eficient i precisa que els humans.</p> <p>No obstant aix\u00f2, no tots el programes que realitzen tasques de manera eficient que els humans s\u00f3n considerats IA.</p> Autor desconegut Figura 1: Meme sobre la IA <p>Determinar si un ordinador realment es comporta de manera intel\u00b7ligent \u00e9s complex. Hi ha moltes definicions de qu\u00e8 \u00e9s exactament la IA. La m\u00e9s estesa \u00e9s la de John McCarthy (1995): </p> <p>Cita</p> <p>\u00c9s la ci\u00e8ncia i l'enginyeria de fer m\u00e0quines intel\u00b7ligents.</p> <p>Artificial Intelligence is the science and engineering of making intelligent machines.</p> <p>Hi ha molts programes que es comporten de manera intel\u00b7ligent, per\u00f2 hui en dia es dona molta import\u00e0ncia a les seg\u00fcents caracter\u00edstiques:</p> <ul> <li>Capacitat d'aprenentatge: Les m\u00e0quines poden aprendre i millorar el seu rendiment (semblant a com ho fem els humans).</li> <li>Autonomia: Les m\u00e0quines poden prendre decisions i realitzar tasques en entorns complexos sense la intervenci\u00f3 humana.</li> <li>Adaptabilitat: Les m\u00e0quines poden adaptar-se a nous entorns i situacions.</li> </ul>","tags":["aprenentatge autom\u00e0tic","aprenentatge supervisat","aprenentatge no supervisat","intel\u00b7lig\u00e8ncia artificial (IA)","IA feble","IA forta","machine learning (ML)","overfitting","underfitting"]},{"location":"apunts/01_introduccio/01_conceptes_generals/#exemples-dus-de-la-ia","title":"Exemples d'\u00fas de la IA","text":"<p>Alguns exemples d'\u00fas de la IA m\u00e9s estesos i fins i tot, quotidians s\u00f3n:</p> <ul> <li>Reconeixement de veu: utilitzat en assistents virtuals com Siri, Alexa o Google Assistant.</li> <li>Sistemes de recomanaci\u00f3: Sistemes de recomanaci\u00f3 que es basen en les prefer\u00e8ncies de l'usuari i el contingut consumit:<ul> <li>Spotify: recomana m\u00fasica basant-se en les can\u00e7ons que m\u00e9s escoltem.</li> <li>Serveis de distribuci\u00f3 audiovisual (Netflix, HBO, ...): recomana s\u00e8ries i pel\u00b7l\u00edcules basant-se en les que hem vist.</li> <li>Xarxes socials (Instagram, X, Facebook): recomanen contingut basant-se en les publicacions que m\u00e9s ens agraden (o fins i tot visualitzem!).</li> </ul> </li> <li>Processament d'imatges:<ul> <li>Aplicacions com Google Photos que permeten cercar imatges per contingut.</li> <li>Reconeixement facial (com en les c\u00e0meres dels m\u00f2bils).</li> <li>Sistemes de conducci\u00f3 aut\u00f2noma.</li> <li>Filtratge i classificaci\u00f3 d'imatges.</li> </ul> </li> <li>Sistemes de traducci\u00f3 autom\u00e0tica: com Google Translate o SoftCatal\u00e0.</li> </ul>","tags":["aprenentatge autom\u00e0tic","aprenentatge supervisat","aprenentatge no supervisat","intel\u00b7lig\u00e8ncia artificial (IA)","IA feble","IA forta","machine learning (ML)","overfitting","underfitting"]},{"location":"apunts/01_introduccio/01_conceptes_generals/#ia-feble-vs-ia-forta","title":"IA feble vs IA forta","text":"<p>Imagina't un robot o un ordinador que no sols puga fer tasques espec\u00edfiques, sin\u00f3 que tamb\u00e9 pense i entenga el m\u00f3n exactament com el fem nosaltres, els humans. Aix\u00f2 es coneix com intel\u00b7lig\u00e8ncia artificial forta(1), que a dia d'avui, sols existeix en la ci\u00e8ncia ficci\u00f3.</p> <ol> <li>Artificial General Intelligence (AGI)</li> </ol> <p>Aquesta \u00e9s la IA que veiem en pel\u00b7l\u00edcules com Ex Machina, Her, Blade Runner o llibres com Jo, Robot i altres d'Isaac Asimov. Aquest tipus de IA \u00e9s capa\u00e7 de realitzar qualsevol tasca que un \u00e9sser hum\u00e0 puga fer, entenent el m\u00f3n i prenent decisions de manera aut\u00f2noma.</p> Image via www.vpnsrus.com Figura 2: Intel\u00b7lig\u00e8ncia Artificial Forta <p>En canvi, la intel\u00b7lig\u00e8ncia artificial feble(1) \u00e9s el tipus de IA que coneixem avui en dia. Aquesta \u00e9s capa\u00e7 de realitzar tasques espec\u00edfiques de manera molt eficient, per\u00f2 no pot realitzar tasques per a les quals no ha estat dissenyada, \u00e9s a dir, estan orientades a un objectiu.</p> <ol> <li>Artificial Narrow Intelligence (ANI)</li> </ol> Huawei Figura 3: Comparaci\u00f3 entre IA feble i IA forta","tags":["aprenentatge autom\u00e0tic","aprenentatge supervisat","aprenentatge no supervisat","intel\u00b7lig\u00e8ncia artificial (IA)","IA feble","IA forta","machine learning (ML)","overfitting","underfitting"]},{"location":"apunts/01_introduccio/01_conceptes_generals/#classificacio-i-conceptes-relacionats","title":"Classificaci\u00f3 i conceptes relacionats","text":"VENN diagram of AI, Big Data and Data Science Fraunhofer FOKUS Figura 4: Relaci\u00f3 entre IA, Big Data i Data Science <ul> <li>Intel\u00b7lig\u00e8ncia Artificial (IA): \u00e9s la ci\u00e8ncia i l'enginyeria de fer m\u00e0quines intel\u00b7ligents.</li> <li>Aprenentatge Autom\u00e0tic (Machine Learning o ML): \u00e9s una branca de la IA que es basa     en la idea que les m\u00e0quines poden aprendre de les dades per si mateixes.</li> <li>Xarxes Neuronals (Neural Networks o NN): \u00e9s un model computacional inspirat en el cervell hum\u00e0     que es basa en la interconnexi\u00f3 de neurones artificials.</li> <li>Aprenentatge Profund (Deep Learning): \u00e9s una branca de l'aprenentatge autom\u00e0tic que es basa en xarxes neuronals     profundes (Deep Neural Networks o DNN).</li> </ul> <p>Altres conceptes relacionats s\u00f3n:</p> <ul> <li>Big Data: \u00e9s la disciplina que es basa en l'an\u00e0lisi de grans volums de dades, que poden ser utilitzats \u2014o no\u2014,     en sistemes d'IA.</li> <li>Data Science: \u00e9s la disciplina que es basa en l'an\u00e0lisi de dades per a obtenir coneixement i informaci\u00f3 \u00fatil.</li> </ul>","tags":["aprenentatge autom\u00e0tic","aprenentatge supervisat","aprenentatge no supervisat","intel\u00b7lig\u00e8ncia artificial (IA)","IA feble","IA forta","machine learning (ML)","overfitting","underfitting"]},{"location":"apunts/01_introduccio/01_conceptes_generals/#aprenentatge-automatic","title":"Aprenentatge Autom\u00e0tic","text":"<p>L'Aprenentatge Autom\u00e0tic (Machine Learning o ML) \u00e9s un camp de la IA que es basa en la idea que les m\u00e0quines poden aprendre de les dades per si mateixes, sense ser programades expl\u00edcitament per a realitzar una tasca concreta.</p>","tags":["aprenentatge autom\u00e0tic","aprenentatge supervisat","aprenentatge no supervisat","intel\u00b7lig\u00e8ncia artificial (IA)","IA feble","IA forta","machine learning (ML)","overfitting","underfitting"]},{"location":"apunts/01_introduccio/01_conceptes_generals/#aprenentatge-supervisat","title":"Aprenentatge Supervisat","text":"<p>L'Aprenentatge Supervisat (Supervised Learning o SL) \u00e9s un tipus de ML en el qual l'aprenentatge es basa en un conjunt de dades etiquetades, de les quals es coneix el resultat esperat.</p> Autor desconegut Figura 5: Aprenentatge Supervisat <p>Dins del SL, trobem dos principals tipus de problemes: classificaci\u00f3 i regressi\u00f3.</p> <p>Exemple</p> <p>En aquest example de classificaci\u00f3, el model ha segut entrenat amb imatges de gats, gossos i gallines, indicant-li al model l'animal (etiqueta) que apareix en cada imatge.</p> <p>El model apr\u00e9n a diferenciar entre aquests animals.</p> <p>Despr\u00e9s, el model pot ser utilitzat per a predir l'animal en una imatge que no ha vist abans.</p>","tags":["aprenentatge autom\u00e0tic","aprenentatge supervisat","aprenentatge no supervisat","intel\u00b7lig\u00e8ncia artificial (IA)","IA feble","IA forta","machine learning (ML)","overfitting","underfitting"]},{"location":"apunts/01_introduccio/01_conceptes_generals/#classificacio","title":"Classificaci\u00f3","text":"<p>En un problema de classificaci\u00f3, el model ha de predir a quina categoria o classe (valors discrets) pertany una observaci\u00f3 (imatge, text, etc.).</p> <p>Durant el proc\u00e9s d'entrenament, el model apr\u00e9n a diferenciar entre les diferents classes a partir de les dades d'entrenament i les etiquetes associades.</p> Autor desconegut Figura 6: Classificaci\u00f3 Autor desconegut Figura 7: Comparaci\u00f3 d'algorismes de classificaci\u00f3 <p>Alguns exemples de classificaci\u00f3 s\u00f3n:</p> <ul> <li>Correu no desitjat: classificar els correus electr\u00f2nics en spam o no spam.</li> <li>An\u00e0lisi de sentiments: classificar els textos en positius, negatius o neutres respecte a un tema.</li> <li>Classificaci\u00f3 d'imatges: classificar les imatges en diferents categories.<ul> <li>Imatge m\u00e8dica, reconeixement facial, conducci\u00f3 aut\u00f2noma, ...</li> </ul> </li> <li>Reconeixement de veu: classificar les paraules pronunciades en diferents categories.</li> </ul>","tags":["aprenentatge autom\u00e0tic","aprenentatge supervisat","aprenentatge no supervisat","intel\u00b7lig\u00e8ncia artificial (IA)","IA feble","IA forta","machine learning (ML)","overfitting","underfitting"]},{"location":"apunts/01_introduccio/01_conceptes_generals/#regressio","title":"Regressi\u00f3","text":"<p>En un problema de regressi\u00f3, el model ha de predir un valor num\u00e8ric (valors continus) a partir de les dades d'entrada.</p> <p>Durant el proc\u00e9s d'entrenament, el model apr\u00e9n a predir aquest valor num\u00e8ric a partir de les caracter\u00edstiques de les dades d'entrenament.G</p> Autor desconegut Figura 8: Regressi\u00f3 <p>Alguns exemples de regressi\u00f3 s\u00f3n:</p> <ul> <li>Preu d'una casa: predir el preu d'una casa a partir de les seves caracter\u00edstiques (m\u00b2, nombre d'habitacions, ...).</li> <li>Assegurances, cr\u00e8dits, hipoteques...: predir el risc associat a un client.</li> <li>Sistemes de recomanaci\u00f3: predir la puntuaci\u00f3 que un usuari donar\u00e0 a un producte o l'inter\u00e8s que tindr\u00e0 en ell.</li> </ul>","tags":["aprenentatge autom\u00e0tic","aprenentatge supervisat","aprenentatge no supervisat","intel\u00b7lig\u00e8ncia artificial (IA)","IA feble","IA forta","machine learning (ML)","overfitting","underfitting"]},{"location":"apunts/01_introduccio/01_conceptes_generals/#aprenentatge-no-supervisat","title":"Aprenentatge No Supervisat","text":"<p>D'un altre costat, l'Aprenentatge No Supervisat (Unsupervised Learning o UNS) \u00e9s un tipus de ML en el qual l'aprenentatge es basa en un conjunt de dades sense etiquetar, \u00e9s a dir, sense saber el resultat esperat.</p> Autor desconegut Figura 9: Aprenentatge No Supervisat <p>Dins de l'UNS, trobem dos principals tipus de problemes: clustering i reducci\u00f3 de la dimensionalitat.</p>","tags":["aprenentatge autom\u00e0tic","aprenentatge supervisat","aprenentatge no supervisat","intel\u00b7lig\u00e8ncia artificial (IA)","IA feble","IA forta","machine learning (ML)","overfitting","underfitting"]},{"location":"apunts/01_introduccio/01_conceptes_generals/#clustering","title":"Clustering","text":"<p>En un problema de clustering, el model ha de dividir les dades en diferents grups o cl\u00fasters, de manera que les observacions dins d'un mateix cl\u00faster siguin similars entre si.</p> <p>La Figure 9 mostra un exemple de clustering en el qual les dades s\u00f3n dividides tres cl\u00fasters.</p> <p>Alguns exemples de clustering s\u00f3n:</p> <ul> <li>Segmentaci\u00f3 de clients: agrupar els clients en diferents segments segons les seves caracter\u00edstiques.     Pot ser \u00fatil per a personalitzar ofertes, campanyes de m\u00e0rqueting o recomanaci\u00f3 de contingut.</li> </ul>","tags":["aprenentatge autom\u00e0tic","aprenentatge supervisat","aprenentatge no supervisat","intel\u00b7lig\u00e8ncia artificial (IA)","IA feble","IA forta","machine learning (ML)","overfitting","underfitting"]},{"location":"apunts/01_introduccio/01_conceptes_generals/#reduccio-de-la-dimensionalitat","title":"Reducci\u00f3 de la dimensionalitat","text":"<p>En un problema de reducci\u00f3 de la dimensionalitat, el model ha de reduir el nombre de dimensions (caracter\u00edstiques) de les dades, mantenint la informaci\u00f3 m\u00e9s rellevant.</p> <p>Aquest tipus de problema \u00e9s \u00fatil per a reduir el temps de c\u00e0lcul i millorar la precisi\u00f3 dels models.</p> Autor desconegut Figura 11: Reducci\u00f3 de la dimensionalitat <p>Alguns exemples de reducci\u00f3 de la dimensionalitat s\u00f3n:</p> <ul> <li>An\u00e0lisi de components principals (PCA): reduir el nombre de dimensions d'un conjunt de dades.</li> <li>Visualitzaci\u00f3 de dades: reduir les dades a un nombre menor de dimensions per a visualitzar-les en 2D o 3D.</li> <li>Reducci\u00f3 de soroll: eliminar les caracter\u00edstiques menys rellevants o redundants.</li> </ul>","tags":["aprenentatge autom\u00e0tic","aprenentatge supervisat","aprenentatge no supervisat","intel\u00b7lig\u00e8ncia artificial (IA)","IA feble","IA forta","machine learning (ML)","overfitting","underfitting"]},{"location":"apunts/01_introduccio/01_conceptes_generals/#aprenentatge-semisupervisat","title":"Aprenentatge semisupervisat","text":"<p>De vegades, tenim un conjunt de dades on sols algunes de les observacions estan etiquetades.</p> <p>En aquests casos, podem utilitzar l'Aprenentatge semisupervisat per a combinar les t\u00e8cniques de SL i UNS.</p> Autor desconegut Figura 12: Aprenentatge semisupervisat","tags":["aprenentatge autom\u00e0tic","aprenentatge supervisat","aprenentatge no supervisat","intel\u00b7lig\u00e8ncia artificial (IA)","IA feble","IA forta","machine learning (ML)","overfitting","underfitting"]},{"location":"apunts/01_introduccio/01_conceptes_generals/#aprenentatge-per-reforcament","title":"Aprenentatge per refor\u00e7ament","text":"<p>L'Aprenentatge per refor\u00e7ament (Reinforcement Learning o RL) \u00e9s un tipus de ML en el qual l'aprenentatge es basa en la interacci\u00f3 amb un entorn.</p> <p>En aquest tipus d'aprenentatge, un agent (robot, cotxe aut\u00f2nom, etc.) ha de prendre decisions per a maximitzar una recompensa a llarg termini. Quan l'agent pren una decisi\u00f3 correcta, rep una recompensa, i quan pren una decisi\u00f3 incorrecta, rep un c\u00e0stig.</p> Autor desconegut Figura 13: Aprenentatge per refor\u00e7ament","tags":["aprenentatge autom\u00e0tic","aprenentatge supervisat","aprenentatge no supervisat","intel\u00b7lig\u00e8ncia artificial (IA)","IA feble","IA forta","machine learning (ML)","overfitting","underfitting"]},{"location":"apunts/01_introduccio/01_conceptes_generals/#aprenentatge-per-lots","title":"Aprenentatge per lots","text":"<p>En l'Aprenentatge per lots (Batch Learning), el model \u00e9s entrenat amb un conjunt de dades fix.</p> <p>Si volem actualitzar el model amb noves dades, hem de tornar a entrenar-lo des de zero.</p> Autor desconegut Figura 14: Aprenentatge per lots","tags":["aprenentatge autom\u00e0tic","aprenentatge supervisat","aprenentatge no supervisat","intel\u00b7lig\u00e8ncia artificial (IA)","IA feble","IA forta","machine learning (ML)","overfitting","underfitting"]},{"location":"apunts/01_introduccio/01_conceptes_generals/#aprenentatge-en-linia","title":"Aprenentatge en l\u00ednia","text":"<p>En l'Aprenentatge en l\u00ednia (Online Learning), el model \u00e9s entrenat amb dades que arriben en temps real.</p> <p>Aquest tipus d'aprenentatge \u00e9s \u00fatil quan les dades s\u00f3n massa grans per a ser processades en mem\u00f2ria o quan les dades arriben de manera cont\u00ednua.</p> Autor desconegut Figura 15: Aprenentatge en l\u00ednia","tags":["aprenentatge autom\u00e0tic","aprenentatge supervisat","aprenentatge no supervisat","intel\u00b7lig\u00e8ncia artificial (IA)","IA feble","IA forta","machine learning (ML)","overfitting","underfitting"]},{"location":"apunts/01_introduccio/01_conceptes_generals/#aprenentatge-basat-en-models","title":"Aprenentatge basat en models","text":"<p>En l'Aprenentatge basat en models (Model-based Learning), existeix un model (normalment matem\u00e0tic/estad\u00edstic) que descriu com les dades s\u00f3n transformades en una predicci\u00f3.</p> <p>Aquest model \u00e9s entrenat amb les dades d'entrenament i despr\u00e9s utilitzat per a fer prediccions.</p> Autor desconegut Figura 16: Aprenentatge basat en models","tags":["aprenentatge autom\u00e0tic","aprenentatge supervisat","aprenentatge no supervisat","intel\u00b7lig\u00e8ncia artificial (IA)","IA feble","IA forta","machine learning (ML)","overfitting","underfitting"]},{"location":"apunts/01_introduccio/01_conceptes_generals/#aprenentatge-basat-en-instancies","title":"Aprenentatge basat en inst\u00e0ncies","text":"<p>En l'Aprenentatge basat en inst\u00e0ncies (Instance-based Learning), les prediccions es basen en la similitud entre les observacions d'entrenament i les noves observacions.</p> <p>Aquest tipus d'aprenentatge \u00e9s \u00fatil quan no es pot construir un model matem\u00e0tic/estad\u00edstic.</p> Autor desconegut Figura 17: Aprenentatge basat en inst\u00e0ncies","tags":["aprenentatge autom\u00e0tic","aprenentatge supervisat","aprenentatge no supervisat","intel\u00b7lig\u00e8ncia artificial (IA)","IA feble","IA forta","machine learning (ML)","overfitting","underfitting"]},{"location":"apunts/01_introduccio/01_conceptes_generals/#prova-i-validacio-de-models","title":"Prova i validaci\u00f3 de models","text":"<p>Una vegada s'ha entrenat un model, \u00e9s important avaluar la seva precisi\u00f3 i rendiment.</p> <p>Per a aix\u00f2, es divideixen les dades en dos conjunts: dades d'entrenament i dades de prova.</p> <ul> <li>Les dades d'entrenament s\u00f3n utilitzades per a entrenar el model.</li> <li>Les dades de prova s\u00f3n utilitzades per a avaluar el rendiment del model.</li> </ul> <p>Important</p> <p>\u00c9s molt important que les dades de prova no hagen segut utilitzades en el proc\u00e9s d'entrenament.</p> <p>Estem avaluant si el model generalitza b\u00e9 el problema o no, per tant, el model no ha de con\u00e9ixer les dades de prova.</p> <p>Info</p> <p>Normalment la proporci\u00f3 entre les dades d'entrenament i les dades de prova \u00e9s de 80%/20% o 70%/30%, respectivament.</p> <p>Cada tipus de problema t\u00e9 unes m\u00e8triques associades per a avaluar la qualitat del model.</p>","tags":["aprenentatge autom\u00e0tic","aprenentatge supervisat","aprenentatge no supervisat","intel\u00b7lig\u00e8ncia artificial (IA)","IA feble","IA forta","machine learning (ML)","overfitting","underfitting"]},{"location":"apunts/01_introduccio/01_conceptes_generals/#principals-problemes-de-laprenentatge-automatic","title":"Principals problemes de l'Aprenentatge Autom\u00e0tic","text":"<p>L'Aprenentatge Autom\u00e0tic \u00e9s una eina molt potent, per\u00f2 tamb\u00e9 dif\u00edcil d'utilitzar perqu\u00e8 siga eficient.</p> <p>Alguns dels principals problemes s\u00f3n:</p> <ul> <li>Quantitat insuficient de dades: per a entrenar un model amb precisi\u00f3, \u00e9s necessari un conjunt de dades gran     que represente correctament el problema.</li> <li>Dades de baixa qualitat: si les dades tenen errors, valors at\u00edpics i soroll, dif\u00edcilment el model     podr\u00e0 fer prediccions correctes.</li> <li> <p>Dades d'entrenament no representatives: per poder generalitzar correctament el problema, \u00e9s crucial     que les dades d'entrenament representen correctament el problema.</p> <p>Si utilitzem un conjunt de dades que no \u00e9s representatiu, el model no podr\u00e0 fer prediccions correctes i ens trobarem en un cas de mostra esbiaixada.</p> </li> </ul> <p>A m\u00e9s, \u00e9s important con\u00e9ixer els problemes que ens podem trobar en el proc\u00e9s d'entrenament:</p> <ul> <li> <p>Sobreajustament (Overfitting): el model s'ajusta massa b\u00e9 a les dades d'entrenament i no pot generalitzar     correctament el problema.</p> </li> <li> <p>Infraajustament (Underfitting): el model no s'ajusta prou b\u00e9 a les dades d'entrenament i no pot fer prediccions     correctes.</p> </li> </ul> Autor desconegut Figura 16: Sobreajustament i Infraajustament <p>Mesurant el rendiment del model amb les dades de prova, podem determinar si el model pateix d'aquests problemes:</p> <ul> <li>Si el model t\u00e9 un mal rendiment amb les dades d'entrenament i les dades de prova, probablement estiguem davant     un cas d'infraajustament.</li> <li>Si el model t\u00e9 un bon rendiment amb les dades d'entrenament i un mal rendiment amb les dades de prova, probablement     estiguem davant un cas de sobreajustament.</li> </ul> <p>El moment de parar l'entrenament del model \u00e9s quan aquest t\u00e9 un bon rendiment amb les dades d'entrenament i la validaci\u00f3 de les dades de prova comen\u00e7a a empitjorar.</p> Autor desconegut Figura 17: Validaci\u00f3 Sobreajustament i Infraajustament","tags":["aprenentatge autom\u00e0tic","aprenentatge supervisat","aprenentatge no supervisat","intel\u00b7lig\u00e8ncia artificial (IA)","IA feble","IA forta","machine learning (ML)","overfitting","underfitting"]},{"location":"apunts/01_introduccio/01_conceptes_generals/#recursos-addicionals","title":"Recursos addicionals","text":"<ul> <li>\u00bfQu\u00e9 es el Machine Learning? | DotCSV</li> <li>\u00bfQu\u00e9 es el Aprendizaje Supervisado y No Supervisado? | DotCSV</li> </ul>","tags":["aprenentatge autom\u00e0tic","aprenentatge supervisat","aprenentatge no supervisat","intel\u00b7lig\u00e8ncia artificial (IA)","IA feble","IA forta","machine learning (ML)","overfitting","underfitting"]},{"location":"apunts/01_introduccio/01_conceptes_generals/#bibliografia","title":"Bibliografia","text":"<ul> <li>Material del m\u00f2dul \"Sistemes d'Aprenentatge Autom\u00e0tic\" de C\u00e9sar Guijarro Rosaleny</li> <li>Material del curs \"Iniciaci\u00f3 a la Intel\u00b7lig\u00e8ncia Artificial amb Python\" impartit per David Campoy Mi\u00f1arro</li> <li>Artificial general intelligence, Wikipedia</li> <li>Weak artificial intelligence, Wikipedia</li> <li>Aprenentatge Autom\u00e0tic, Viquip\u00e8dia</li> <li>Supervised learning, Wikipedia</li> <li>Unsupervised learning, Wikipedia</li> <li>Reinforcement learning, Wikipedia</li> <li>Online machine learning, Wikipedia</li> <li>Mostra esbiaixada, Viquip\u00e8dia</li> </ul>","tags":["aprenentatge autom\u00e0tic","aprenentatge supervisat","aprenentatge no supervisat","intel\u00b7lig\u00e8ncia artificial (IA)","IA feble","IA forta","machine learning (ML)","overfitting","underfitting"]},{"location":"apunts/01_introduccio/02_xarxes_neuronals/","title":"Xarxes neuronals","text":"","tags":["xarxes neuronals","neural networks (NN)","aprenentatge profund","deep learning","deep neural networks (DNN)","backpropagation","perceptr\u00f3","xarxes neuronals convolucionals (CNN)","xarxes neuronals recurrents (RNN)"]},{"location":"apunts/01_introduccio/02_xarxes_neuronals/#xarxes-neuronals","title":"Xarxes Neuronals","text":"<p>Les xarxes neuronals (neural networks o NN) s\u00f3n un model computacional inspirat en el funcionament del cervell dels organismes vius: un conjunt de neurones interconnectades entre s\u00ed, que s'activen quan reben un est\u00edmul i treballen col\u00b7lectivament per resoldre un problema.</p> <p>Aquest model ha revolucionat el camp del Aprenentatge Autom\u00e0tica (ML) en els \u00faltims anys.</p>","tags":["xarxes neuronals","neural networks (NN)","aprenentatge profund","deep learning","deep neural networks (DNN)","backpropagation","perceptr\u00f3","xarxes neuronals convolucionals (CNN)","xarxes neuronals recurrents (RNN)"]},{"location":"apunts/01_introduccio/02_xarxes_neuronals/#perceptro","title":"Perceptr\u00f3","text":"<p>Les xarxes neuronals estan compostes per neurones artificials, que s\u00f3n l'element b\u00e0sic d'aquest model. La neurona artificial esta inspirada en la neurona natural, que \u00e9s la c\u00e8l\u00b7lula b\u00e0sica del cervell dels animals.</p> <p></p> <p>Mauro Lanari, Wikimedia Commons</p> <p>Figura 1. Neurona natural</p> <p>La neurona artificial, tamb\u00e9 anomenada perceptr\u00f3, \u00e9s la unitat b\u00e0sica d'una xarxa neuronal. Aquesta rep un conjunt d'entrades (inputs), que s\u00f3n ponderades per uns pesos (weights) i sumades amb un biaix (sesgo o bias).</p> <p>L'eixida (output) de la neurona es calcula aplicant una funci\u00f3 d'activaci\u00f3 a la suma ponderada de les entrades.</p> <p></p> <p>Autor desconegut</p> <p>Figura 2. Perceptr\u00f3</p> <p>L'eixida d'un perceptr\u00f3 es linear respecte a les entrades, per tant, no podria resoldre problemes no lineals. Per evitar aquesta limitaci\u00f3, s'han afegit les funcions d'activaci\u00f3, que permeten a les xarxes neuronals resoldre problemes m\u00e9s complexos.</p> <p>Les funcions d'activaci\u00f3 s\u00f3n funcions no lineals que s'apliquen a abans de l'eixida de la neurona.</p> <p></p> <p>Autor desconegut</p> <p>Figura 3. Funcions d'activaci\u00f3</p> <p>Nota</p> <p>Existeixes moltes funcions d'activaci\u00f3, que caldr\u00e0 seleccionar segons el problema a resoldre.</p>","tags":["xarxes neuronals","neural networks (NN)","aprenentatge profund","deep learning","deep neural networks (DNN)","backpropagation","perceptr\u00f3","xarxes neuronals convolucionals (CNN)","xarxes neuronals recurrents (RNN)"]},{"location":"apunts/01_introduccio/02_xarxes_neuronals/#xarxes-neuronals-profundes-dnn","title":"Xarxes neuronals profundes (DNN)","text":"<p>Les xarxes neuronals profundes (Deep Neural Networks o DNN) s\u00f3n un tipus de xarxes neuronals, en les quals es connecten m\u00faltiples capes de neurones entre s\u00ed.</p> <p>Aquesta estructura permet modelar relacions m\u00e9s complexes entre les dades, i per tant, resoldre problemes m\u00e9s complicats.</p> <p>Nota</p> <p>Realment, el que defineix el DNN no \u00e9s el nombre de capes, sin\u00f3 el processament de les dades de manera jer\u00e0rquica. Cada capa extrau caracter\u00edstiques m\u00e9s abstractes de les dades que la capa anterior arribant a la resposta final.</p> <p></p> <p>https://wwww.quantamagazine.org</p> <p>Figura 4. Proc\u00e9s d'una xarxa neuronal profunda</p> <p>La primera capa s'anomena capa d'entrada, que tindr\u00e0 tantes neurones com entrades tinguen les nostres dades.</p> <p>Exemple</p> <p>Si volem predir el preu d'una casa, les entrades podrien ser:</p> <ul> <li>Metres quadrats</li> <li>Nombre de dormitoris</li> <li>Nombre de banys</li> <li>Barri</li> </ul> <p>En aquest cas, la capa d'entrada tindria 4 neurones.</p> <p>De la mateixa manera, l'\u00faltima capa s'anomena capa d'eixida, que tindr\u00e0 tantes neurones com resultats esperem obtindre.</p> <p>Exemple</p> <p>En el problema anterior, l'eixida que esperem \u00e9s el preu de la casa.</p> <p>Per tant, la capa d'eixida tindria una sola neurona.</p> <p>Les capes interm\u00e8dies s'anomenen capa ocultes que estan connectades entre s\u00ed, de manera que l'eixida d'una capa \u00e9s l'entrada de la seg\u00fcent. El nombre de neurones en aquestes capes dep\u00e8n del problema a resoldre.</p> <p></p> <p>Autor desconegut</p> <p>Figura 5. Xarxa neuronal profunda</p>","tags":["xarxes neuronals","neural networks (NN)","aprenentatge profund","deep learning","deep neural networks (DNN)","backpropagation","perceptr\u00f3","xarxes neuronals convolucionals (CNN)","xarxes neuronals recurrents (RNN)"]},{"location":"apunts/01_introduccio/02_xarxes_neuronals/#retropropagacio-backpropagation","title":"Retropropagaci\u00f3 (backpropagation)","text":"<p>La retropropagaci\u00f3 (backpropagation) \u00e9s un algoritme d'aprenentatge supervisat que s'utilitza per entrenar xarxes neuronals.</p> <p>Aquest algoritme ajusta els pesos de les connexions entre les neurones per minimitzar l'error entre l'eixida de la xarxa i l'eixida esperada.</p> <p>El funcionament \u00e9s el seg\u00fcent:</p> <ul> <li>S'envia un conjunt de dades a la xarxa, i es calcula l'eixida de la xarxa.</li> <li>Es compara l'eixida de la xarxa amb l'eixida esperada, i es calcula l'error.</li> <li>L'error es propaga cap enrere a trav\u00e9s de la xarxa, ajustant els pesos de les connexions.</li> </ul> <p></p> <p>Autor desconegut</p> <p>Figura 6. Retropropagaci\u00f3</p> <p>Aquest proc\u00e9s es repeteix moltes vegades de manera iterativa, reduint l'error de la xarxa fins a arribar a un valor acceptable.</p> <p>Nota</p> <p>La retropropagaci\u00f3 \u00e9s un algoritme computacionalment intensiu, i requereix una gran quantitat de dades per a ser efectiu.</p>","tags":["xarxes neuronals","neural networks (NN)","aprenentatge profund","deep learning","deep neural networks (DNN)","backpropagation","perceptr\u00f3","xarxes neuronals convolucionals (CNN)","xarxes neuronals recurrents (RNN)"]},{"location":"apunts/01_introduccio/02_xarxes_neuronals/#tipus-de-xarxes-neuronals","title":"Tipus de xarxes neuronals","text":"<p>Hi ha molts tipus de xarxes neuronals, cadascuna dissenyada per a resoldre un tipus de problema concret.</p>","tags":["xarxes neuronals","neural networks (NN)","aprenentatge profund","deep learning","deep neural networks (DNN)","backpropagation","perceptr\u00f3","xarxes neuronals convolucionals (CNN)","xarxes neuronals recurrents (RNN)"]},{"location":"apunts/01_introduccio/02_xarxes_neuronals/#xarxes-neuronals-convolucionals-cnn","title":"Xarxes neuronals convolucionals (CNN)","text":"<p>Les xarxes neuronals convolucionals (Convolutional Neural Networks o CNN) s\u00f3n un tipus de xarxes neuronals especialment dissenyades per a processar imatges.</p> <p>Les primeres capes d'una CNN s\u00f3n capes de convoluci\u00f3, que apliquen s'encarreguen d'extraure caracter\u00edstiques de xicotetes regions de la imatge (lines, curves, textures, etc.).</p> <p></p> <p>Autor desconegut</p> <p>Figura 7. Xarxa neuronal convolucional</p>","tags":["xarxes neuronals","neural networks (NN)","aprenentatge profund","deep learning","deep neural networks (DNN)","backpropagation","perceptr\u00f3","xarxes neuronals convolucionals (CNN)","xarxes neuronals recurrents (RNN)"]},{"location":"apunts/01_introduccio/02_xarxes_neuronals/#xarxes-neuronals-recurrents-rnn","title":"Xarxes neuronals recurrents (RNN)","text":"<p>Les xarxes neuronals recurrents (Recurrent Neural Networks o RNN) s\u00f3n un tipus de xarxes neuronals dissenyades per a processar seq\u00fc\u00e8ncies de dades, com textos, temps, etc.</p> <p>Aquest tipus de xarxes tenen connexions c\u00edcliques entre les neurones, de manera que l'eixida de la xarxa pot ser utilitzada com a entrada en la seg\u00fcent iteraci\u00f3.</p> <p></p> <p>Autor desconegut</p> <p>Figura 8. Xarxa neuronal recurrent</p>","tags":["xarxes neuronals","neural networks (NN)","aprenentatge profund","deep learning","deep neural networks (DNN)","backpropagation","perceptr\u00f3","xarxes neuronals convolucionals (CNN)","xarxes neuronals recurrents (RNN)"]},{"location":"apunts/01_introduccio/02_xarxes_neuronals/#xarxes-neuronals-generatives-adversaries-gan","title":"Xarxes neuronals generatives advers\u00e0ries (GAN)","text":"<p>Les xarxes neuronals generatives advers\u00e0ries (Generative Adversarial Networks o GAN) s\u00f3n un tipus de xarxes neuronals dissenyades per a generar dades noves a partir de dades existents.</p> <p>Aquest tipus de xarxes estan compostes per dues xarxes neuronals:</p> <ul> <li>Generador: Aquesta xarxa genera dades noves a partir de dades existents.</li> <li>Discriminador: Aquesta xarxa intenta distingir entre les dades reals     i les dades generades pel generador.</li> </ul> <p>La tasca del generador \u00e9s enganyar el discriminador, i la tasca del discriminador \u00e9s diferenciar entre les dades reals i les dades generades.</p> <p>Quan el discriminador descarta les dades generades pel generador, aquest apr\u00e9n de l'error i millora la seua capacitat per a generar dades noves.</p> <p>En canvi, quan el discriminador no pot distingir entre les dades reals i les dades generades, el discriminador apr\u00e9n de l'error i millora la seua capacitat per a distingir entre les dades reals i les dades generades.</p> <p></p> <p>Autor desconegut</p> <p>Figura 9. Xarxa neuronal generativa advers\u00e0ria</p>","tags":["xarxes neuronals","neural networks (NN)","aprenentatge profund","deep learning","deep neural networks (DNN)","backpropagation","perceptr\u00f3","xarxes neuronals convolucionals (CNN)","xarxes neuronals recurrents (RNN)"]},{"location":"apunts/01_introduccio/02_xarxes_neuronals/#recursos-addicionals","title":"Recursos addicionals","text":"<ul> <li>\u00bfQu\u00e9 es una Red Neuronal? Parte 1 : La Neurona | DotCSV</li> <li>\u00bfQu\u00e9 es una Red Neuronal? Parte 2 : La Red | DotCSV</li> <li>Jugando con Redes Neuronales - Parte 2.5 | DotCSV</li> <li>\u00bfQu\u00e9 es una Red Neuronal? Parte 3 : Backpropagation | DotCSV</li> <li>A Friendly Introduction to Generative Adversarial Networks (GANs)</li> </ul>","tags":["xarxes neuronals","neural networks (NN)","aprenentatge profund","deep learning","deep neural networks (DNN)","backpropagation","perceptr\u00f3","xarxes neuronals convolucionals (CNN)","xarxes neuronals recurrents (RNN)"]},{"location":"apunts/01_introduccio/02_xarxes_neuronals/#bibliografia","title":"Bibliografia","text":"<ul> <li>Material del m\u00f2dul \"Sistemes d'Aprenentatge Autom\u00e0tic\" de C\u00e9sar Guijarro Rosaleny</li> <li>Retropropagaci\u00f3, Wikipedia: https://ca.wikipedia.org/wiki/Retropropagaci%C3%B3</li> </ul>","tags":["xarxes neuronals","neural networks (NN)","aprenentatge profund","deep learning","deep neural networks (DNN)","backpropagation","perceptr\u00f3","xarxes neuronals convolucionals (CNN)","xarxes neuronals recurrents (RNN)"]},{"location":"apunts/02_estadistica/00_preparacio_entorn/","title":"Preparaci\u00f3 de l'entorn","text":"","tags":["python","PyCharm"]},{"location":"apunts/02_estadistica/00_preparacio_entorn/#objectius","title":"Objectius","text":"<p>L'objectiu d'aquest material \u00e9s configurar l'entorn de desenvolupament en ordinadors amb sistema operatiu Windows o distribucions de Linux basades en Debian, com Ubuntu o Linux Mint.</p> <p>En aquest manual s'instal\u00b7lar\u00e0 i es configuraran les seg\u00fcent eines:</p> <ul> <li>Python 3: Llenguatge de programaci\u00f3.</li> <li>PyCharm: Entorn de desenvolupament integrat.</li> </ul> <p>Info</p> <p>Podeu utilitzar l'entorn de desenvolupament que vulgueu, per\u00f2 heu de saber configurar-lo per a Python 3.</p> <p>El professorat no donar\u00e0 suport a altres entorns de desenvolupament.</p>","tags":["python","PyCharm"]},{"location":"apunts/02_estadistica/00_preparacio_entorn/#python-3","title":"Python 3","text":"<p>Python 3 est\u00e0 disponible a https://www.python.org/ per a Windows, macOS i Linux.</p> <p>A Linux, Python 3 ja ve instal\u00b7lat per defecte a pr\u00e0cticament totes les distribucions.</p>","tags":["python","PyCharm"]},{"location":"apunts/02_estadistica/00_preparacio_entorn/#pycharm","title":"PyCharm","text":"<p>PyCharm est\u00e0 disponible a https://www.jetbrains.com/pycharm/ per a Windows, macOS i Linux.</p> <p>Cal descarregar la versi\u00f3 Community, que \u00e9s de codi obert i gratu\u00efta.</p>","tags":["python","PyCharm"]},{"location":"apunts/02_estadistica/00_preparacio_entorn/#creacio-de-projecte","title":"Creaci\u00f3 de projecte","text":"<p>Per a comen\u00e7ar a treballar, heu de crear un projecte a PyCharm.</p> <p>Jo he triat les seg\u00fcents opcions:</p> <ul> <li>Project type: Pure Python</li> <li>Nome del projecte: <code>CognomNom-SAA</code></li> <li>Location: Per defecte.</li> <li>Interpreter: Python 3.12</li> <li>Interpreter type: Virtualenv</li> <li>Create Git repository: S\u00ed</li> </ul> <p>Important</p> <p>S'utilitzara un entorn virtual per a a\u00efllar les depend\u00e8ncies del projecte respecte de les del sistema.</p> <p>Consell</p> <p>Vos recomane crear un repositori de  Git per gestionar el vostre codi.</p> <p></p>","tags":["python","PyCharm"]},{"location":"apunts/02_estadistica/00_preparacio_entorn/#installacio-de-dependencies","title":"Instal\u00b7laci\u00f3 de depend\u00e8ncies","text":"<p>En aquest m\u00f2dul farem servir les llibreries especificades al fitxer <code>requirements.txt</code>, que haur\u00e0s de situar a l'arrel del projecte.</p> requirements.txt<pre><code>\n</code></pre> <p>Consell</p> <p>En el meu cas, s'ha situat a <code>PuigcerverJoan-SAA/requirements.txt</code>.</p> <p>Per instal\u00b7lar les depend\u00e8ncies, obriu un terminal a PyCharm i executeu la seg\u00fcent comanda:</p> <pre><code>(.venv) jpuigcerver@fedora:~/PuigcerverJoan-SAA (main) $ pip install -r requirements.txt\n</code></pre> <p>Fixa't</p> <p>Fixeu-vos que el entorn virtual est\u00e0 activat: <code>(.venv)</code>.</p> <p>Si no ho est\u00e0, el podeu activar amb la seg\u00fcent comanda:</p> <pre><code>jpuigcerver@fedora:~/PuigcerverJoan-SAA (main) $ source .venv/bin/activate\n</code></pre>","tags":["python","PyCharm"]},{"location":"apunts/02_estadistica/00_preparacio_entorn/#execucio-de-codi","title":"Execuci\u00f3 de codi","text":"<p>En Python, el codi est\u00e0 estructurat en m\u00f2duls, que s\u00f3n directoris amb un fitxer <code>__init__.py</code>. Podeu crear un m\u00f2dul amb Bot\u00f3 dret &gt; New &gt; Python Package.</p> <ul> <li>Crea el m\u00f2dul <code>ud2</code>.</li> </ul> <p>Despr\u00e9s, c\u00f2pia l'exemple <code>exemple_python.py</code> a aquest m\u00f2dul.</p> <pre><code>#!/usr/bin/env python\n\n# Python Basics Example Script\n\n# 1. Variables and Data Types\n# ----------------------------\n\n# Integer\nage = 25\n# Float\nheight = 5.9\n# String\nname = \"Alice\"\n# Boolean\nis_student = True\n\nprint(f\"My name is {name}, I am {age} years old, {height} feet tall, and it is {is_student} that I am a student.\")\n\n# 2. Conditional Statements (if-elif-else)\n# ----------------------------------------\n\nif age &lt; 18:\n    print(\"You are a minor.\")\nelif age &lt; 65:\n    print(\"You are an adult.\")\nelse:\n    print(\"You are a senior.\")\n\n# 3. Loops (for, while)\n# ----------------------\n\n# for loop example\nprint(\"\\nFor loop example:\")\nfor i in range(5):  # Will loop from 0 to 4\n    print(f\"Iteration {i}\")\n\n# while loop example\nprint(\"\\nWhile loop example:\")\ncount = 0\nwhile count &lt; 3:\n    print(f\"Count is {count}\")\n    count += 1\n\n# 4. Functions\n# -------------\n\ndef greet(name, is_morning=True):\n    \"\"\"Function to greet a person based on the time of day.\"\"\"\n    if is_morning:\n        return f\"Good morning, {name}!\"\n    else:\n        return f\"Hello, {name}!\"\n\nprint(\"\\nFunction example:\")\nprint(greet(\"Alice\"))\nprint(greet(\"Bob\", False))\n\n# 5. Lists and Dictionaries\n# ---------------------------\n\n# List of numbers\nnumbers = [10, 20, 30, 40, 50]\n\n# Dictionary representing a person\nperson = {\n    \"name\": \"John\",\n    \"age\": 30,\n    \"is_student\": False\n}\n\n# Accessing list and dictionary elements\nprint(\"\\nList and Dictionary example:\")\nprint(f\"The first number in the list is {numbers[0]}\")\nprint(f\"The person's name is {person['name']} and they are {person['age']} years old.\")\n\n# 6. Classes and Objects\n# -----------------------\n\nclass Dog:\n    \"\"\"A simple class representing a dog.\"\"\"\n\n    def __init__(self, name, breed):\n        self.name = name\n        self.breed = breed\n\n    def bark(self):\n        return f\"{self.name} says Woof!\"\n\n# Creating an instance (object) of the Dog class\nmy_dog = Dog(\"Buddy\", \"Golden Retriever\")\n\nprint(\"\\nClass and Object example:\")\nprint(f\"My dog's name is {my_dog.name} and he is a {my_dog.breed}.\")\nprint(my_dog.bark())\n</code></pre> <p>Tracta d'executar el codi amb   Run. Comprova la consola per veure si s'ha executat correctament.</p>","tags":["python","PyCharm"]},{"location":"apunts/02_estadistica/01_estadistica_basica/","title":"Estad\u00edstica b\u00e0sica","text":""},{"location":"apunts/02_estadistica/01_estadistica_basica/#estadistica-basica","title":"Estad\u00edstica b\u00e0sica","text":"<p>L'aprenentatge autom\u00e0tic est\u00e0 basat en models matem\u00e0tics i estad\u00edstics. Per aix\u00f2, \u00e9s important tindre una base s\u00f2lida en estad\u00edstica per entendre el funcionament dels algoritmes d'aprenentatge autom\u00e0tic i analitzar els resultats obtinguts.</p> <p>L'estad\u00edstica \u00e9s una disciplina que estudia la recopilaci\u00f3, an\u00e0lisi i interpretaci\u00f3 de dades.</p> <p>En aquests apunts veurem operacions b\u00e0siques com la mitjana, la mediana, la moda, la desviaci\u00f3 est\u00e0ndard i la vari\u00e0ncia.</p>"},{"location":"apunts/02_estadistica/01_estadistica_basica/#mitjana-aritmetica-barx","title":"Mitjana aritm\u00e8tica (\\(\\bar{X}\\))","text":"<p>La mitjana aritm\u00e8tica \u00e9s el valor obtingut en sumar tots els valors d'una mostra i dividir-los pel nombre total de valors.</p> \\[ \\bar{X} = \\frac{1}{N} \\sum_{i=1}^{N} x_i \\] <p>Exemple</p> <p>Donades les edats d'un grup de persones \\(X = \\{ 20, 20, 50, 60, 80 \\}\\), la mitjana aritm\u00e8tica \u00e9s:</p> \\[ \\bar{X} = \\frac{1}{5} (20 + 20 + 50 + 60 + 80) = 46 \\] <p>Exemple amb Pandas</p> <pre><code>import pandas as pd\n\ndf = pd.DataFrame({\"A\":[12,  4,  5, 44,  1],\n                   \"B\":[ 5,  2, 54,  3,  2],\n                   \"C\":[20, 16,  7,  3,  8],\n                   \"D\":[14,  3, 14,  3, 14]})\n\nprint(\"DataFrame:\")\nprint(df)\n\n# axis = 0 calcular\u00e1 la mitjana de cada columna (A, B, C, D)\ncolumn_mean = df.mean(axis = 0)\nprint(\"Mitjana de cada columna:\")\nprint(column_mean)\n\n# axis = 1 calcular\u00e1 la mitjana de cada fila (0, 1, 2, 3, 4)\nrow_mean = df.mean(axis = 1)\nprint(\"Mitjana de cada fila:\")\nprint(row_mean)\n</code></pre> <pre><code>DataFrame:\n    A   B   C   D\n0  12   5  20  14\n1   4   2  16   3\n2   5  54   7  17\n3  44   3   3   2\n4   1   2   8   6\nMitjana de cada columna:\nA    13.2\nB    13.2\nC    10.8\nD    10.2\ndtype: float64\nMitjana de cada fila:\n0    12.75\n1     6.25\n2    20.75\n3    13.00\n4     6.25\ndtype: float64\n</code></pre> <p>Exemple mitjana d'una fila</p> <p>Amb l'anterior <code>DataFrame</code>, podem utilitzar la funci\u00f3 <code>iloc</code> per seleccionar una fila i calcular la mitjana dels seus valors.</p> <pre><code>mean = df.iloc[0].mean()\nprint(\"Mitjana de la primera fila:\")\nprint(mean)\n</code></pre> <pre><code>Mitjana de la primera fila:\n12.75\n</code></pre> <p>Exemple mitjana d'una columna</p> <p>De la mateixa manera, podem calcular la mitjana d'una columna.</p> <pre><code>mean = df.loc[:,\"A\"].mean()\nprint(\"Mitjana de la columna A:\")\nprint(mean)\n</code></pre> <pre><code>Mitjana de la columna A:\n13.2\n</code></pre>"},{"location":"apunts/02_estadistica/01_estadistica_basica/#mediana-tildex","title":"Mediana (\\(\\tilde{X}\\))","text":"<p>La mediana \u00e9s el valor que divideix la mostra en dues parts iguals, \u00e9s a dir, la meitat dels valors s\u00f3n m\u00e9s grans que la mediana i l'altra meitat s\u00f3n m\u00e9s xicotets.</p> <p>Per a calcular la mediana, primer s'ordenen els valors de la mostra de menor a major i es tria el valor central.</p> <ul> <li>Si la mostra t\u00e9 un nombre imparell de valors, la mediana \u00e9s el valor central.</li> <li>Si la mostra t\u00e9 un nombre parell de valors, la mediana \u00e9s la mitjana aritm\u00e8tica dels dos valors centrals.</li> </ul> <p>Exemple</p> <p>Donades les edats d'un grup de persones \\(X = \\{ 20, 20, 50, 60, 80 \\}\\), la mediana \u00e9s:</p> \\[ \\tilde{X} = 50 \\] <p>Exemple amb Pandas</p> <pre><code>median = df.median()\nprint(\"Mediana de cada columna:\")\nprint(median)\n</code></pre> <pre><code>Mediana de cada columna:\nA     5.0\nB     3.0\nC     8.0\nD    14.0\ndtype: float64\n</code></pre>"},{"location":"apunts/02_estadistica/01_estadistica_basica/#moda","title":"Moda","text":"<p>La moda \u00e9s el valor que m\u00e9s vegades apareix en una mostra.</p> <p>Exemple</p> <p>Donades les edats d'un grup de persones \\(X = \\{ 20, 20, 50, 60, 80 \\}\\), la moda \u00e9s:</p> \\[ \\text{moda}(X) = 20 \\] <p>Nota</p> <p>El m\u00e8tode <code>mode()</code> de Pandas retorna la moda de cada columna.</p> <p>Si hi ha m\u00e9s d'una moda, el m\u00e8tode retorna totes les modes.</p> <p>Exemple amb Pandas</p> <pre><code>mode = df.mode()\nprint(\"Moda de cada columna:\")\nprint(mode)\n</code></pre> <pre><code>Moda de cada columna:\n    A    B   C     D\n0   1  2.0   3   3.0\n1   4  NaN   7  14.0\n2   5  NaN   8   NaN\n3  12  NaN  16   NaN\n4  44  NaN  20   NaN\n</code></pre>"},{"location":"apunts/02_estadistica/01_estadistica_basica/#variancia-sigma2","title":"Vari\u00e0ncia (\\(\\sigma^2\\))","text":"<p>La vari\u00e0ncia \u00e9s una mesura de la dispersi\u00f3 dels valors d'una mostra respecte a la mitjana.</p> <p>Es calcula com la mitjana dels quadrats de les difer\u00e8ncies entre cada valor i la mitjana.</p> \\[ \\sigma^2 = \\frac{1}{N} \\sum_{i=1}^{N} (x_i - \\bar{X})^2 \\] <p>Nota</p> <p>Les difer\u00e8ncies s\u00f3n elevades al quadrat per a que siguen sempre positives.</p> <p>Exemple</p> <p>Donades les edats d'un grup de persones \\(X = \\{ 20, 20, 50, 60, 80 \\}\\), la vari\u00e0ncia \u00e9s:</p> \\[ \\sigma^2 = \\frac{1}{5} ((20-46)^2 + (20-46)^2 + (50-46)^2 + (60-46)^2 + (80-46)^2) \\\\ \\sigma^2 = \\frac{1}{5} (676 + 676 + 16 + 196 + 1156) \\\\ \\sigma^2 = \\frac{2720}{5} = 544 \\] <p>Exemple amb Pandas</p> <pre><code>variance = df.var()\nprint(\"Vari\u00e0ncia de cada columna:\")\nprint(variance)\n</code></pre> <pre><code>Vari\u00e0ncia de cada columna:\nA    312.7\nB    521.7\nC     48.7\nD     44.7\ndtype: float64\n</code></pre>"},{"location":"apunts/02_estadistica/01_estadistica_basica/#desviacio-estandard-sigma","title":"Desviaci\u00f3 est\u00e0ndard (\\(\\sigma\\))","text":"<p>La desviaci\u00f3 est\u00e0ndard \u00e9s la arrel quadrada de la vari\u00e0ncia. Mesura la dispersi\u00f3 dels valors respecte a la mitjana, per\u00f2 indica la dispersi\u00f3 en les mateixes unitats que els valors.</p> \\[ \\sigma = \\sqrt{\\sigma^2} = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (x_i - \\bar{X})^2} \\] <p>Exemple</p> <p>Donades les edats d'un grup de persones \\(X = \\{ 20, 20, 50, 60, 80 \\}\\), la desviaci\u00f3 est\u00e0ndard \u00e9s:</p> \\[ \\sigma = \\sqrt{544} = 23.32 \\] <p>Exemple amb Pandas</p> <pre><code>std = df.std()\nprint(\"Desviaci\u00f3 est\u00e0ndard de cada columna:\")\nprint(std)\n</code></pre> <pre><code>Desviaci\u00f3 est\u00e0ndard de cada columna:\nA    17.683325\nB    22.840753\nC     6.978539\nD     6.685806\ndtype: float64\n</code></pre>"},{"location":"apunts/02_estadistica/01_estadistica_basica/#quantils","title":"Quantils","text":"<p>Els quantils s\u00f3n mesures de posici\u00f3 que divideixen una mostra de manera que una proporci\u00f3 determinada de valors queda a cada costat del quantil.</p> <p>Els quantils m\u00e9s importants s\u00f3n els quartils, decils i percentils.</p>"},{"location":"apunts/02_estadistica/01_estadistica_basica/#percentils","title":"Percentils","text":"<p>Els percentils divideixen la mostra en cent parts iguals, cadascuna amb el 1% dels valors.</p> <p>\u00c9s una de les mesures m\u00e9s utilitzades en estad\u00edstica per a comparar valors.</p> <p>Quartils en Pandas</p> <pre><code>import numpy as np\nimport pandas as pd\n\nedats = [\n    34, 48, 48, 55, 39, 39, 39, 35, 18, 54, 53, 29, 40, 37, 38,  23, 38,\n    51, 71, 49, 46, 40, 39, 54, 48, 38, 34, 43, 39, 45, 42, 49,  32, 56,\n    73, 57, 47, 54, 35, 29, 78, 63, 54, 59, 56, 71, 76, 80, 80,  78, 67,\n    62, 52, 82, 67, 65, 83, 59, 79, 73, 57, 68, 81, 79, 87, 73, 108, 59,\n    12, 15,  3, 26, 24, 16, 11,  2,  9, 23, 14, 12, 21, 27, 18,  19, 29,\n    18, 13, 22, 13, 12, 28, 13, 19, 12, 13, 20, 14, 18\n]\n\ndf = pd.DataFrame(edats, columns=['edat'])\n\npercentils = df.quantile([0.20, 0.85])\nprint(percentils)\n</code></pre> <pre><code>Percentils:\n      edat\n0.20  18.4\n0.85  71.9\n</code></pre>"},{"location":"apunts/02_estadistica/01_estadistica_basica/#quartils","title":"Quartils","text":"<p>Els quartils divideixen la mostra en quatre parts iguals.</p> <p>Per tant, obtenim tres punts de tall: \\(Q_1\\), \\(Q_2\\) i \\(Q_3\\), corresponents als percentils 25%, 50% i 75%.</p> Autor desconegut Figura 1: Quartils <p>Quartils en Pandas</p> <pre><code>quartils = df.quantile([0.25, 0.5, 0.75])\nprint(\"Quartils:\")\nprint(quartils)\n</code></pre> <pre><code>Quartils:\n       edat\n0.25  22.25\n0.50  40.00\n0.75  59.00\n</code></pre>"},{"location":"apunts/02_estadistica/01_estadistica_basica/#decils","title":"Decils","text":"<p>Els decils divideixen la mostra en deu parts iguals, cadascuna amb el 10% dels valors.</p> Autor desconegut Figura 2: Decils <p>Decils en Pandas</p> <pre><code>percentils = df.quantile(np.arange(0.1, 1, 0.1))\nprint(\"Decils:\")\nprint(percentils)\n</code></pre> <pre><code>Decils:\n     edat\n0.1  13.0\n0.2  18.4\n0.3  27.1\n0.4  36.6\n0.5  40.0\n0.6  49.0\n0.7  55.9\n0.8  66.2\n0.9  78.0\n</code></pre>"},{"location":"apunts/02_estadistica/01_estadistica_basica/#unitat-tipificada-standard-score","title":"Unitat tipificada (standard-score)","text":"<p>La unitat tipificada (standard-score o z-score) \u00e9s una mesura que serveix per comparar una observaci\u00f3 dins d'una distribuci\u00f3 estad\u00edstica.</p> <p>Aquesta unitat indiquen el nombre de desviacions t\u00edpiques que una observaci\u00f3 est\u00e0 per damunt o per davall de la mitjana.</p> <p>\u00c9s molt \u00fatil per a comparar observacions de diferents distribucions, ja que el seu valor no dep\u00e9n de les unitats de les variables.</p> <p>La unitat tipificada es calcula com:</p> \\[z = \\frac{x - \\mu}{\\sigma}\\] <p>Exemple</p> <p>Donada la poblaci\u00f3 de persones \\(X={20,20,50,60,80}\\):</p> <ul> <li>La mitjana \u00e9s \\(\\mu = 46\\).</li> <li>La desviaci\u00f3 est\u00e0ndard \u00e9s \\(\\sigma = 23.9\\).</li> </ul> <p>Per cada observaci\u00f3 de la poblaci\u00f3, calculem la unitat tipificada:</p> \\[ z_i = \\frac{x_i - \\mu}{\\sigma} \\] <p>La poblaci\u00f3 amb les seues unitats tipificades \u00e9s:</p> \\[ Z = \\{ -1.087, -1.087, 0.1673, 0.5858, 1.4226 \\} \\]"},{"location":"apunts/02_estadistica/01_estadistica_basica/#covariancia","title":"Covari\u00e0ncia","text":"<p>La covari\u00e0ncia \u00e9s una mesura de la relaci\u00f3 entre dues variables.</p> \\[ S_{XY} = \\frac{1}{N - ddof} \\sum_{i=1}^{N} (x_i - \\bar{X}) (y_i - \\bar{Y}) \\] <p>on \\(ddof\\) \u00e9s el grau de llibertat, que normalment \u00e9s 1.</p> <p>Aquesta mesura indica si les dues variables s\u00f3n independents o si tenen una relaci\u00f3 lineal.</p> <ul> <li>Si \\(S_{XY} \\gt 0\\) \u00e9s positiva, les dues variables s\u00f3n directament proporcionals.</li> <li>Si \\(S_{XY} \\lt 0\\) \u00e9s negativa, les dues variables s\u00f3n inversament proporcionals.</li> <li>Si \\(S_{XY} \\approx 0\\) \u00e9s zero, les dues variables s\u00f3n independents.</li> </ul> Autor desconegut Figura 3: Dues variables directament proporcionals Autor desconegut Figura 4: Dues variables inversament proporcionals <p>La matriu de covari\u00e0ncia \u00e9s una taula que cont\u00e9 les covari\u00e0ncies entre totes les parelles de variables d'un conjunt de dades.</p> <p>En Python, podem utilitzar la funci\u00f3 <code>cov()</code> de Pandas per a calcular la covari\u00e0ncia entre les columnes d'un <code>DataFrame</code>.</p> <p>Per defecte, <code>cov()</code> utilitza el grau de llibertat <code>ddof</code> igual a 1.</p> <p>Covari\u00e0ncia en Python</p> <pre><code>import pandas as pd\n\ndata = [[5, 6, 7],\n        [2, 6, 9]]\n\ndf = pd.DataFrame(data)\nprint(\"DataFrame:\")\nprint(df)\nprint()\n\ncov = df.cov()\nprint(\"Matriu de covari\u00e0ncia:\")\nprint(cov)\n</code></pre> <pre><code>DataFrame:\n   0  1  2\n0  5  6  7\n1  2  6  9\n\nMatriu de covari\u00e0ncia:\n     0    1    2\n0  4.5  0.0 -3.0\n1  0.0  0.0  0.0\n2 -3.0  0.0  2.0\n</code></pre> \\[ M_{0,0} = \\frac{1}{2 - 1}((5 - 3.5)(5 - 3.5) + (2 - 5)(2 - 5)) = 4.5 \\\\ M_{0,1} = \\frac{1}{2 - 1}((5 - 3.5)(6 - 6) + (2 - 5)(6 - 6)) = 0.0 \\\\ M_{0,2} = \\frac{1}{2 - 1}((5 - 3.5)(7 - 6.5) + (2 - 5)(9 - 6.5)) = -3.0 \\\\ ... \\]"},{"location":"apunts/02_estadistica/01_estadistica_basica/#correlacio","title":"Correlaci\u00f3","text":"<p>Similar a la covari\u00e0ncia, la correlaci\u00f3 \u00e9s una mesura normalitzada de la relaci\u00f3 entre dues variables.</p> <p>La difer\u00e8ncia principal \u00e9s que el valor de la covari\u00e0ncia dep\u00e8n de les unitats de les variables, i t\u00e9 una dif\u00edcil interpretaci\u00f3.</p> <p>En canvi, la correlaci\u00f3 \\(r\\) \u00e9s un valor que oscil\u00b7la entre -1 i 1 en qualsevol cas, que facilita la seua interpretaci\u00f3.</p> <ul> <li>Si \\(r = 1\\) les dues variables tenen una correlaci\u00f3 positiva perfecta.</li> <li>Si \\(r = -1\\) les dues variables tenen una correlaci\u00f3 negativa perfecta.</li> <li>Si \\(r = 0\\) les dues variables s\u00f3n independents.</li> </ul> <p>Quan \\(r\\) m\u00e9s s'aproxima a 1 o -1, m\u00e9s forta \u00e9s la relaci\u00f3 entre les dues variables.</p> <p>Els tipus de correlaci\u00f3 m\u00e9s comuns s\u00f3n Pearson, Rho de Spearman i Tau de Kendall.</p>"},{"location":"apunts/02_estadistica/01_estadistica_basica/#correlacio-de-pearson","title":"Correlaci\u00f3 de Pearson","text":"<p>La correlaci\u00f3 de Pearson \u00e9s la covari\u00e0ncia calculada a partir de les unitats tipificades de les dues variables.</p> <p>Aquesta mesura funciona b\u00e9 amb variables quantitatives que tenen una distribuci\u00f3 normal o similar. \u00c9s m\u00e9s sensible als valors extrems que les altres dues alternatives.</p> \\[ r_{xy} = S(z_x, z_y) \\] <p>Aquesta expressi\u00f3 s'expandeix com:</p> \\[ r_{xy} = \\frac{1}{N} \\sum_{i=1}^{N} \\left( \\frac{x_i - \\bar{X}}{\\sigma_X} \\right) \\left( \\frac{y_i - \\bar{Y}}{\\sigma_Y} \\right) \\\\ r_{xy} = \\frac{1}{N} \\frac{\\sum_{i=1}^{N} (x_i - \\bar{X})(y_i - \\bar{Y})}{\\sigma_X \\sigma_Y} \\] <p>Arribant a la simplificaci\u00f3:</p> \\[ r_{xy} = \\frac{S_{XY}}{\\sigma_X \\sigma_Y} \\] <p>Aquesta f\u00f3rmula pots ser interpretada com la covari\u00e0ncia dividida pel producte de les desviacions est\u00e0ndard de les dues variables.</p> <p>En Python, podem utilitzar la funci\u00f3 <code>corr()</code> amb l'argument <code>method='pearson'</code> (valor per defecte) per a calcular la correlaci\u00f3 de Pearson.</p> <p>Correlaci\u00f3 de Pearson en Python</p> <pre><code>corr = df.corr()\nprint(\"Correlaci\u00f3 de Pearson:\")\nprint(corr)\n</code></pre> <pre><code>Correlaci\u00f3 de Pearson:\n     0   1    2\n0  1.0 NaN -1.0\n1  NaN NaN  NaN\n2 -1.0 NaN  1.0\n</code></pre> <p>Info</p> <p><code>NaN</code> indica que no es pot calcular la correlaci\u00f3 quan una de les variables t\u00e9 desviaci\u00f3 est\u00e0ndard zero, \u00e9s a dir, \u00e9s constant.</p>"},{"location":"apunts/02_estadistica/01_estadistica_basica/#correlacio-de-spearman","title":"Correlaci\u00f3 de Spearman","text":"<p>La correlaci\u00f3 de Spearman \\(\\rho\\) (rho) \u00e9s una mesura de la relaci\u00f3 que utilitza la posici\u00f3 dels valors quan han sigut ordenats.</p> <p>Aquesta mesura \u00e9s \u00fatil quan les dades no s\u00f3n lineals.</p> <p>La f\u00f3rmula de la correlaci\u00f3 de Spearman \u00e9s:</p> \\[ \\rho = 1 - \\frac{6 \\sum_{i=1}^{N} d_i^2}{N(N^2 - 1)} \\] <p>on \\(d_i\\) \u00e9s la difer\u00e8ncia entre les posicions de les dues variables.</p> <p>Correlaci\u00f3 de Spearman en Python</p> <pre><code>spearman = df.corr(method='spearman')\nprint(\"Correlaci\u00f3 de Spearman:\")\nprint(spearman)\n</code></pre> <pre><code>Correlaci\u00f3 de Spearman:\n     0   1    2\n0  1.0 NaN -1.0\n1  NaN NaN  NaN\n2 -1.0 NaN  1.0\n</code></pre> <p>Correlaci\u00f3 de Spearman</p> <p>Utilitzant les dades \\(X = \\{5, 2\\}\\) i \\(Y = \\{7, 9\\}\\) que corresponen a les columnes 0 i 2 del <code>DataFrame</code>.</p> <p>Les posicions de les variables ordenades s\u00f3n:</p> \\(X\\) \\(Y\\) \\(O_X\\) \\(O_Y\\) \\(d_i\\) \\(d_i^2\\) 2 9 1 2 1 1 5 7 2 1 -1 1 <p>La correlaci\u00f3 de Spearman \u00e9s:</p> \\[ \\rho_{02} = 1 - \\frac{6(1^2 + 1^2)}{2(2^2 - 1)} = 1 - \\frac{12}{6} = 1 - 2 = -1 \\]"},{"location":"apunts/02_estadistica/01_estadistica_basica/#correlacio-de-kendall","title":"Correlaci\u00f3 de Kendall","text":"<p>La correlaci\u00f3 de Kendall \\(\\tau\\) (tau) \u00e9s una mesura de la relaci\u00f3 que utilitza els rangs de les variables per a calcular la correlaci\u00f3.</p> <p>Aquesta mesura \u00e9s preferible a la de Spearman quan hi ha molt poques dades i a m\u00e9s hi ha molts empats.</p> <p>La f\u00f3rmula de la correlaci\u00f3 de Kendall \u00e9s:</p> \\[ \\tau = \\frac{C - D}{C + D} \\] <p>on:</p> <ul> <li>\\(C\\) \u00e9s el nombre de parelles concordants.</li> <li>\\(D\\) \u00e9s el nombre de parelles discordants.</li> </ul> <p>Info</p> <p>Vegeu el v\u00eddeo Kendall's Tau Easily Explained per a una explicaci\u00f3 detallada.</p>"},{"location":"apunts/02_estadistica/01_estadistica_basica/#codi-font","title":"Codi font","text":"<ul> <li> <p><code>estadistica_basica.py</code></p> <pre><code>#!/usr/bin/env python3\n\nimport pandas as pd\n\ndf = pd.DataFrame({\"A\":[12,  4,  5, 44,  1],\n                   \"B\":[ 5,  2, 54,  3,  2],\n                   \"C\":[20, 16,  7,  3,  8],\n                   \"D\":[14,  3, 17,  3, 14]})\n\nprint(\"DataFrame:\")\nprint(df)\n\n# axis = 0 calcular\u00e1 la mitjana de cada columna (A, B, C, D)\ncolumn_mean = df.mean(axis = 0)\nprint(\"Mitjana de cada columna:\")\nprint(column_mean)\n\n# axis = 1 calcular\u00e1 la mitjana de cada fila (0, 1, 2, 3, 4)\nrow_mean = df.mean(axis = 1)\nprint(\"Mitjana de cada fila:\")\nprint(row_mean)\n\nmean = df.iloc[0].mean()\nprint(\"Mitjana de la primera fila:\")\nprint(mean)\n\nmean = df.loc[:,\"A\"].mean()\nprint(\"Mitjana de la columna A:\")\nprint(mean)\n\nmedian = df.median()\nprint(\"Mediana de cada columna:\")\nprint(median)\n\nmode = df.mode()\nprint(\"Moda de cada columna:\")\nprint(mode)\n\nvariance = df.var()\nprint(\"Vari\u00e0ncia de cada columna:\")\nprint(variance)\n\nstd = df.std()\nprint(\"Desviaci\u00f3 est\u00e0ndard de cada columna:\")\nprint(std)\n</code></pre> </li> <li> <p><code>quantils.py</code></p> <pre><code>#!/usr/bin/env python3\n\nimport numpy as np\nimport pandas as pd\n\nedats = [\n    34, 48, 48, 55, 39, 39, 39, 35, 18, 54, 53, 29, 40, 37, 38,  23, 38,\n    51, 71, 49, 46, 40, 39, 54, 48, 38, 34, 43, 39, 45, 42, 49,  32, 56,\n    73, 57, 47, 54, 35, 29, 78, 63, 54, 59, 56, 71, 76, 80, 80,  78, 67,\n    62, 52, 82, 67, 65, 83, 59, 79, 73, 57, 68, 81, 79, 87, 73, 108, 59,\n    12, 15,  3, 26, 24, 16, 11,  2,  9, 23, 14, 12, 21, 27, 18,  19, 29,\n    18, 13, 22, 13, 12, 28, 13, 19, 12, 13, 20, 14, 18\n]\n\ndf = pd.DataFrame(edats, columns=['edat'])\npercentils = df.quantile([0.20, 0.85])\nprint(\"Percentils:\")\nprint(percentils)\n\n\nquartils = df.quantile([0.25, 0.5, 0.75])\nprint(\"Quartils:\")\nprint(quartils)\n\ndecils = df.quantile(np.arange(0.1, 1, 0.1))\nprint(\"Decils:\")\nprint(decils)\n</code></pre> </li> <li> <p><code>covariancia.py</code></p> <pre><code>#!/usr/bin/env python3\n\nimport pandas as pd\n\ndata = [[5, 6, 7],\n        [2, 6, 9]]\n\ndf = pd.DataFrame(data)\nprint(\"DataFrame:\")\nprint(df)\nprint()\n\ncov = df.cov()\nprint(\"Matriu de covari\u00e0ncia:\")\nprint(cov)\nprint()\n\npearson = df.corr(method='pearson')\nprint(\"Correlaci\u00f3 de Pearson:\")\nprint(pearson)\nprint()\n\nspearman = df.corr(method='spearman')\nprint(\"Correlaci\u00f3 de Spearman:\")\nprint(spearman)\nprint()\n</code></pre> </li> </ul>"},{"location":"apunts/02_estadistica/01_estadistica_basica/#recursos-addicionals","title":"Recursos addicionals","text":"<ul> <li>Kendall's Tau Easily Explained</li> </ul>"},{"location":"apunts/02_estadistica/01_estadistica_basica/#bibliografia","title":"Bibliografia","text":"<ul> <li>Material del m\u00f2dul \"Sistemes d'Aprenentatge Autom\u00e0tic\" de C\u00e9sar Guijarro Rosaleny</li> <li>Quantil, Viquip\u00e8dia</li> <li>Coval\u00e8ncia, Viquip\u00e8dia</li> <li>Matriu de covari\u00e0ncia, Viquip\u00e8dia</li> <li>Correlaci\u00f3, Viquip\u00e8dia</li> <li>Correlaci\u00f3 de Pearson, Viquip\u00e8dia</li> <li>Correlaci\u00f3 de Spearman, Viquip\u00e8dia</li> <li>Kendall rank correlation coefficient, Wikipedia</li> <li>A comparison of the Pearson and Spearman correlation</li> </ul>"},{"location":"apunts/02_estadistica/02_distribucions/","title":"Distribucions de probabilitat","text":""},{"location":"apunts/02_estadistica/02_distribucions/#distribucions-de-probabilitat","title":"Distribucions de probabilitat","text":"<p>En probabilitats i estad\u00edstica, una distribuci\u00f3 de probabilitat \u00e9s una funci\u00f3 que indica la probabilitat que una variable aleat\u00f2ria prenga un valor determinat.</p> <p>Una variable aleat\u00f2ria \u00e9s una funci\u00f3 que assigna un valor num\u00e8ric a cada resultat possible d'un experiment aleatori.</p> <p>Variable aleat\u00f2ria: Catan</p> <p>En el joc de taula Catan, el resultat de llan\u00e7ar dos daus \u00e9s una variable aleat\u00f2ria.</p> <p>Considerem l'experi\u00e8ncia aleat\u00f2ria del llan\u00e7ament de dos daus. El conjunt de resultats possibles \u00e9s:</p> \\[\\Omega = \\{(1,1), (1,2), \\ldots, (1,6), (2,1), (2,2), \\ldots, (5,6), (6,6)\\}\\] <p>on cada parell \\((i,j)\\) representa el resultat obtingut en cada dau.</p> <p>La variable aleat\u00f2ria \\(X\\), que assigna a cada possible resultat la suma dels dos daus, \u00e9s:</p> \\[X((i,j)) = i+j\\] <p>Els valors possibles de la variable aleat\u00f2ria \\(X\\) s\u00f3n:</p> \\[X = \\{2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\\}\\]"},{"location":"apunts/02_estadistica/02_distribucions/#distribucio-de-probabilitat-discreta","title":"Distribuci\u00f3 de probabilitat discreta","text":"<p>Una distribuci\u00f3 de probabilitat \u00e9s discreta si la variable aleat\u00f2ria \u00e9s tamb\u00e9 discreta, \u00e9s a dir, si la variable aleat\u00f2ria pren valors en un conjunt finit o numerable.</p> <p>Catan</p> <p>En l'exemple anterior, la variable aleat\u00f2ria \\(X\\) \u00e9s discreta, ja que pren valors en un conjunt finit.</p> <p>Per calcular la distribuci\u00f3 de probabilitat de la variable aleat\u00f2ria \\(X\\), hem de calcular la probabilitat de cada valor possible de la variable aleat\u00f2ria.</p> <p>El nombre total de resultats possibles \u00e9s \\(6 \\times 6 = 36\\).</p> Suma \\(i\\) Resultats \\(\\{X = i\\}\\) Probabilitat \\(P(X = i)\\) 2 \\(\\{(1,1)\\}\\) \\(\\frac{1}{36} \\approx 0.0278\\) 3 \\(\\{(1,2), (2,1)\\}\\) \\(\\frac{2}{36} \\approx 0.0556\\) 4 \\(\\{(1,3), (2,2), (3,1)\\}\\) \\(\\frac{3}{36} \\approx 0.0833\\) 5 \\(\\{(1,4), (2,3), (3,2), (4,1)\\}\\) \\(\\frac{4}{36} \\approx 0.1111\\) 6 \\(\\{(1,5), (2,4), (3,3), (4,2), (5,1)\\}\\) \\(\\frac{5}{36} \\approx 0.1389\\) 7 \\(\\{(1,6), (2,5), (3,4), (4,3), (5,2), (6,1)\\}\\) \\(\\frac{6}{36} \\approx 0.1667\\) 8 \\(\\{(2,6), (3,5), (4,4), (5,3), (6,2)\\}\\) \\(\\frac{5}{36} \\approx 0.1389\\) 9 \\(\\{(3,6), (4,5), (5,4), (6,3)\\}\\) \\(\\frac{4}{36} \\approx 0.1111\\) 10 \\(\\{(4,6), (5,5), (6,4)\\}\\) \\(\\frac{3}{36} \\approx 0.0833\\) 11 \\(\\{(5,6), (6,5)\\}\\) \\(\\frac{2}{36} \\approx 0.0556\\) 12 \\(\\{(6,6)\\}\\) \\(\\frac{1}{36} \\approx 0.0278\\) <pre><code>xychart-beta\n    title \"Distribuci\u00f3 de probabilitat la suma de dos daus\"\n    x-axis \"Suma dels dos daus\" [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n    y-axis \"Probabilitat en %\" 0 --&gt; 20\n    bar [2.78, 5.56, 8.33, 11.11, 13.89, 16.67, 13.89, 11.11, 8.33, 5.56, 2.78]</code></pre>"},{"location":"apunts/02_estadistica/02_distribucions/#distribucio-de-bernoulli","title":"Distribuci\u00f3 de Bernoulli","text":"<p>La distribuci\u00f3 de Bernoulli \u00e9s una distribuci\u00f3 de probabilitat discreta que modela  un experiment aleatori amb dos possibles resultats: \u00e8xit o frac\u00e0s.</p> <ul> <li>Quan \u00e9s \u00e8xit, la variable aleat\u00f2ria pren el valor 1.</li> <li>Quan \u00e9s frac\u00e0s, la variable aleat\u00f2ria pren el valor 0.</li> </ul> <p>La distribuci\u00f3 de Bernoulli dep\u00e8n de dos par\u00e0metres:</p> <ul> <li>La probabilitat d'\u00e8xit \\(p\\).</li> <li>La probabilitat de frac\u00e0s \\(q\\).</li> </ul> <p>On sempre es compleix que \\(p + q = 1\\).</p> <p>La funci\u00f3 de probabilitat de la distribuci\u00f3 de Bernoulli \u00e9s:</p> \\[P(X = x) = \\begin{cases}     p &amp; \\text{si } x = 1 \\\\     q &amp; \\text{si } x = 0 \\\\     0 &amp; \\text{altrament} \\end{cases}\\] <p>O escrit com a f\u00f3rmula, on \\(x \\in \\{0, 1\\}\\):</p> \\[P(X = x) = p^x \\cdot (1 - p)^{1-x}\\] <p>Llan\u00e7ament d'una moneda</p> <p>En el llan\u00e7ament d'una moneda equilibrada, la variable aleat\u00f2ria \\(X\\) que indica si el resultat \u00e9s cara o creu \u00e9s una variable de Bernoulli, on \\(p = q = 0.5\\).</p>"},{"location":"apunts/02_estadistica/02_distribucions/#distribucio-binomial","title":"Distribuci\u00f3 binomial","text":"<p>La distribuci\u00f3 binomial \u00e9s una distribuci\u00f3 de probabilitat discreta que modela el nombre d'\u00e8xits en una seq\u00fc\u00e8ncia de \\(n\\) experiments amb una probabilitat d'\u00e8xit \\(p\\).</p> \\[X \\sim B(n, p)\\] <p>\u00c9s a dir, la distribuci\u00f3 binomial modela el nombre de vegades que es repeteix un esdeveniment de Bernoulli.</p> <p>La funci\u00f3 de probabilitat de la distribuci\u00f3 binomial \u00e9s la probabilitat de obtindre exactament \\(k\\) \u00e8xits en \\(n\\) experiments:</p> \\[P(X = k) = \\binom{n}{k} \\cdot p^k \\cdot (1 - p)^{n-k}\\] <p>on el coeficient binomial, \u00e9s el nombre de combinacions en qu\u00e8 es poden escollir \\(k\\) elements d'un conjunt de \\(n\\) elements:</p> \\[\\binom{n}{k} = \\frac{n!}{k! \\cdot (n-k)!}\\] <p>Dau igual a 6</p> <p>En el llan\u00e7ament d'un dau equilibrat, la variable aleat\u00f2ria \\(X\\) que indica si el resultat \u00e9s un 6 \u00e9s una variable de Bernoulli, on \\(p = \\frac{1}{6}\\).</p> <p>Si llancem el dau 10 vegades, la variable aleat\u00f2ria \\(Y\\) que indica el nombre de vegades que ha sortit un 6 \u00e9s una variable binomial amb \\(n = 10\\) i \\(p = \\frac{1}{6}\\).</p> \\[X \\sim B(10, \\frac{1}{6})\\] <p>La probabilitat de no treure cap 6 \u00e9s:</p> \\[P(Y = 0) = \\binom{10}{0} \\cdot \\left(\\frac{1}{6}\\right)^0 \\cdot \\left(1 - \\frac{1}{6}\\right)^{10} \\approx 0.16151\\] <pre><code>xychart-beta\n    title \"Distribuci\u00f3 de probabilitat de llan\u00e7ar un dau 10 vegades\"\n    x-axis \"Nombre de 6\" [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n    y-axis \"Probabilitat en %\" 0 --&gt; 35\n    bar [16.151, 32.301, 29.071, 15.505, 5.427, 1.302, 0.217, 0.025, 0.002, 0.000, 0.000]</code></pre>"},{"location":"apunts/02_estadistica/02_distribucions/#distribucio-de-poisson","title":"Distribuci\u00f3 de Poisson","text":"<p>La distribuci\u00f3 de Poisson \u00e9s una distribuci\u00f3 de probabilitat discreta que modela el nombre d'ocurr\u00e8ncies d'un esdeveniment en un interval de temps o espai, sempre i quan aquestes ocurr\u00e8ncies siguin independents i la seva freq\u00fc\u00e8ncia siga constant independentment del temps des de l'\u00faltima ocurr\u00e8ncia.</p> <p>La funci\u00f3 de probabilitat de la distribuci\u00f3 de Poisson \u00e9s:</p> \\[P(X = k) = \\frac{\\lambda^k \\cdot e^{-\\lambda}}{k!}\\] <p>on \\(\\lambda\\) \u00e9s la mitjana del nombre (o el nombre esperat) d'ocurr\u00e8ncies en l'interval.</p> <p>Central 112</p> <p>La central d'emerg\u00e8ncies 112 rep una mitjana de 5 trucades per minut.</p> <p>La variable aleat\u00f2ria \\(X\\) que indica el nombre de trucades que rep la central en un minut \u00e9s una variable de Poisson amb \\(\\lambda = 5\\) si les trucades s\u00f3n independents.</p> <p>La probabilitat que la central rebi exactament 3 trucades en un minut \u00e9s:</p> \\[P(X = 3) = \\frac{5^3 \\cdot e^{-5}}{3!} \\approx 0.14037\\] <pre><code>xychart-beta\n    title \"Distribuci\u00f3 de probabilitat de trucades a la central 112\"\n    x-axis \"Nombre de trucades\" [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n    y-axis \"Probabilitat en %\" 0 --&gt; 20\n    bar [0.674, 3.369, 8.422, 14.037, 17.546, 17.546, 14.621, 10.444, 6.527, 3.626, 1.813, 0.825, 0.347]</code></pre> <p>La probabilitat acumulada de rebre \\(x\\) o menys trucades en un minut \u00e9s:</p> \\[F(x)=P(X\u2264x)\\] <pre><code>xychart-beta\n    title \"Distribuci\u00f3 de probabilitat acumulada de trucades a la central 112\"\n    x-axis \"Nombre de trucades\" [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n    y-axis \"Probabilitat en %\" 0 --&gt; 100\n    line [0.674, 4.043, 12.465, 26.502, 44.048, 61.594, 76.215, 86.659, 93.186, 96.812, 98.625, 99.450, 99.797]</code></pre>"},{"location":"apunts/02_estadistica/02_distribucions/#distribucio-de-probabilitat-continua","title":"Distribuci\u00f3 de probabilitat cont\u00ednua","text":"<p>Una distribuci\u00f3 de probabilitat \u00e9s cont\u00ednua si la variable aleat\u00f2ria \u00e9s cont\u00ednua, \u00e9s a dir, si la variable aleat\u00f2ria pren valors en un conjunt no numerable (infinit) de valors.</p> <p>En aquest cas, la funci\u00f3 de probabilitat \u00e9s una funci\u00f3 de densitat de probabilitat, que indica la probabilitat que la variable aleat\u00f2ria prengui un valor en un interval.</p> \\[P(a \\leq X \\leq b) = \\int_a^b f(x) \\, dx\\] <p>Nota</p> <p>La probabilitat que la variable aleat\u00f2ria prenga un valor exacte \u00e9s sempre zero.</p>"},{"location":"apunts/02_estadistica/02_distribucions/#distribucio-uniforme-continua","title":"Distribuci\u00f3 uniforme cont\u00ednua","text":"<p>La distribuci\u00f3 uniforme cont\u00ednua \u00e9s una distribuci\u00f3 de probabilitat cont\u00ednua que modela una variable aleat\u00f2ria que pren valors en un interval amb la mateixa probabilitat.</p> <p>La funci\u00f3 de densitat de probabilitat de la distribuci\u00f3 uniforme \u00e9s:</p> \\[ f(x) = \\begin{cases}     \\frac{1}{b-a} &amp; \\text{si } a \\leq x \\leq b \\\\     0 &amp; \\text{altrament} \\end{cases} \\] <p></p> <p>La funci\u00f3 de distribuci\u00f3 de probabilitat acumulada \u00e9s:</p> \\[ F(x) = \\begin{cases}     0 &amp; \\text{si } x &lt; a \\\\     \\frac{x-a}{b-a} &amp; \\text{si } a \\leq x \\leq b \\\\     1 &amp; \\text{si } x &gt; b \\end{cases} \\] <p></p> <p>Fabricaci\u00f3 de llapis</p> <p>En una f\u00e0brica de llapis, la longitud dels llapis \u00e9s una variable aleat\u00f2ria cont\u00ednua que segueix una distribuci\u00f3 uniforme en l'interval \\([10, 20]\\) cm.</p> <p>La probabilitat que un llapis fabricat tinga una longitud entre 15 i 17 cm \u00e9s:</p> \\[P(15 \\leq X \\leq 17) = F(17) - F(15) = \\frac{17-10}{20-10} - \\frac{15-10}{20-10} = \\frac{7}{10} - \\frac{5}{10} = \\frac{2}{10} = 0.2\\]"},{"location":"apunts/02_estadistica/02_distribucions/#distribucio-normal","title":"Distribuci\u00f3 normal","text":"<p>La distribuci\u00f3 normal \u00e9s una distribuci\u00f3 de probabilitat cont\u00ednua que modela variables aleat\u00f2ries que segueixen una distribuci\u00f3 sim\u00e8trica al voltant d'un valor mitj\u00e0, on existeix poc valors extrems i molts valors prop del mitj\u00e0.</p> <p>\u00c9s el model m\u00e9s com\u00fa en estad\u00edstica, ja que existeixen moltes variables associades a fen\u00f2mens naturals que segueixen aquesta distribuci\u00f3.</p> <p>Aquesta distribuci\u00f3 es caracteritza per una campana de Gauss a partir d'un valor mitj\u00e0 \\(\\mu\\), sobre el qual el 50% dels valors queda a cada costat, i una desviaci\u00f3 est\u00e0ndard \\(\\sigma\\).</p> \\[X \\sim N(\\mu, \\sigma)\\] <p>La funci\u00f3 de densitat de probabilitat de la distribuci\u00f3 normal \u00e9s:</p> \\[f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\cdot e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\] <p></p> <p>Alguna de les propietats de la distribuci\u00f3 normal s\u00f3n:</p> <ul> <li>La mitjana, la mediana i la moda coincideixen.</li> <li>\u00c9s sim\u00e8trica respecte al valor mitj\u00e0.<ul> <li>L'interval \\([\\mu - \\sigma, \\mu + \\sigma]\\) cont\u00e9 el 68.27% dels valors.</li> <li>L'interval \\([\\mu - 2\\sigma, \\mu + 2\\sigma]\\) cont\u00e9 el 95.45% dels valors.</li> <li>L'interval \\([\\mu - 3\\sigma, \\mu + 3\\sigma]\\) cont\u00e9 el 99.73% dels valors.</li> </ul> </li> </ul> <p>A partir de la versi\u00f3 3.8 de Python, la llibreria est\u00e0ndard <code>statistics</code> inclou la classe <code>NormalDist</code> que permet treballar amb distribucions normals.</p> <p>Al\u00e7ada d'una poblaci\u00f3</p> <p>L'al\u00e7ada d'una poblaci\u00f3 segueix una distribuci\u00f3 normal amb una mitjana de 170 cm i una desviaci\u00f3 est\u00e0ndard de 10 cm.</p> <pre><code>xychart-beta\n    title \"Distribuci\u00f3 de probabilitat de l'al\u00e7ada d'una poblaci\u00f3\"\n    x-axis \"Al\u00e7ada en cm\" [140, 145, 150, 155, 160, 165, 170, 175, 180, 185, 190, 195, 200]\n    y-axis \"\" 0 --&gt; 5\n    line [0.044318, 0.175283, 0.539910, 1.295176, 2.419707, 3.520653, 3.989423, 3.520653, 2.419707, 1.295176, 0.539910, 0.175283, 0.044318]</code></pre> <p>Note</p> <p>Aquest c\u00e0lcul es pot fer mitjan\u00e7ant  unitats tipificades (standard-score) i la taula de la distribuci\u00f3 normal.</p> <p>La probabilitat que una persona triada a l'atzar tinga una al\u00e7ada entre 160 i 180 cm \u00e9s:</p> \\[P(160 \\leq X \\leq 180) = 0.6826\\] <p>La probabilitat que una persona triada a l'atzar tinga una al\u00e7ada m\u00e9s gran que 190 cm \u00e9s:</p> \\[P(X &gt; 190) = 1 - P(X \\leq 190) = 1 - 0.9772 = 0.0228\\] <pre><code>from statistics import NormalDist\n\nheight_dist = NormalDist(mu=170, sigma=10)\n\n# Probability of a person being taller than 160 cm and shorter than 180 cm\np = height_dist.cdf(180) - height_dist.cdf(160)\nprint(\"Probability of a person being taller than 160 cm and shorter than 180 cm:\", p)\n\n# Probability of a person being taller than 190 cm\np = 1 - height_dist.cdf(190)\nprint(\"Probability of a person being taller than 190 cm:\", p)\n</code></pre> <pre><code>Probability of a person being taller than 160 cm and shorter than 180 cm: 0.6826\nProbability of a person being taller than 190 cm: 0.02275\n</code></pre>"},{"location":"apunts/02_estadistica/02_distribucions/#distribucio-normal-estandard","title":"Distribuci\u00f3 normal est\u00e0ndard","text":"<p>La distribuci\u00f3 normal est\u00e0ndard \u00e9s cas especial d'una distribuci\u00f3 normal, que t\u00e9 una mitjana \\(\\mu = 0\\) i una desviaci\u00f3 est\u00e0ndard \\(\\sigma = 1\\).</p> \\[X \\sim N(0, 1)\\] <p>A Python, inicialitzar una distribuci\u00f3 normal est\u00e0ndard es fa amb la classe <code>NormalDist</code> sense par\u00e0metres.</p> <pre><code>from statistics import NormalDist\n\nstd_normal_dist = NormalDist() # mu=0, sigma=1\n</code></pre> <p>Aquesta distribuci\u00f3 \u00e9s molt important en estad\u00edstica, ja que permet calcular la probabilitat acumulada de qualsevol distribuci\u00f3 normal utilitzant les  unitats tipificades (standard-score) i consultat la taula de la distribuci\u00f3 normal.</p> <p>Aquesta taula indica la probabilitat acumulada de trobar un valor menor que \\(z\\) en una distribuci\u00f3 normal est\u00e0ndard.</p> \\[P(Z \\leq z)\\] www.a-levelmathstutor.com CDF de la distribuci\u00f3 normal est\u00e0ndard <p>El m\u00e8tode <code>cdf</code> de la classe <code>NormalDist</code> permet calcular la probabilitat acumulada de trobar un valor menor o igual que \\(z\\) en una distribuci\u00f3 normal.</p> <pre><code>std_normal_dist.cdf(z)\n</code></pre> <p>C\u00e0lcul de probabilitats al\u00e7ada d'una poblaci\u00f3</p> <p>Calculem la probabilitat que una persona tinga una al\u00e7ada entre 160 i 180 cm.</p> <ol> <li> <p>Per a \\(x = 160\\) cm:</p> \\[z_1 = \\frac{160 - 170}{10} = -1\\] </li> <li> <p>Per a \\(x = 180\\) cm:</p> \\[z_2 = \\frac{180 - 170}{10} = 1\\] </li> </ol> <p>Utilitzant les unitats tipificades \\(z_1 = -1\\) i \\(z_2 = 1\\), podem calcular la probabilitat acumulada de trobar un valor entre \\(z_1\\) i \\(z_2\\):</p> \\[P(-1 \\leq Z \\leq 1) = P(Z \\leq 1) - P(Z \\leq -1)\\] <p>Consultem la taula de la distribuci\u00f3 normal est\u00e0ndard:</p> \\[P(Z \\leq 1) = 0.8413\\] \\[P(Z \\leq -1) = 0.1587\\] <p>Per tant:</p> \\[P(-1 \\leq Z \\leq 1) = 0.8413 - 0.1587 = 0.6826\\] <pre><code># Probability of a person being taller than 160 cm and shorter than 180 cm\nz1 = (160 - 170) / 10\nz2 = (180 - 170) / 10\np = std_normal_dist.cdf(z2) - std_normal_dist.cdf(z1)\nprint(\"Probability of a person being taller than 160 cm and shorter than 180 cm:\", p)\n</code></pre> <pre><code>Probability of a person being taller than 160 cm and shorter than 180 cm: 0.6826\n</code></pre>"},{"location":"apunts/02_estadistica/02_distribucions/#distribucio-conjunta-i-mostral","title":"Distribuci\u00f3 conjunta i mostral","text":"<p>Curiositat</p> <p>-CIS: \u00bfC\u00f3mo se hacen las encuestas?</p>"},{"location":"apunts/02_estadistica/02_distribucions/#distribucio-conjunta","title":"Distribuci\u00f3 conjunta","text":"<p>La distribuci\u00f3 conjunta \u00e9s la distribuci\u00f3 de probabilitat de tots els possibles valors d'una variable aleat\u00f2ria en una poblaci\u00f3.</p> <p>En la pr\u00e0ctica, la distribuci\u00f3 poblacional \u00e9s desconeguda, ja que no es molt dif\u00edcil o impossible obtenir tots els valors d'una poblaci\u00f3.</p> <p>Edats d'una poblaci\u00f3</p> <p>Donada una poblaci\u00f3 de 10000 persones, la distribuci\u00f3 de les edats \u00e9s la seg\u00fcent.</p> <pre><code># Distribuci\u00f3 conjunta (totes les dades)\ndf_edats = pd.read_csv('generated_edats.csv', header=None, index_col=False, names=['edat'])\nmean = df_edats.mean().values[0].round(2)\nstd = df_edats.std().values[0].round(2)\n</code></pre> <pre><code># Distribuci\u00f3 conjunta\nMitjana de les edats: 44.14\nDesviaci\u00f3 est\u00e0ndard de les edats: 22.39\n</code></pre>"},{"location":"apunts/02_estadistica/02_distribucions/#distribucio-mostral","title":"Distribuci\u00f3 mostral","text":"<p>La distribuci\u00f3 mostral \u00e9s la distribuci\u00f3 de probabilitat d'una estad\u00edstica calculada a partir d'una mostra aleat\u00f2ria d'una poblaci\u00f3.</p> <p>Les distribucions mostrals s\u00f3n importants en les estad\u00edstiques perqu\u00e8 proporcionen una important simplificaci\u00f3 abans d'utilitzar la infer\u00e8ncia estad\u00edstica, quan obtindre tots els valors d'una poblaci\u00f3 \u00e9s molt dif\u00edcil o impossible.</p> <p>Normalment, quan major \u00e9s la mida de la mostra, m\u00e9s s'assembla a la distribuci\u00f3 la distribuci\u00f3 poblacional.</p> <p>Mostres en edats d'una poblaci\u00f3</p> <p>Realitzem tres mostres de 10, 100 i 1000 persones de la poblaci\u00f3 anterior.</p> <p>Vegem com varien les mitjanes i les desviacions est\u00e0ndard de les mostres, que segons augmenta la mida de la mostra, s'assemblen m\u00e9s a la distribuci\u00f3 poblacional.</p> <pre><code># Distribuci\u00f3 mostral I (agafem 1 mostra de 10 dades)\nsample1 = df_edats.sample(10, random_state=42)\nmean = sample1.mean().values[0].round(2)\nstd = sample1.std().values[0].round(2)\n\nprint(\"Distribuci\u00f3 mostral I\")\nprint(\"Mitjana de la mostra 1:\", mean)\nprint(\"Desviaci\u00f3 est\u00e0ndard de la mostra 1:\", std)\nprint()\n\n# Distribuci\u00f3 mostral II (agafem 1 mostra de 100 dades)\nsample2 = df_edats.sample(100, random_state=42)\nmean = sample2.mean().values[0].round(2)\nstd = sample2.std().values[0].round(2)\n\nprint(\"Distribuci\u00f3 mostral II\")\nprint(\"Mitjana de la mostra 2:\", mean)\nprint(\"Desviaci\u00f3 est\u00e0ndard de la mostra 2:\", std)\nprint()\n\n# Distribuci\u00f3 mostral III (agafem 1 mostra de 1000 dades)\nsample3 = df_edats.sample(1000, random_state=42)\nmean = sample3.mean().values[0].round(2)\nstd = sample3.std().values[0].round(2)\n\nprint(\"Distribuci\u00f3 mostral III\")\nprint(\"Mitjana de la mostra 3:\", mean)\nprint(\"Desviaci\u00f3 est\u00e0ndard de la mostra 3:\", std)\n</code></pre> <pre><code>Distribuci\u00f3 mostral I\nMitjana de la mostra 1: 36.5\nDesviaci\u00f3 est\u00e0ndard de la mostra 1: 26.38\n\nDistribuci\u00f3 mostral II\nMitjana de la mostra 2: 45.59\nDesviaci\u00f3 est\u00e0ndard de la mostra 2: 24.78\n\nDistribuci\u00f3 mostral III\nMitjana de la mostra 3: 43.46\nDesviaci\u00f3 est\u00e0ndard de la mostra 3: 22.23\n</code></pre>"},{"location":"apunts/02_estadistica/02_distribucions/#distribucio-mostral-de-la-mitjana","title":"Distribuci\u00f3 mostral de la mitjana","text":"<p>La distribuci\u00f3 mostral de la mitjana \u00e9s una distribuci\u00f3 de probabilitat calculada a partir de les mitjanes de distribucions mostrals.</p> <p>Segons el teorema del l\u00edmit central, aquesta distribuci\u00f3 s'assembla m\u00e9s a la distribuci\u00f3 conjunta a mesura que s'utilitzen m\u00e9s mostres.</p> <p>Mitjana de mostres en edats d'una poblaci\u00f3</p> <p>Realitzem tres grups de mostres de 1, 10 i 100 grups de 10 persones de la poblaci\u00f3 anterior.</p> <p>Vegem com varien les mitjanes i les desviacions est\u00e0ndard de les mostres, que segons augmenta el nombre de mostres, s'assemblen m\u00e9s a la distribuci\u00f3 poblacional.</p> <pre><code># Distribuci\u00f3 mostral de la mitjana I (agafem 1 mostra de 10 dades)\nsample1 = df_edats.sample(10, random_state=42)\nmean = sample1.mean().values[0].round(2)\nstd = sample1.std().values[0].round(2)\n\nprint(\"Distribuci\u00f3 mostral de la mitjana I\")\nprint(\"Mitjana de la mostra 1:\", mean)\nprint(\"Desviaci\u00f3 est\u00e0ndard de la mostra 1:\", std)\nprint()\n\n# Distribuci\u00f3 mostral de la mitjana II (agafem 10 mostres de 10 dades)\nmeans = []\nstds = []\nfor i in range(10):\n    sample = df_edats.sample(10, random_state=i)\n    means.append(sample.mean().values[0])\n    stds.append(sample.std().values[0])\n\nmean = pd.Series(means).mean().round(2)\nstd = pd.Series(stds).mean().round(2)\n\nprint(\"Distribuci\u00f3 mostral de la mitjana II\")\nprint(\"Mitjana de les mitjanes:\", mean)\nprint(\"Desviaci\u00f3 est\u00e0ndard de les mitjanes:\", std)\nprint()\n\n# Distribuci\u00f3 mostral de la mitjana III (agafem 100 mostres de 10 dades)\nmeans = []\nstds = []\nfor i in range(100):\n    sample = df_edats.sample(10, random_state=i)\n    means.append(sample.mean().values[0])\n    stds.append(sample.std().values[0])\n\nmean = pd.Series(means).mean().round(2)\nstd = pd.Series(stds).mean().round(2)\n\nprint(\"Distribuci\u00f3 mostral de la mitjana III\")\nprint(\"Mitjana de les mitjanes:\", mean)\nprint(\"Desviaci\u00f3 est\u00e0ndard de les mitjanes:\", std)\n</code></pre> <pre><code>Distribuci\u00f3 mostral de la mitjana I\nMitjana de la mostra 1: 36.5\nDesviaci\u00f3 est\u00e0ndard de la mostra 1: 26.38\n\nDistribuci\u00f3 mostral de la mitjana II\nMitjana de les mitjanes: 45.11\nDesviaci\u00f3 est\u00e0ndard de les mitjanes: 23.27\n\nDistribuci\u00f3 mostral de la mitjana III\nMitjana de les mitjanes: 44.26\nDesviaci\u00f3 est\u00e0ndard de les mitjanes: 21.41\n</code></pre>"},{"location":"apunts/02_estadistica/02_distribucions/#contrast-dhipotesis","title":"Contrast d'hip\u00f2tesis","text":"<p>En molts estudis estad\u00edstics, l'objectiu \u00e9s comprovar si una afirmaci\u00f3 sobre una poblaci\u00f3 \u00e9s certa o no.</p> <p>En general, \u00e9s impossible provar que una afirmaci\u00f3 \u00e9s certa al 100%, ja que caldria con\u00e8ixer tots els valors de la poblaci\u00f3.</p> <p>Per tant, el que es fa \u00e9s contrastar hip\u00f2tesis sobre la poblaci\u00f3, on es tracta de comprovar si una afirmaci\u00f3 \u00e9s probable o no.</p> <p>Aquest proc\u00e9s tracta de prendre una decisi\u00f3 sobre dues hip\u00f2tesis:</p> <ul> <li>Hip\u00f2tesi nul\u00b7la (\\(H_0\\)): \u00c9s la hip\u00f2tesi que s'accepta provisionalment.</li> <li>Hip\u00f2tesi alternativa (\\(H_1\\)): \u00c9s la hip\u00f2tesi contr\u00e0ria.</li> </ul> <p>Hores d'esport a la setmana</p> <p>Un estudi afirma que la poblaci\u00f3 dedica m\u00e9s de 5 hores setmana a fer esport, amb una desviaci\u00f3 est\u00e0ndard de 4 hores.</p> <p>Sospitem que aquesta afirmaci\u00f3 \u00e9s falsa, i volem contrastar-la amb una mostra de 20 persones.</p> \\[X = \\{7, 6, 4, 3, 1, 9, 8, 7, 3, 1, 1,0, 9, 4, 3, 2, 1, 5, 5, 6, 4\\}\\] <p>Les hip\u00f2tesis s\u00f3n:</p> <ul> <li>\\(H_0 = \\mu \\geq 5\\): La mitjana de les hores d'esport \u00e9s major o igual a 5.</li> <li>\\(H_1 = \\mu &lt; 5\\): La mitjana de les hores d'esport \u00e9s menor que 5.</li> </ul> <p>Per comprovar-ho, primer hem de triar un nivell de significaci\u00f3 \\(\\alpha\\), que marcar\u00e0 els l\u00edmits entre la regi\u00f3 d'acceptaci\u00f3 i la regi\u00f3 de rebuig.</p> <p>Un valor com\u00fa \u00e9s \\(\\alpha = 0.05\\).</p> <p>Calculem la <code>z-score</code> de \\(\\alpha\\), que marcar\u00e0 el l\u00edmit de la regi\u00f3 de rebuig en una distribuci\u00f3 normal est\u00e0ndard.</p> <pre><code>#!/usr/bin/env python3\n\nfrom statistics import NormalDist\n\nalpha = 0.05\nz_alpha = round(NormalDist().inv_cdf(alpha), 2)\nprint(\"Z-score de alpha:\", z_alpha)\n</code></pre> <pre><code>Z-score de alpha: -1.64\n</code></pre> <p></p> <p>El seg\u00fcent pas \u00e9s calcular la <code>z-score</code> de la mitjana de la mostra, que ens indicar\u00e0 si la mitjana de la mostra \u00e9s dins de la regi\u00f3 d'acceptaci\u00f3 o de rebuig.</p> <p>Note</p> <p>S'utilitza la desviaci\u00f3 est\u00e0ndard de la mostra.</p> \\[\\sigma_{\\bar{X}} = \\frac{\\sigma}{\\sqrt{n}}\\] <p>Per tant, el c\u00e0lcul de la <code>z-score</code> de la mitjana de la mostra \u00e9s:</p> \\[Z_{\\bar{X}} = \\frac{\\bar{X} - \\mu}{\\sigma_{\\bar{X}}} = \\frac{\\bar{X} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}}\\] <pre><code>import numpy as np\n\n# Mostra\nX = np.array([7, 6, 4, 3, 1, 9, 8, 7, 3, 1, 1, 0, 9, 4, 3, 2, 1, 5, 5, 6, 4])\n\n# Mitjana i desviaci\u00f3 est\u00e0ndard de la mostra\nmean = X.mean()\nstd = X.std()\n\n# Z-score de la mitjana de la mostra\nz = (mean - 5) / (std / np.sqrt(len(X)))\nprint(\"Mitjana de la mostra:\", mean)\nprint(\"Z-score de la mitjana de la mostra:\", round(z, 2))\n</code></pre> <pre><code>Mitjana de la mostra: 4.238095238095238\nZ-score de la mitjana de la mostra: -1.3\n</code></pre> <p>Per \u00faltim, comparem la <code>z-score</code> de la mitjana de la mostra amb la <code>z-score</code> de \\(\\alpha\\).</p> <p>Si la <code>z-score</code> de la mitjana de la mostra \u00e9s menor que la <code>z-score</code> de \\(\\alpha\\), rebutgem la hip\u00f2tesi nul\u00b7la.</p> <pre><code># Comprovaci\u00f3 de la hip\u00f2tesi\np_value = NormalDist().cdf(z)\nprint(f\"Z-score de la mitjana de la mostra: {round(z, 2)} (p_value: {round(p_value, 4)})\")\nprint(f\"Z-score de alpha: {z_alpha} (significancia: {alpha})\")\nif z &lt; z_alpha:\n    print(\"Rebutgem la hip\u00f2tesi nul\u00b7la\")\nelse:\n    print(\"Acceptem la hip\u00f2tesi nul\u00b7la\")\n</code></pre> <pre><code>Z-score de la mitjana de la mostra: -1.3 (p_value: 0.097)\nZ-score de alpha: -1.64 (0.05)\nAcceptem la hip\u00f2tesi nul\u00b7la\n</code></pre> <p>Com que la \\(Z_{\\bar{X}}\\) i el valor p s\u00f3n majors que la de \\(Z_\\alpha\\) i \\(\\alpha\\) respectivament, acceptem la hip\u00f2tesi nul\u00b7la, \u00e9s a dir, la mitjana de les hores d'esport \u00e9s major o igual a 5.</p> <p>Advert\u00e8ncia</p> <p>Existeixen moltes proves estad\u00edstiques de contrast d'hip\u00f2tesis, segons les dades i la naturalesa del problema.</p> <p>Perill</p> <p>El valor p no indica el percentatge de certesa de la hip\u00f2tesi.</p> <p>En l'exemple anterior, no podem afirmar amb un 90.3% de certesa que la mitjana de les hores d'esport \u00e9s major o igual a 5,</p> <p>Realment, el valor p indica la probabilitat de trobar la mitjana que hem obtingut assumint que la hip\u00f2tesi nul\u00b7la \u00e9s certa.</p> <p>Per tant, si el valor p \u00e9s molt baix, podem rebutjar la hip\u00f2tesi nul\u00b7la.</p>"},{"location":"apunts/02_estadistica/02_distribucions/#codi-font","title":"Codi font","text":"<ul> <li> <p><code>normal.py</code></p> <pre><code>#!/usr/bin/env python3\n\nfrom statistics import NormalDist\n\nheight_dist = NormalDist(mu=170, sigma=10)\n\n# Probability of a person being taller than 160 cm and shorter than 180 cm\np = height_dist.cdf(180) - height_dist.cdf(160)\nprint(\"Probability of a person being taller than 160 cm and shorter than 180 cm:\", p)\n\n# Probability of a person being taller than 190 cm\np = 1 - height_dist.cdf(190)\nprint(\"Probability of a person being taller than 190 cm:\", p)\n</code></pre> </li> <li> <p><code>generated_edats.csv</code></p> </li> <li> <p><code>distribucio_mostral.py</code></p> <pre><code>#!/usr/bin/env python3\n\nimport pandas as pd\n\n# Distribuci\u00f3 conjunta (totes les dades)\ndf_edats = pd.read_csv('generated_edats.csv', header=None, index_col=False, names=['edat'])\nmean = df_edats.mean().values[0].round(2)\nstd = df_edats.std().values[0].round(2)\n\nprint(\"# Distribuci\u00f3 conjunta\")\nprint(\"Mitjana de les edats:\", mean)\nprint(\"Desviaci\u00f3 est\u00e0ndard de les edats:\", std)\nprint()\n\n# Distribuci\u00f3 mostral I (agafem 1 mostra de 10 dades)\nsample1 = df_edats.sample(10, random_state=42)\nmean = sample1.mean().values[0].round(2)\nstd = sample1.std().values[0].round(2)\n\nprint(\"Distribuci\u00f3 mostral I\")\nprint(\"Mitjana de la mostra 1:\", mean)\nprint(\"Desviaci\u00f3 est\u00e0ndard de la mostra 1:\", std)\nprint()\n\n# Distribuci\u00f3 mostral II (agafem 1 mostra de 100 dades)\nsample2 = df_edats.sample(100, random_state=42)\nmean = sample2.mean().values[0].round(2)\nstd = sample2.std().values[0].round(2)\n\nprint(\"Distribuci\u00f3 mostral II\")\nprint(\"Mitjana de la mostra 2:\", mean)\nprint(\"Desviaci\u00f3 est\u00e0ndard de la mostra 2:\", std)\nprint()\n\n# Distribuci\u00f3 mostral III (agafem 1 mostra de 1000 dades)\nsample3 = df_edats.sample(1000, random_state=42)\nmean = sample3.mean().values[0].round(2)\nstd = sample3.std().values[0].round(2)\n\nprint(\"Distribuci\u00f3 mostral III\")\nprint(\"Mitjana de la mostra 3:\", mean)\nprint(\"Desviaci\u00f3 est\u00e0ndard de la mostra 3:\", std)\nprint()\n\n# Distribuci\u00f3 mostral de la mitjana I (agafem 1 mostra de 10 dades)\nsample1 = df_edats.sample(10, random_state=42)\nmean = sample1.mean().values[0].round(2)\nstd = sample1.std().values[0].round(2)\n\nprint(\"Distribuci\u00f3 mostral de la mitjana I\")\nprint(\"Mitjana de la mostra 1:\", mean)\nprint(\"Desviaci\u00f3 est\u00e0ndard de la mostra 1:\", std)\nprint()\n\n# Distribuci\u00f3 mostral de la mitjana II (agafem 10 mostres de 10 dades)\nmeans = []\nstds = []\nfor i in range(10):\n    sample = df_edats.sample(10, random_state=i)\n    means.append(sample.mean().values[0])\n    stds.append(sample.std().values[0])\n\nmean = pd.Series(means).mean().round(2)\nstd = pd.Series(stds).mean().round(2)\n\nprint(\"Distribuci\u00f3 mostral de la mitjana II\")\nprint(\"Mitjana de les mitjanes:\", mean)\nprint(\"Desviaci\u00f3 est\u00e0ndard de les mitjanes:\", std)\nprint()\n\n# Distribuci\u00f3 mostral de la mitjana III (agafem 100 mostres de 10 dades)\nmeans = []\nstds = []\nfor i in range(100):\n    sample = df_edats.sample(10, random_state=i)\n    means.append(sample.mean().values[0])\n    stds.append(sample.std().values[0])\n\nmean = pd.Series(means).mean().round(2)\nstd = pd.Series(stds).mean().round(2)\n\nprint(\"Distribuci\u00f3 mostral de la mitjana III\")\nprint(\"Mitjana de les mitjanes:\", mean)\nprint(\"Desviaci\u00f3 est\u00e0ndard de les mitjanes:\", std)\n</code></pre> </li> <li> <p><code>contrast_hipotesi.py</code></p> <pre><code>#!/usr/bin/env python3\n\nfrom statistics import NormalDist\nimport numpy as np\n\nalpha = 0.05\nz_alpha = round(NormalDist().inv_cdf(alpha), 2)\nprint(\"Z-score de alpha:\", z_alpha)\n\nX = np.array([7, 6, 4, 3, 1, 9, 8, 7, 3, 1, 1, 0, 9, 4, 3, 2, 1, 5, 5, 6, 4])\n\n# Mitjana i desviaci\u00f3 est\u00e0ndard de la mostra\nmean = X.mean()\nstd = X.std()\n\n# Z-score de la mitjana de la mostra\nz = (mean - 5) / (std / np.sqrt(len(X)))\nprint()\nprint(\"Mitjana de la mostra:\", mean)\nprint(\"Z-score de la mitjana de la mostra:\", round(z, 2))\n\n# Comprovaci\u00f3 de la hip\u00f2tesi\np_value = NormalDist().cdf(z)\nprint()\nprint(f\"Z-score de la mitjana de la mostra: {round(z, 2)} (p_value: {round(p_value, 4)})\")\nprint(f\"Z-score de alpha: {z_alpha} ({alpha})\")\nif z &lt; z_alpha:\n    print(\"Rebutgem la hip\u00f2tesi nul\u00b7la\")\nelse:\n    print(\"Acceptem la hip\u00f2tesi nul\u00b7la\")\n</code></pre> </li> </ul>"},{"location":"apunts/02_estadistica/02_distribucions/#bibliografia","title":"Bibliografia","text":"<ul> <li>Material del m\u00f2dul \"Sistemes d'Aprenentatge Autom\u00e0tic\" de C\u00e9sar Guijarro Rosaleny</li> <li>Distribuci\u00f3 de probabilitat, Viquip\u00e8dia</li> <li>Variable aleat\u00f2ria, Viquip\u00e8dia</li> <li>Distribuci\u00f3 de Bernoulli, Viquip\u00e8dia</li> <li>Distribuci\u00f3 binomial, Viquip\u00e8dia</li> <li>Distribuci\u00f3 de Poisson, Viquip\u00e8dia</li> <li>Distribuci\u00f3 uniforme cont\u00ednua, Viquip\u00e8dia</li> <li>Distribuci\u00f3 normal, Viquip\u00e8dia</li> <li>Joint Probability Distribution, Wikipedia</li> <li>Sampling Distribution, Wikipedia</li> <li>Teorema del l\u00edmit central, Viquip\u00e8dia</li> <li>Significaci\u00f3 estad\u00edstica, Viquip\u00e8dia</li> <li>Valor p, Viquip\u00e8dia</li> </ul>"},{"location":"apunts/03_manipulacio_dades/01_pandas/","title":"Manipulaci\u00f3 de dades amb Pandas","text":"","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#manipulacio-de-dades-amb-pandas","title":"Manipulaci\u00f3 de dades amb Pandas","text":"<p><code>pandas</code> \u00e9s una llibreria de Python que proporciona estructures de dades (<code>Series</code> i <code>DataFrame</code>) i eines per a l'an\u00e0lisi de dades.</p> <p>Existeixen altres llibreries que proporcionen ferramentes semblants, com <code>numpy</code>, per\u00f2 en aquest cas, els seus casos d'\u00fas son diferents.</p>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#installacio","title":"Instal\u00b7laci\u00f3","text":"<p>Pots instal\u00b7lar la llibreria <code>pandas</code> amb <code>pip</code>:</p> <pre><code>pip install pandas\n</code></pre>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#importacio","title":"Importaci\u00f3","text":"<p>Per utilitzar <code>pandas</code>, cal importar la llibreria abans:</p> <pre><code>import pandas as pd# (1)!\n</code></pre> <ol> <li><code>pd</code> \u00e9s un alias que es fa servir com a prefix per a accedir a les funcions de <code>pandas</code>.</li> </ol>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#estructura-de-dades","title":"Estructura de dades","text":"<p><code>pandas</code> proporciona dues estructures de dades principals:</p> <ul> <li><code>Series</code>: \u00e9s un array unidimensional etiquetat.</li> <li><code>DataFrame</code>: \u00e9s una estructura de dades bidimensional etiquetada amb columnes de tipus diferents.</li> </ul>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#series","title":"<code>Series</code>","text":"<p><code>Series</code> \u00e9s un array unidimensional etiquetat, que pot contindre dades de qualsevol tipus (n\u00fameros, cadenes de car\u00e0cters, objectes, etc.). Les etiquetes son referenciades com a <code>index</code>.</p> <p>La sintaxi b\u00e0sica per a crear una <code>Series</code> \u00e9s la seg\u00fcent:</p> <pre><code>s = pd.Series(data, index=index)\n</code></pre> <ul> <li><code>data</code>: Dades de la <code>Series</code>, que pot ser una llista, un diccionari, un array de <code>numpy</code>, un valor escalar, etc.</li> <li><code>index</code>: Etiquetes de la <code>Series</code>. La mida de <code>index</code> ha de coincidir amb la mida de <code>data</code>.</li> </ul> <p>Info</p> <p>Si no s'especifica <code>index</code>, es crea un \u00edndex num\u00e8ric de 0 a <code>len(data) - 1</code>.</p> <p>Documentaci\u00f3</p> <p>Cap\u00edtol \"2.2.1 <code>Series</code>\" del llibre Practical Tutorial on Data Manipulation with Numpy and Pandas in Python.</p> <p>Exemple</p> <pre><code>import pandas as pd\n\n# Crear una Series amb una llista\na = [1, 3, 5, 7, 9]\ns = pd.Series(a)\nprint(\"Series amb una llista\")\nprint(s)\nprint()\n\n# Crear una Series amb un diccionari\nd = {'a': 1, 'b': 3, 'c': 5, 'd': 7, 'e': 9}\ns = pd.Series(d)\nprint(\"Series amb un diccionari\")\nprint(s)\nprint()\n\n# Crear una Series amb un valor escalar\ns = pd.Series(5, index=[0, 1, 2, 3, 4])\nprint(\"Series amb un valor escalar\")\nprint(s)\n</code></pre> <pre><code>Series amb una llista\n0    1\n1    3\n2    5\n3    7\n4    9\ndtype: int64\n\nSeries amb un diccionari\na    1\nb    3\nc    5\nd    7\ne    9\ndtype: int64\n\nSeries amb un valor escalar\n0    5\n1    5\n2    5\n3    5\n4    5\ndtype: int64\n</code></pre>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#dataframe","title":"<code>DataFrame</code>","text":"<p><code>DataFrame</code> \u00e9s una estructura de dades bidimensional (2D) etiquetada amb columnes de tipus diferents. Pot considerar-se com una taula de base de dades SQL o un full de c\u00e0lcul.</p> <p>La sintaxi b\u00e0sica per a crear un <code>DataFrame</code> \u00e9s la seg\u00fcent:</p> <pre><code>df = pd.DataFrame(data, index=index, columns=columns)\n</code></pre> <ul> <li> <p><code>data</code>: Dades del <code>DataFrame</code>, que poden ser:</p> <ul> <li>Un diccionari de llistes, arrays de <code>numpy</code>, <code>Series</code>, etc.</li> <li>Un array bidimensional de <code>numpy</code>.</li> <li>Un altre <code>DataFrame</code>.</li> </ul> </li> <li> <p><code>index</code>: Etiquetes de les files del <code>DataFrame</code>. La mida de <code>index</code> ha de coincidir amb el nombre de files de <code>data</code>.</p> </li> <li> <p><code>columns</code>: Etiquetes de les columnes del <code>DataFrame</code>. La mida de <code>columns</code> ha de coincidir amb el nombre de columnes de <code>data</code>.</p> </li> </ul> <p>Info</p> <p>Si no s'especifica <code>index</code> o <code>columns</code>, es creen \u00edndexs num\u00e8rics de a partir de 0.</p> <p>Documentaci\u00f3</p> <p>Cap\u00edtol \"2.2.2 <code>DataFrame</code>\" del llibre Practical Tutorial on Data Manipulation with Numpy and Pandas in Python.</p> <p>Exemple</p> <pre><code># Crear un DataFrame amb una llista\na = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\ndf = pd.DataFrame(a)\nprint(\"DataFrame amb una llista\")\nprint(df)\nprint()\n\n# Crear un Dataframe amb una llista, indicant els noms de les columnes\ndf = pd.DataFrame(a, columns=['A', 'B', 'C'])\nprint(\"DataFrame amb una llista i noms de columnes\")\nprint(df)\nprint()\n\n# Crear un DataFrame amb un diccionari\nd = {'A': [1, 4, 7], 'B': [2, 5, 8], 'C': [3, 6, 9]}\ndf = pd.DataFrame(d)\nprint(\"DataFrame amb un diccionari\")\nprint(df)\nprint()\n</code></pre> <pre><code>DataFrame amb una llista\n   0  1  2\n0  1  2  3\n1  4  5  6\n2  7  8  9\n\nDataFrame amb una llista i noms de columnes\n   A  B  C\n0  1  2  3\n1  4  5  6\n2  7  8  9\n\nDataFrame amb un diccionari\n   A  B  C\n0  1  2  3\n1  4  5  6\n2  7  8  9\n</code></pre>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#operacions-de-lectura-i-escriptura","title":"Operacions de lectura i escriptura","text":"<p><code>pandas</code> permet llegir i escriure dades de diferents formats, com ara CSV o JSON.</p> <p>Documentaci\u00f3</p> <p>Cap\u00edtol \"2.4. IO Tools\" del llibre Practical Tutorial on Data Manipulation with Numpy and Pandas in Python.</p>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#carregar-dades","title":"Carregar dades","text":"<p>Per carregar dades, es fa servir la funci\u00f3 <code>read_&lt;tipus&gt;()</code>, on <code>&lt;tipus&gt;</code> pot ser <code>csv</code>, <code>json</code> o altres.</p> <p>En el cas de carregar dades d'un fitxer CSV, es fa servir la funci\u00f3 <code>read_csv()</code>.</p> <p>Carregar dades d'un fitxer CSV</p> <pre><code># Crear un DataFrame a partir d'un fitxer CSV\ncotxes_df = pd.read_csv('../../files/ud3/cotxes.csv')\nprint(\"DataFrame a partir d'un fitxer CSV\")\nprint(cotxes_df)\n</code></pre> <pre><code>DataFrame a partir d'un fitxer CSV\n         marca     km data_matriculacio\n0         Ford  39031        08/12/2000\n1         Seat  10542        02/01/2001\n2   Volkswagen   8065        02/04/2001\n...\n56        Fiat  18358        06/11/2002\n57     Porsche  19791        02/01/2012\n58      Nissan  18722        02/04/2001\n59    Mercedes  48813        10/03/2005\n</code></pre>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#guardar-dades","title":"Guardar dades","text":"<p>Per guardar dades, es fa servir la funci\u00f3 <code>to_&lt;tipus&gt;()</code>, on <code>&lt;tipus&gt;</code> pot ser <code>csv</code>, <code>json</code> o altres.</p> <p>En el cas de guardar dades en un fitxer CSV, es fa servir la funci\u00f3 <code>to_csv()</code>.</p> <p>Guardar dades en un fitxer CSV</p> <p>Info</p> <p><code>index=False</code> evita que s'afegisca una columna amb l'\u00edndex de les files (0, 1, 2, ...).</p> <pre><code># Guardar un DataFrame en un fitxer CSV\ndf = pd.DataFrame({\n    'nom': ['Aina', 'Mar', 'Pere'],\n    'edat': [25, 30, 35],\n    'ciutat': ['Val\u00e8ncia', 'Mislata', 'Alboraia']\n})\ndf.to_csv('../../files/ud3/persones.csv', index=False)\n</code></pre> <pre><code>jpuigcerver@fp:~/pandas $ cat persones.csv\nnom,edat,ciutat\nAina,25,Val\u00e8ncia\nMar,30,Mislata\nPere,35,Alboraia\n</code></pre>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#informacio-de-les-dades","title":"Informaci\u00f3 de les dades","text":"<p><code>pandas</code> proporciona diverses funcions per a obtindre informaci\u00f3 de les dades.</p> <p>El m\u00e8tode <code>df.info()</code> mostra informaci\u00f3 b\u00e0sica del <code>DataFrame</code>, com ara el nombre de files, columnes, tipus de dades, etc.</p> <p>Exemple</p> <pre><code># Mostrar informaci\u00f3 b\u00e0sica del DataFrame cotxes_df\nprint(\"Informaci\u00f3 b\u00e0sica del DataFrame cotxes_df\")\ncotxes_df.info()\n</code></pre> <pre><code>Informaci\u00f3 b\u00e0sica del DataFrame cotxes_df\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 60 entries, 0 to 59\nData columns (total 3 columns):\n #   Column             Non-Null Count  Dtype \n---  ------             --------------  ----- \n 0   marca              60 non-null     object\n 1   km                 60 non-null     int64 \n 2   data_matriculacio  60 non-null     object\ndtypes: int64(1), object(2)\nmemory usage: 1.5+ KB\n</code></pre> <p>El m\u00e8tode <code>df.head()</code> les primeres files del <code>DataFrame</code>.</p> <ul> <li>El par\u00e0metre <code>n</code> indica el nombre de files a mostrar,     que per defecte \u00e9s 5.</li> </ul> <p>Exemple</p> <pre><code># Mostrar les primeres files del DataFrame cotxes_df\nprint(\"Primeres files del DataFrame cotxes_df\")\nprint(cotxes_df.head())\n</code></pre> <pre><code>Primeres files del DataFrame cotxes_df\nPrimeres files del DataFrame cotxes_df\n    marca     km data_matriculacio\n0        Ford  39031        08/12/2000\n1        Seat  10542        02/01/2001\n2  Volkswagen   8065        02/04/2001\n3     Peugeot  48623        28/11/2001\n4        Audi  57737        05/12/2001\n</code></pre> <p>El m\u00e8tode <code>df.tail()</code> les \u00faltimes files del <code>DataFrame</code>.</p> <ul> <li>El par\u00e0metre <code>n</code> indica el nombre de files a mostrar,     que per defecte \u00e9s 5.</li> </ul> <p>Exemple</p> <pre><code># Mostrar les \u00faltimes files del DataFrame cotxes_df\nprint(\"\u00daltimes files del DataFrame cotxes_df\")\nprint(cotxes_df.tail())\n</code></pre> <pre><code>\u00daltimes files del DataFrame cotxes_df\n       marca     km data_matriculacio\n55      Seat  15734        15/07/2015\n56      Fiat  18358        06/11/2002\n57   Porsche  19791        02/01/2012\n58    Nissan  18722        02/04/2001\n59  Mercedes  48813        10/03/2005\n</code></pre>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#acces-a-les-dades","title":"Acc\u00e9s a les dades","text":"","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#acces-a-les-columnes","title":"Acc\u00e9s a les columnes","text":"<p>Es pot accedir a les dades d'una columna del <code>DataFrame</code> de dues maneres:</p> <ul> <li>Amb l'operador <code>[]</code>.</li> <li>Com un atribut de l'objecte <code>DataFrame</code>.</li> </ul> <p>En cas que s'accedisca a una sola columna, el resultat \u00e9s una <code>Series</code>.</p> <p>Exemple</p> <pre><code># Accedir a la columna 'marca' del DataFrame cotxes_df\nprint(\"Columna 'marca' del DataFrame cotxes_df\")\nprint(\"Amb []\")\nprint(cotxes_df['marca'].head(2))\nprint(\"Com atribut\")\nprint(cotxes_df.marca.head(2))\nprint()\n</code></pre> <pre><code>Columna 'marca' del DataFrame cotxes_df\nAmb []\n0    Ford\n1    Seat\nName: marca, dtype: object\nCom atribut\n0    Ford\n1    Seat\nName: marca, dtype: object\n</code></pre> <p>Tamb\u00e9 es pot accedir a m\u00e9s d'una columna del <code>DataFrame</code> utilitzant l'operador <code>[]</code>, indicant la llista de les etiquetes.</p> <p>Exemple</p> <pre><code># Accedir a les columnes 'marca' i 'km' del DataFrame cotxes_df\nprint(\"Columnes 'marca' i 'km' del DataFrame cotxes_df\")\nprint(cotxes_df[['marca', 'km']].head(2))\n</code></pre> <pre><code>Columnes 'marca' i 'km' del DataFrame cotxes_df\n  marca     km\n0  Ford  39031\n1  Seat  10542\n</code></pre>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#acces-a-les-files-per-index","title":"Acc\u00e9s a les files per \u00edndex","text":"<p>Es pot accedir a les dades d'una fila del <code>DataFrame</code> amb la funci\u00f3 <code>df.loc[]</code>.</p> <p>El primer par\u00e0metre de la funci\u00f3 <code>loc</code> \u00e9s l'\u00edndex de la fila (no necess\u00e0riament num\u00e8ric) o una condici\u00f3.</p> <ul> <li><code>df.loc[n]</code>: Accedeix a la fila amb \u00edndex <code>n</code>.</li> <li><code>df.loc[[n1, n2, ...]]</code>: Accedeix a les files amb \u00edndexs <code>n1</code>, <code>n2</code>, ...</li> <li><code>df.loc[n:m]</code>: Accedeix a les files amb \u00edndexs de <code>n</code> a <code>m</code>.</li> <li><code>df.loc[condicio]</code>: Accedeix a les files que compleixen la condici\u00f3.</li> </ul> <p>El segon par\u00e0metre de la funci\u00f3 <code>loc</code> \u00e9s l'etiqueta de la columna que volem obtindre.</p> <ul> <li><code>df.loc[param1, 'columna']</code>: Accedeix a la columna <code>columna</code> de la fila especificada.</li> <li><code>df.loc[param1, ['columna1', 'columna2']]</code>: Accedeix a les columnes <code>columna1</code> i <code>columna2</code> de la fila especificada.</li> </ul> <p>Exemple</p> <pre><code># Accedir a la fila amb \u00edndex 0 del DataFrame cotxes_df\nprint(\"Fila amb \u00edndex 0 del DataFrame cotxes_df\")\nprint(cotxes_df.loc[0])\nprint()\n\n# Accedir a les files amb \u00edndex 0 i 2 del DataFrame cotxes_df\nprint(\"Files amb \u00edndex 0 i 2 del DataFrame cotxes_df\")\nprint(cotxes_df.loc[[0, 2]])\nprint()\n\n# Accedir a les files amb \u00edndex 0 i 2 i a les columnes 'marca' i 'km' del DataFrame cotxes_df\nprint(\"Files amb \u00edndex 0 fins 2 i columnes 'marca' i 'km' del DataFrame cotxes_df\")\nprint(cotxes_df.loc[0:2, ['marca', 'km']])\nprint()\n</code></pre> <pre><code>Fila amb \u00edndex 0 del DataFrame cotxes_df\nmarca                      Ford\nkm                        39031\ndata_matriculacio    08/12/2000\nName: 0, dtype: object\n\nFiles amb \u00edndex 0 i 2 del DataFrame cotxes_df\n        marca     km data_matriculacio\n0        Ford  39031        08/12/2000\n2  Volkswagen   8065        02/04/2001\n\nFiles amb \u00edndex 0 fins 2 i columnes 'marca' i 'km' del DataFrame cotxes_df\n        marca     km\n0        Ford  39031\n1        Seat  10542\n2  Volkswagen   8065\n</code></pre>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#acces-a-les-files-per-posicio","title":"Acc\u00e9s a les files per posici\u00f3","text":"<p>Es pot accedir a les dades d'una fila del <code>DataFrame</code> mitjan\u00e7ant la seua posici\u00f3 amb la funci\u00f3 <code>df.iloc[]</code>.</p> <p>El funcionament \u00e9s pr\u00e0cticament igual que amb <code>loc</code>, per\u00f2 en aquest cas s'utilitza la posici\u00f3 num\u00e8rica de la fila en compte de l'\u00edndex (que pot ser num\u00e8ric o no).</p>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#acces-condicional","title":"Acc\u00e9s condicional","text":"<p>Es pot accedir a les dades del <code>DataFrame</code> utilitzant condicions l\u00f2giques, que permet filtrar les dades.</p> <p>Utilitzem l'operador <code>[]</code> amb una condici\u00f3 per a filtrar les dades.</p> <p>Exemple</p> <pre><code># Filtrar els cotxes amb 'km' major que 70000\nprint(\"Cotxes amb m\u00e9s de 100000 km\")\nprint(cotxes_df.loc[cotxes_df['km'] &gt; 70000])\nprint()\n\n# Filtrar els cotxes de la marca 'Ford' amb 'km' menor que 50000\nprint(\"Cotxes de la marca 'Ford' amb menys de 50000 km\")\nprint(cotxes_df.loc[(cotxes_df['marca'] == 'Ford') &amp; (cotxes_df['km'] &lt; 50000)])\nprint()\n</code></pre> <pre><code>Cotxes amb m\u00e9s de 100000 km\n           marca     km data_matriculacio\n26  Mercedes  72868        04/06/2001\n50      Audi  70279        19/01/2001\n\nCotxes de la marca 'Ford' amb menys de 50000 km\n  marca     km data_matriculacio\n0  Ford  39031        08/12/2000\n</code></pre>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#modificacio-de-les-dades","title":"Modificaci\u00f3 de les dades","text":"<p><code>pandas</code> permet diferents operacions per a modificar les dades d'un <code>DataFrame</code>.</p>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#modificar-una-columna","title":"Modificar una columna","text":"<p>Es pot modificar una columna del <code>DataFrame</code> amb l'operador <code>[]</code>.</p> <pre><code># Assignar un valor constant a tota la columna\ndf['nom_columna'] = 10\n\n# Aplicar una operaci\u00f3 a la columna\ndf['nom_columna'] = df['nom_columna'] * 2\n</code></pre> <p>Important</p> <p>Si la columna especificada no existeix, es crea una columna nova.</p>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#eliminar-una-columna","title":"Eliminar una columna","text":"<p>Es pot eliminar una columna del <code>DataFrame</code> amb el m\u00e8tode <code>df.drop()</code>.</p> <pre><code># Eliminar la columna 'nom_columna'\ndf.drop(columns=['nom_columna'], inplace=True)\n\n# O utilitzant axis=1\ndf.drop('nom_columna', axis=1, inplace=True)\n</code></pre> <p>Info</p> <p>El par\u00e0metre <code>inplace=True</code> fa que la modificaci\u00f3 es realitze sobre el mateix <code>DataFrame</code>.</p> <p>En cas de especificar <code>inplace=False</code> (per defecte), el m\u00e8tode <code>drop</code> retorna un nou <code>DataFrame</code> amb la modificaci\u00f3.</p>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#modificar-una-fila","title":"Modificar una fila","text":"<p>Es pot modificar una fila del <code>DataFrame</code> amb el m\u00e8tode <code>df.loc[]</code>.</p> <pre><code># Modificar la fila amb \u00edndex 0\ndf.loc[0] = ['nou_valor', 100, '01/01/2022']\n</code></pre>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#eliminar-una-fila","title":"Eliminar una fila","text":"<p>Es pot eliminar una fila del <code>DataFrame</code> amb el m\u00e8tode <code>df.drop()</code> utilitzant el par\u00e0metre <code>axis=0</code> (per defecte).</p> <pre><code># Eliminar la fila amb \u00edndex 0\ndf.drop(0, axis=0, inplace=True)\n</code></pre>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#modificar-una-cella","title":"Modificar una cel\u00b7la","text":"<p>Es pot modificar una cel\u00b7la concreta del <code>DataFrame</code> amb el m\u00e8tode <code>df.loc[]</code>, utilitzant l'\u00edndex de la fila i el nom de la columna.</p> <pre><code># Modificar la cel\u00b7la de la fila amb \u00edndex 0 i la columna 'A'\ndf.loc[0, 'A'] = 'nou_valor'\n</code></pre>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#afegir-una-fila","title":"Afegir una fila","text":"<p>Es pot afegir una fila al <code>DataFrame</code> amb el m\u00e8tode <code>df.concat()</code>.</p> <pre><code>files = pd.Series()\n# o b\u00e9\nfiles = pd.DataFrame()\n\n# Afegir les files al final del DataFrame\ndf = pd.concat([df, files], axis=0)\n</code></pre> <p>Info</p> <p>Tamb\u00e9 es poden afegir columnes amb <code>axis=1</code>.</p>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#funcions-dagregacio","title":"Funcions d'agregaci\u00f3","text":"<p><code>pandas</code> incorpora diverses funcions d'agregaci\u00f3 per a realitzar c\u00e0lculs sobre les dades.</p> <p>El m\u00e8tode <code>max()</code> retorna el valor m\u00e0xim de cada columna.</p> <p>El m\u00e8tode <code>min()</code> retorna el valor m\u00ednim de cada columna.</p> <pre><code># Valor m\u00ednim i m\u00e0xim de cada columna\ndf.min()\ndf.max()\n\n# Valor m\u00ednim i m\u00e0xim d'una columna concreta\ndf['nom_columna'].min()\ndf['nom_columna'].max()\n</code></pre> <p>El m\u00e8tode <code>sum()</code> retorna la suma de cada columna.</p> <pre><code># Suma de cada columna\ndf.sum()\n\n# Suma d'una columna concreta\ndf['nom_columna'].sum()\n</code></pre> <p>El m\u00e8tode <code>mean()</code> retorna la mitjana aritm\u00e8tica de cada columna.</p> <pre><code># Mitjana de cada columna\ndf.mean()\n\n# Mitjana d'una columna concreta\ndf['nom_columna'].mean()\n</code></pre>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#agrupacio-de-les-dades","title":"Agrupaci\u00f3 de les dades","text":"<p><code>pandas</code> permet agrupar les dades segons els valors d'una o m\u00e9s columnes, mitjan\u00e7ant el m\u00e8tode <code>df.groupby()</code>.</p> <p>Despr\u00e9s, \u00e9s possible aplicar funcions d'agregaci\u00f3 per a obtindre informaci\u00f3 de les dades agrupades.</p> <p>Exemple</p> <pre><code># Agrupar les dades per la columna 'marca' i calcular la mitjana dels 'km'\nmean = cotxes_df.groupby('marca')['km'].mean()\nprint(\"Mitjana dels km per marca\")\nprint(mean)\n</code></pre> <pre><code>Mitjana dels km per marca\nmarca\nAlfa Romeo    45899.857143\nAudi          60097.333333\nBMW           35245.000000\nFerrari       34201.000000\nFiat          35642.333333\nFord          39031.000000\nKia           44016.500000\nMercedes      49078.000000\nNissan        21125.333333\nPeugeot       48423.125000\nPorsche       28426.400000\nRenault       51360.666667\nSeat          29210.666667\nToyota        33753.000000\nVolkswagen    18710.333333\nName: km, dtype: float64\n</code></pre>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#dades-nulles-o-invalides","title":"Dades nul\u00b7les o inv\u00e0lides","text":"<p><code>pandas</code> proporciona funcions per a tractar les dades nul\u00b7les o inv\u00e0lides (com <code>NaN</code>).</p> <p>El m\u00e8tode <code>isnull()</code> retorna <code>True</code> si la dada \u00e9s nul\u00b7la o inv\u00e0lida.</p> <pre><code># Comprovar el nombre de dades nul\u00b7les per columna\ndf.isnull().sum()\n</code></pre> <p>El m\u00e8tode <code>dropna()</code> permet eliminar les files amb dades nul\u00b7les.</p> <pre><code># Eliminar les files amb dades nul\u00b7les\ndf.dropna(inplace=True)\n</code></pre>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#codi-font","title":"Codi font","text":"<ul> <li><code>cotxes.csv</code></li> <li> <p><code>pandas_example.py</code></p> <pre><code>#!/usr/bin/env python\n\nimport pandas as pd\n\n# Crear una Series amb una llista\na = [1, 3, 5, 7, 9]\ns = pd.Series(a)\nprint(\"Series amb una llista\")\nprint(s)\nprint()\n\n# Crear una Series amb un diccionari\nd = {'a': 1, 'b': 3, 'c': 5, 'd': 7, 'e': 9}\ns = pd.Series(d)\nprint(\"Series amb un diccionari\")\nprint(s)\nprint()\n\n# Crear una Series amb un valor escalar\ns = pd.Series(5, index=[0, 1, 2, 3, 4])\nprint(\"Series amb un valor escalar\")\nprint(s)\nprint()\n\n# Crear un DataFrame amb una llista\na = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\ndf = pd.DataFrame(a)\nprint(\"DataFrame amb una llista\")\nprint(df)\nprint()\n\n# Crear un Dataframe amb una llista, indicant els noms de les columnes\ndf = pd.DataFrame(a, columns=['A', 'B', 'C'])\nprint(\"DataFrame amb una llista i noms de columnes\")\nprint(df)\nprint()\n\n# Crear un DataFrame amb un diccionari\nd = {'A': [1, 4, 7], 'B': [2, 5, 8], 'C': [3, 6, 9]}\ndf = pd.DataFrame(d)\nprint(\"DataFrame amb un diccionari\")\nprint(df)\nprint()\n\n# Crear un DataFrame a partir d'un fitxer CSV\ncotxes_df = pd.read_csv('../../files/ud3/cotxes.csv')\nprint(\"DataFrame a partir d'un fitxer CSV\")\nprint(cotxes_df)\nprint()\n\n# Guardar un DataFrame en un fitxer CSV\npersones_df = pd.DataFrame({\n    'nom': ['Aina', 'Mar', 'Pere'],\n    'edat': [25, 30, 35],\n    'ciutat': ['Val\u00e8ncia', 'Mislata', 'Alboraia']\n})\npersones_df.to_csv('../../files/ud3/persones.csv', index=False)\n\n# Mostrar informaci\u00f3 b\u00e0sica del DataFrame cotxes_df\nprint(\"Informaci\u00f3 b\u00e0sica del DataFrame cotxes_df\")\ncotxes_df.info()\nprint()\n\n# Mostrar les primeres files del DataFrame cotxes_df\nprint(\"Primeres files del DataFrame cotxes_df\")\nprint(cotxes_df.head())\nprint()\n\n# Mostrar les \u00faltimes files del DataFrame cotxes_df\nprint(\"\u00daltimes files del DataFrame cotxes_df\")\nprint(cotxes_df.tail())\nprint()\n\n# Accedir a la columna 'marca' del DataFrame cotxes_df\nprint(\"Columna 'marca' del DataFrame cotxes_df\")\nprint(\"Amb []\")\nprint(cotxes_df['marca'].head(2))\nprint(\"Com atribut\")\nprint(cotxes_df.marca.head(2))\nprint()\n\n# Accedir a les columnes 'marca' i 'km' del DataFrame cotxes_df\nprint(\"Columnes 'marca' i 'km' del DataFrame cotxes_df\")\nprint(cotxes_df[['marca', 'km']].head(2))\nprint()\n\n# Accedir a la fila amb \u00edndex 0 del DataFrame cotxes_df\nprint(\"Fila amb \u00edndex 0 del DataFrame cotxes_df\")\nprint(cotxes_df.loc[0])\nprint()\n\n# Accedir a les files amb \u00edndex 0 i 2 del DataFrame cotxes_df\nprint(\"Files amb \u00edndex 0 i 2 del DataFrame cotxes_df\")\nprint(cotxes_df.loc[[0, 2]])\nprint()\n\n# Accedir a les files amb \u00edndex 0 i 2 i a les columnes 'marca' i 'km' del DataFrame cotxes_df\nprint(\"Files amb \u00edndex 0 fins 2 i columnes 'marca' i 'km' del DataFrame cotxes_df\")\nprint(cotxes_df.loc[0:2, ['marca', 'km']])\nprint()\n\n# Filtrar els cotxes amb 'km' major que 70000\nprint(\"Cotxes amb m\u00e9s de 100000 km\")\nprint(cotxes_df.loc[cotxes_df['km'] &gt; 70000])\nprint()\n\n# Filtrar els cotxes de la marca 'Ford' amb 'km' menor que 50000\nprint(\"Cotxes de la marca 'Ford' amb menys de 50000 km\")\nprint(cotxes_df.loc[(cotxes_df['marca'] == 'Ford') &amp; (cotxes_df['km'] &lt; 50000)])\nprint()\n\n# Agrupar les dades per la columna 'marca' i calcular la mitjana dels 'km'\nmean = cotxes_df.groupby('marca')['km'].mean().sort_values(ascending=False)\nprint(\"Mitjana dels km per marca\")\nprint(mean)\nprint()\n</code></pre> </li> </ul>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/01_pandas/#bibliografia-i-recursos-addicionals","title":"Bibliografia i recursos addicionals","text":"<ul> <li>Material del m\u00f2dul \"Sistemes d'Aprenentatge Autom\u00e0tic\" de C\u00e9sar Guijarro Rosaleny</li> <li>Documentaci\u00f3 oficial de Pandas</li> <li>Llibre \"pandas: powerful Python data analysis toolkit\"</li> <li>Practical Tutorial on Data Manipulation with Numpy and Pandas in Python</li> <li>12 Amazing Pandas &amp; NumPy Functions</li> <li>Cleaning Your Data Using Pandas</li> <li>Pandas Data Wrangling Cheat Sheet 2021</li> <li>An\u00e1lisis Exploratorio de Datos (EDA) con pandas_profiling</li> <li>Error-free import of CSV files using Pandas DataFrame</li> <li>10 Tricks for Converting Numbers and Strings to Datetime in Pandas</li> <li>Be a more efficient data analyst, a comprehensive guide to pandas</li> <li>Differences Between concat(), merge() and join() with Python</li> <li>Simple ways to manipulate datetime variables with pandas</li> </ul>","tags":["pandas","manipulaci\u00f3 de dades"]},{"location":"apunts/03_manipulacio_dades/020_plotnine/","title":"Visualitzaci\u00f3 de les dades amb Plotnine","text":"","tags":["plotnine","visualitzaci\u00f3 de dades","gr\u00e0fics"]},{"location":"apunts/03_manipulacio_dades/020_plotnine/#visualitzacio-de-les-dades-amb-plotnine","title":"Visualitzaci\u00f3 de les dades amb Plotnine","text":"<p><code>plotnine</code> \u00e9s una llibreria de Python que permet crear gr\u00e0fics de dades de manera senzilla i elegant, inspirada en la llibreria de R <code>ggplot2</code>.</p> <p>Altres llibreries de Python per a la visualitzaci\u00f3 de dades s\u00f3n:</p> <ul> <li><code>matplotlib</code></li> <li><code>seaborn</code></li> </ul>","tags":["plotnine","visualitzaci\u00f3 de dades","gr\u00e0fics"]},{"location":"apunts/03_manipulacio_dades/020_plotnine/#installacio","title":"Instal\u00b7laci\u00f3","text":"<p>Per instal\u00b7lar la llibreria <code>plotnine</code> amb <code>pip</code>:</p> <pre><code>pip install plotnine\n</code></pre>","tags":["plotnine","visualitzaci\u00f3 de dades","gr\u00e0fics"]},{"location":"apunts/03_manipulacio_dades/020_plotnine/#importacio","title":"Importaci\u00f3","text":"<p>Per importar la llibreria <code>plotnine</code>:</p> <pre><code>from plotnine import *\n</code></pre>","tags":["plotnine","visualitzaci\u00f3 de dades","gr\u00e0fics"]},{"location":"apunts/03_manipulacio_dades/020_plotnine/#utilitzacio","title":"Utilitzaci\u00f3","text":"<p>La llibreria es basa en diferents objectes per a la creaci\u00f3 de gr\u00e0fics:</p> <ul> <li><code>ggplot</code>: objecte principal que cont\u00e9 les dades i les capes del gr\u00e0fic.</li> <li><code>aes</code>: objecte que defineix les variables est\u00e8tiques del gr\u00e0fic.</li> <li><code>geom</code>: objecte que defineix la geometria del gr\u00e0fic.</li> <li><code>theme</code>: objecte que defineix el tema del gr\u00e0fic.</li> </ul> <p>Documentaci\u00f3</p> <p>Documentaci\u00f3 oficial de <code>plotnine</code></p> <p>Exemple</p> <pre><code>from plotnine import ggplot, geom_point, aes\nfrom plotnine.data import mtcars\n\nprint(\"Dades `mtcars`:\")\nprint(mtcars)\n\nplot = (\n    ggplot(mtcars)\n    + aes(\"wt\", \"mpg\", color=\"factor(gear)\")\n    + geom_point()\n)\n\nplot.show()\n</code></pre> <p></p> <p>Figura 1. Exemple b\u00e0sic amb <code>plotnine</code>.</p> <ol> <li>Creaci\u00f3 d'un objecte <code>ggplot</code> amb les dades <code>mtcars</code>.</li> <li>Definici\u00f3 de les variables est\u00e8tiques amb <code>aes</code>.<ul> <li>Sobre l'eix X: <code>wt</code> (pes del vehicle).</li> <li>Sobre l'eix Y: <code>mpg</code> (consum del vehicle).</li> <li>Color: <code>gear</code> (nombre de marxes).</li> </ul> </li> <li>Definici\u00f3 de la geometria amb <code>geom_point</code>.<ul> <li>Cada punt representa un vehicle.</li> </ul> </li> </ol>","tags":["plotnine","visualitzaci\u00f3 de dades","gr\u00e0fics"]},{"location":"apunts/03_manipulacio_dades/020_plotnine/#estetica-aes","title":"Est\u00e8tica (<code>aes</code>)","text":"<p>L'est\u00e8tica control les propietats visuals d'una gr\u00e0fica. Aquestes funcions controlen com es mostren i distribueixen les dades (i els c\u00e0lculs basats en aquestes).</p> <p>La funci\u00f3 principal per a definir l'est\u00e8tica \u00e9s <code>aes</code>.</p> <pre><code>aes(x, y, **kwargs)\n</code></pre> <ul> <li><code>x</code>: dades utilitzades per a l'eix X.</li> <li><code>y</code>: dades utilitzades per a l'eix Y.</li> </ul> <p>Info</p> <p>Els par\u00e0metres <code>x</code> i <code>y</code> poden rebre m\u00faltiples tipus de dades. Podeu consultar-ho a la documentaci\u00f3 oficial.</p> <p>Documentaci\u00f3</p> <p>Documentaci\u00f3 oficial de la <code>aes</code>.</p> <p>Altres par\u00e0metres comuns s\u00f3n:</p> <ul> <li><code>color</code>: color dels elements.</li> <li><code>fill</code>: color de fons dels elements.</li> </ul>","tags":["plotnine","visualitzaci\u00f3 de dades","gr\u00e0fics"]},{"location":"apunts/03_manipulacio_dades/020_plotnine/#geometria-geom","title":"Geometria (<code>geom</code>)","text":"<p>La geometria controla el format amb que es presenten les dades.</p> <p>Documentaci\u00f3</p> <p>Documentaci\u00f3 oficial de la geometria.</p> <p><code>plotnine</code> ofereix diferents tipus de geometries, que venen definides per funcions amb el prefix <code>geom_</code>. Podeu consultar la llista completa a la documentaci\u00f3 oficial.</p> <p>Els tipus de geometries m\u00e9s comuns s\u00f3n:</p> <ul> <li><code>geom_point</code>: punts.</li> <li><code>geom_line</code>: l\u00ednies.</li> <li><code>geom_bar</code>: barres.</li> <li><code>geom_boxplot</code>: diagrama de caixes.</li> </ul> <p>Exemple amb punts</p> <p>La Figura 1 mostra un exemple b\u00e0sic amb <code>geom_point</code>.</p> <p>Exemple amb l\u00ednies</p> <p>Info</p> <p>La funci\u00f3 <code>factor()</code> converteix una variable num\u00e8rica en una variable categ\u00f2rica.</p> <pre><code>plot = (\n    ggplot(mtcars)\n    + aes(\"wt\", \"mpg\", color=\"factor(gear)\")\n    + geom_line()\n)\n\nplot.show()\n</code></pre> <p></p> <p>Figura 2. Exemple b\u00e0sic amb <code>geom_line</code>.</p> <p>Exemple amb barres</p> <pre><code>bar_plot = (\n    ggplot(mtcars)\n    + aes(x='factor(cyl)', fill='factor(gear)')\n    + geom_bar()\n)\n\nbar_plot.show()\n</code></pre> <p></p> <p>Figura 3. Exemple b\u00e0sic amb <code>geom_bar</code>.</p>","tags":["plotnine","visualitzaci\u00f3 de dades","gr\u00e0fics"]},{"location":"apunts/03_manipulacio_dades/020_plotnine/#titol-i-etiquetes","title":"T\u00edtol i etiquetes","text":"<p>Es pot especificar el t\u00edtol del gr\u00e0fic amb la funci\u00f3 <code>ggtitle</code>.</p> <p>Documentaci\u00f3</p> <p>Documentaci\u00f3 oficial de la funci\u00f3 <code>ggtitle</code>.</p> <p>Tamb\u00e9 es pot afegir etiquetes als eixos X i Y amb les funcions:</p> <ul> <li><code>labs</code>: Permet especificar el t\u00edtol i les etiquetes dels eixos X i Y i altres elements.</li> <li><code>xlab</code>: etiqueta de l'eix X.</li> <li><code>ylab</code>: etiqueta de l'eix Y.</li> </ul> <p>Exemple amb t\u00edtol i etiquetes</p> <pre><code>plot = (\n    ggplot(mtcars)\n    + aes(\"wt\", \"mpg\", color=\"factor(gear)\")\n    + geom_point()\n    + labs(title=\"Consum (wt) vs Pes (mpg)\",\n           x=\"Pes en lliures\",\n           y=\"Consum en milles per gal\u00f3\",\n           color=\"Nombre de marxes\"\n    )\n)\n\nplot.show()\n</code></pre> <p></p> <p>Figura 4. Exemple amb t\u00edtol i etiquetes.</p>","tags":["plotnine","visualitzaci\u00f3 de dades","gr\u00e0fics"]},{"location":"apunts/03_manipulacio_dades/020_plotnine/#temes","title":"Temes","text":"<p>Es poden utilitzar diferents temes per a personalitzar l'aparen\u00e7a del gr\u00e0fic.</p> <p>Documentaci\u00f3</p> <p>Documentaci\u00f3 oficial dels temes.</p> <p>Per a utilitzar un tema, s'ha d'afegir la funci\u00f3 <code>theme</code> al gr\u00e0fic.</p> <p>Exemple amb el tema fosc</p> <pre><code>plot = (\n    ggplot(mtcars)\n    + aes(\"wt\", \"mpg\", color=\"factor(gear)\")\n    + geom_point()\n    + labs(title=\"Consum (wt) vs Pes (mpg)\",\n           x=\"Pes en lliures\",\n           y=\"Consum en milles per gal\u00f3\",\n           color=\"Nombre de marxes\"\n    )\n    + theme_dark()\n)\n\nplot.show()\n</code></pre> <p></p> <p>Figura 5. Exemple amb tema fosc.</p>","tags":["plotnine","visualitzaci\u00f3 de dades","gr\u00e0fics"]},{"location":"apunts/03_manipulacio_dades/020_plotnine/#multiples-grafics-facets","title":"M\u00faltiples gr\u00e0fics (facets)","text":"<p>Els gr\u00e0fics poden ser dividits en diferents subgr\u00e0fics segons els valors d'una variable amb dues funcions:</p> <ul> <li><code>facet_wrap</code>: divideix el gr\u00e0fic en subgr\u00e0fics en funci\u00f3 d'una variable.</li> <li><code>facet_grid</code>: divideix el gr\u00e0fic en subgr\u00e0fics en funci\u00f3 de dues o m\u00e9s variables.</li> </ul> <p>Exemple amb <code>facet_wrap</code></p> <pre><code>facet_plot = (\n    ggplot(mtcars)\n    + aes(\"wt\", \"mpg\", color=\"factor(gear)\")\n    + geom_point()\n    + facet_wrap(\"gear\")\n    + labs(title=\"Consum (wt) vs Pes (mpg)\",\n        x=\"Pes en lliures\",\n        y=\"Consum en milles per gal\u00f3\",\n        color=\"Nombre de marxes\"\n    )\n)\nfacet_plot.show()\n</code></pre> <p></p> <p>Figura 6. Diferents gr\u00e0fics per nombre de marxes.</p> <p>Exemple amb <code>facet_grid</code></p> <pre><code>facet_grid_plot = (\n    ggplot(mtcars)\n    + aes(\"wt\", \"mpg\", color=\"factor(gear)\")\n    + geom_point()\n    + facet_grid(\"gear\", \"cyl\", labeller=\"label_both\")\n    + labs(title=\"Consum (wt) vs Pes (mpg)\",\n           x=\"Pes en lliures\",\n           y=\"Consum en milles per gal\u00f3\",\n           color=\"Nombre de marxes\"\n    )\n)\nfacet_grid_plot.show()\n</code></pre> <p></p> <p>Figura 7. Diferents gr\u00e0fics per nombre de marxes i cilindres.</p>","tags":["plotnine","visualitzaci\u00f3 de dades","gr\u00e0fics"]},{"location":"apunts/03_manipulacio_dades/020_plotnine/#codi-font","title":"Codi font","text":"plotnine_example.py<pre><code>#!/usr/bin/env python\n\nfrom plotnine import *\nfrom plotnine.data import mtcars\n\nprint(\"Dades `mtcars`:\")\nprint(mtcars)\n\ndef regular_plot():\n    plot = (\n        ggplot(mtcars)\n        + aes(\"wt\", \"mpg\", color=\"factor(gear)\")\n        + geom_point()\n        + labs(title=\"Consum (wt) vs Pes (mpg)\",\n               x=\"Pes en lliures\",\n               y=\"Consum en milles per gal\u00f3\",\n               color=\"Nombre de marxes\"\n        )\n        + theme_dark()\n    )\n\n    plot.show()\n\ndef line_plot():\n    line_plot = (\n        ggplot(mtcars)\n        + aes(x='wt', y='mpg', color='factor(gear)')\n        + geom_line()\n    )\n\n    line_plot.show()\n\ndef bar_plot():\n    bar_plot = (\n        ggplot(mtcars)\n        + aes(x='factor(cyl)', fill='factor(gear)')\n        + geom_bar()\n    )\n\n    bar_plot.show()\n\ndef facet_wrap_plot():\n    facet_plot = (\n        ggplot(mtcars)\n        + aes(\"wt\", \"mpg\", color=\"factor(gear)\")\n        + geom_point()\n        + facet_wrap(\"gear\")\n        + labs(title=\"Consum (wt) vs Pes (mpg)\",\n               x=\"Pes en lliures\",\n               y=\"Consum en milles per gal\u00f3\",\n               color=\"Nombre de marxes\"\n        )\n    )\n\n    facet_plot.show()\n\ndef facet_grid_plot():\n    facet_grid_plot = (\n        ggplot(mtcars)\n        + aes(\"wt\", \"mpg\", color=\"factor(gear)\")\n        + geom_point()\n        + facet_grid(\"gear\", \"cyl\", labeller=\"label_both\")\n        + labs(title=\"Consum (wt) vs Pes (mpg)\",\n               x=\"Pes en lliures\",\n               y=\"Consum en milles per gal\u00f3\",\n               color=\"Nombre de marxes\"\n        )\n    )\n\n    facet_grid_plot.show()\n\n# simple_plot()\n# line_plot()\n# bar_plot()\n# facet_wrap_plot()\nfacet_grid_plot()\n</code></pre>","tags":["plotnine","visualitzaci\u00f3 de dades","gr\u00e0fics"]},{"location":"apunts/03_manipulacio_dades/020_plotnine/#bibliografia","title":"Bibliografia","text":"<ul> <li>Material del m\u00f2dul \"Sistemes d'Aprenentatge Autom\u00e0tic\" de C\u00e9sar Guijarro Rosaleny</li> <li>Documentaci\u00f3 oficial de <code>plotnine</code></li> <li>StackOverflow: What's the difference between facet_wrap() and facet_grid() in ggplot2?</li> </ul>","tags":["plotnine","visualitzaci\u00f3 de dades","gr\u00e0fics"]},{"location":"apunts/03_manipulacio_dades/021_exercicis_plotnine/","title":"Exercicis amb Plotnine","text":""},{"location":"apunts/03_manipulacio_dades/021_exercicis_plotnine/#exercicis-amb-plotnine","title":"Exercicis amb Plotnine","text":"<p>A partir del conjunt de dades 120 years of Olympic history: athletes and results, realitza els seg\u00fcents exercicis amb la llibreria <code>plotnine</code>.</p> <p>Info</p> <p>Podeu descarregar-se el dataset des de aquest enlla\u00e7.</p>"},{"location":"apunts/03_manipulacio_dades/021_exercicis_plotnine/#exercici-1-medalles-de-xina","title":"Exercici 1: Medalles de Xina","text":""},{"location":"apunts/03_manipulacio_dades/021_exercicis_plotnine/#exercici-1a","title":"Exercici 1.a","text":"<p>Crea un gr\u00e0fic de barres que mostre el nombre de medalles guanyades pels atletes de la Xina en cada esport.</p>"},{"location":"apunts/03_manipulacio_dades/021_exercicis_plotnine/#exercici-1b","title":"Exercici 1.b","text":"<p>Modifica el gr\u00e0fic anterior perqu\u00e8 es diferencien les medalles canviant el color segons el tipus.</p>"},{"location":"apunts/03_manipulacio_dades/021_exercicis_plotnine/#exercici-1c","title":"Exercici 1.c","text":"<p>Fes les modificacions necess\u00e0ries perqu\u00e8 el gr\u00e0fic de l'exercici anterior quede semblant a aquest:</p> <p></p>"},{"location":"apunts/03_manipulacio_dades/021_exercicis_plotnine/#exercici-1d","title":"Exercici 1.d","text":"<p>Modifica el gr\u00e0fic anterior per ordenar els esports segons el nombre de medalles guanyades, seguint el seg\u00fcent criteri:</p> <ul> <li>Ordenar descendentment segons el nombre de medalles d'or.</li> <li>En cas d'empat, ordenar descendentment segons el nombre de medalles de plata.</li> <li>En cas d'empat, ordenar descendentment segons el nombre de medalles de bronze.</li> <li>En cas d'empat, ordenar alfab\u00e8ticament segons el nom de l'esport.</li> </ul> <p></p>"},{"location":"apunts/03_manipulacio_dades/021_exercicis_plotnine/#exercici-2-medalles-de-russia","title":"Exercici 2: Medalles de R\u00fassia","text":""},{"location":"apunts/03_manipulacio_dades/021_exercicis_plotnine/#exercici-2a","title":"Exercici 2.a","text":"<p>Crea un gr\u00e0fic de barres apilades que mostre la distribuci\u00f3 de les medalles guanyades pels atletes de R\u00fassia per any i g\u00e8nere.</p> <p>Crea els gr\u00e0fics separats en dues columnes.</p>"},{"location":"apunts/03_manipulacio_dades/021_exercicis_plotnine/#exercici-2b","title":"Exercici 2.b","text":"<p>Modifica el gr\u00e0fic anterior per mostrar els gr\u00e0fics en 2 files separades.</p>"},{"location":"apunts/03_manipulacio_dades/021_exercicis_plotnine/#exercici-2c","title":"Exercici 2.c","text":"<p>Modifica el gr\u00e0fic anterior per mostrar les columnes de medallistes homes i dones en el mateix gr\u00e0fic.</p>"},{"location":"apunts/03_manipulacio_dades/021_exercicis_plotnine/#exercici-2d","title":"Exercici 2.d","text":"<p>Elimina les medalles guanyades abans de 1994 del gr\u00e0fic anterior.</p>"},{"location":"apunts/03_manipulacio_dades/021_exercicis_plotnine/#exercici-2e","title":"Exercici 2.e","text":"<p>Fes les modificacions necess\u00e0ries perqu\u00e8 el gr\u00e0fic de l'exercici anterior quede semblant a aquest:</p> <p></p>"},{"location":"apunts/03_manipulacio_dades/021_exercicis_plotnine/#exercici-3-participacio-als-jocs-olimpics","title":"Exercici 3: Participaci\u00f3 als Jocs Ol\u00edmpics","text":""},{"location":"apunts/03_manipulacio_dades/021_exercicis_plotnine/#exercici-3a","title":"Exercici 3.a","text":"<p>Crea un gr\u00e0fic de l\u00ednies que mostre com ha evolucionat la quantitat de participants als Jocs Ol\u00edmpics al llarg dels anys similar al seg\u00fcent:</p> <p></p>"},{"location":"apunts/03_manipulacio_dades/021_exercicis_plotnine/#exercici-3b","title":"Exercici 3.b","text":"<p>Pregunta</p> <p>Per qu\u00e8 creus que ixen eixos dents de serra en el gr\u00e0fic anterior?</p> <p>Arregla les dades perqu\u00e8 mostren dades amb m\u00e9s rellev\u00e0ncia estad\u00edstica:</p> <p></p>"},{"location":"apunts/03_manipulacio_dades/021_exercicis_plotnine/#exercici-4-participacio-femenina","title":"Exercici 4: Participaci\u00f3 femenina","text":"<p>Tria 5 esports i mostra la evoluci\u00f3 de la participaci\u00f3 femenina al llarg dels anys amb un gr\u00e0fic:</p> <p></p>"},{"location":"apunts/03_manipulacio_dades/021_exercicis_plotnine/#bibliografia","title":"Bibliografia","text":"<ul> <li>Material del m\u00f2dul \"Sistemes d'Aprenentatge Autom\u00e0tic\" de C\u00e9sar Guijarro Rosaleny</li> </ul>"},{"location":"apunts/03_manipulacio_dades/03_preparacio_dades/","title":"Preparaci\u00f3 de les dades","text":""},{"location":"apunts/03_manipulacio_dades/03_preparacio_dades/#preparacio-de-les-dades","title":"Preparaci\u00f3 de les dades","text":"<p>Quan treballem en la resoluci\u00f3 d'un problema d'aprenentatge autom\u00e0tic, el primer pas fonamental \u00e9s con\u00e8ixer les dades amb les quals treballarem i preparar-les adequadament.</p> <p>Advert\u00e8ncia</p> <p>Treballar amb dades sense cap preparaci\u00f3 impedir\u00e0 obtenir resultats satisfactoris en la majoria dels casos.</p> <p>En aquesta secci\u00f3, veurem com preparar les dades per poder-les utilitzar en els models d'aprenentatge autom\u00e0tic.</p> <p>Conjunt de dades <code>adult-dataset</code></p> <p>En aquests apunts treballarem en el seg\u00fcent conjunt de dades adult-dataset.</p>"},{"location":"apunts/03_manipulacio_dades/03_preparacio_dades/#informacio-sobre-les-dades","title":"Informaci\u00f3 sobre les dades","text":"<p>El primer pas \u00e9s con\u00e8ixer les dades amb les quals treballarem.</p> <p>Podem obtindre informaci\u00f3 sobre les dades utilitzant diferents m\u00e8todes.</p> <p>Els m\u00e8todes <code>head()</code>, <code>tail()</code>, <code>info()</code> vists a Informaci\u00f3 de les dades) ens permeten obtenir una visi\u00f3 general de les dades.</p> Exemple: <code>head()</code>, <code>tail()</code> i <code>info()</code> <pre><code>file_path = \"../../files/ud3/adult.data\"\ndf = pd.read_csv(file_path, header=None)\n\nprint(\"Head of the dataset:\")\nprint(df.head(), \"\\n\")\nprint(\"Tail of the dataset:\")\nprint(df.tail(), \"\\n\")\nprint(\"Info of the dataset:\")\ndf.info()\nprint()\n</code></pre> <pre><code>Head of the dataset:\n   0                  1       2           3   4                    5                   6               7       8        9     10  11  12              13      14\n0  39          State-gov   77516   Bachelors  13        Never-married        Adm-clerical   Not-in-family   White     Male  2174   0  40   United-States   &lt;=50K\n1  50   Self-emp-not-inc   83311   Bachelors  13   Married-civ-spouse     Exec-managerial         Husband   White     Male     0   0  13   United-States   &lt;=50K\n2  38            Private  215646     HS-grad   9             Divorced   Handlers-cleaners   Not-in-family   White     Male     0   0  40   United-States   &lt;=50K\n3  53            Private  234721        11th   7   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male     0   0  40   United-States   &lt;=50K\n4  28            Private  338409   Bachelors  13   Married-civ-spouse      Prof-specialty            Wife   Black   Female     0   0  40            Cuba   &lt;=50K \n\nTail of the dataset:\n       0              1       2            3   4                    5                   6           7       8        9      10  11  12              13      14\n32556  27        Private  257302   Assoc-acdm  12   Married-civ-spouse        Tech-support        Wife   White   Female      0   0  38   United-States   &lt;=50K\n32557  40        Private  154374      HS-grad   9   Married-civ-spouse   Machine-op-inspct     Husband   White     Male      0   0  40   United-States    &gt;50K\n32558  58        Private  151910      HS-grad   9              Widowed        Adm-clerical   Unmarried   White   Female      0   0  40   United-States   &lt;=50K\n32559  22        Private  201490      HS-grad   9        Never-married        Adm-clerical   Own-child   White     Male      0   0  20   United-States   &lt;=50K\n32560  52   Self-emp-inc  287927      HS-grad   9   Married-civ-spouse     Exec-managerial        Wife   White   Female  15024   0  40   United-States    &gt;50K \n\nInfo of the dataset:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 32561 entries, 0 to 32560\nData columns (total 15 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   0       32561 non-null  int64 \n 1   1       32561 non-null  object\n 2   2       32561 non-null  int64 \n 3   3       32561 non-null  object\n 4   4       32561 non-null  int64 \n 5   5       32561 non-null  object\n 6   6       32561 non-null  object\n 7   7       32561 non-null  object\n 8   8       32561 non-null  object\n 9   9       32561 non-null  object\n 10  10      32561 non-null  int64 \n 11  11      32561 non-null  int64 \n 12  12      32561 non-null  int64 \n 13  13      32561 non-null  object\n 14  14      32561 non-null  object\ndtypes: int64(6), object(9)\nmemory usage: 3.7+ MB\n</code></pre> <p>A m\u00e9s, podem utilitzar els seg\u00fcents m\u00e8todes per obtindre m\u00e9s informaci\u00f3:</p> <ul> <li><code>shape</code>: proporciona el nombre de files i columnes del conjunt de dades.</li> <li><code>describe()</code>: proporciona estad\u00edstiques descriptives del conjunt de dades com el nombre de valors no nuls,     la mitjana, la desviaci\u00f3 est\u00e0ndard, el valor m\u00ednim, els quartils i el valor m\u00e0xim.</li> <li><code>unique()</code>: proporciona els valors \u00fanics d'una columna.</li> <li><code>value_counts()</code>: proporciona el nombre de vegades que es repeteix cada valor d'una columna.</li> </ul> Exemple: <code>shape</code>, <code>describe()</code> i <code>unique()</code> <pre><code>print(\"Shape of the dataset:\")\nprint(df.shape, \"\\n\")\nprint(\"Description of the dataset:\")\nprint(df.describe(), \"\\n\")\nprint(\"Unique values of workclass column:\")\nprint(df['workclass'].unique(), \"\\n\")\nprint(\"Value counts of workclass column:\")\nprint(df['workclass'].value_counts(dropna=False), \"\\n\")\n</code></pre> <pre><code>Shape of the dataset:\n(32561, 15) \n\nDescription of the dataset:\n                 0             2             4             10            11            12\ncount  32561.000000  3.256100e+04  32561.000000  32561.000000  32561.000000  32561.000000\nmean      38.581647  1.897784e+05     10.080679   1077.648844     87.303830     40.437456\nstd       13.640433  1.055500e+05      2.572720   7385.292085    402.960219     12.347429\nmin       17.000000  1.228500e+04      1.000000      0.000000      0.000000      1.000000\n25%       28.000000  1.178270e+05      9.000000      0.000000      0.000000     40.000000\n50%       37.000000  1.783560e+05     10.000000      0.000000      0.000000     40.000000\n75%       48.000000  2.370510e+05     12.000000      0.000000      0.000000     45.000000\nmax       90.000000  1.484705e+06     16.000000  99999.000000   4356.000000     99.000000 \n\nUnique values of workclass column:\n'State-gov' 'Self-emp-not-inc' 'Private' 'Federal-gov' 'Local-gov' '?'\n 'Self-emp-inc' 'Without-pay' 'Never-worked']\n\nValue counts of workclass column:\nworkclass\nPrivate             22696\nSelf-emp-not-inc     2541\nLocal-gov            2093\nNaN                  1836\nState-gov            1298\nSelf-emp-inc         1116\nFederal-gov           960\nWithout-pay            14\nNever-worked            7\nName: count, dtype: int64\n</code></pre>"},{"location":"apunts/03_manipulacio_dades/03_preparacio_dades/#valors-nuls","title":"Valors nuls","text":"<p>Un dels problemes m\u00e9s comuns en les dades s\u00f3n els valors nuls, ja que la majoria de models no permeten treballar amb valors no num\u00e8rics.</p> <p>Podem identificar els valors nuls amb el m\u00e8tode <code>isnull()</code>.</p> Exemple: <code>isnull()</code> <p>Warning</p> <p>Hem modificat el conjunt de dades inicial per afegir un valor nul a la columna <code>age</code>.</p> <pre><code>df.loc[50, 'age'] = None # Assignem un valor nul a la columna 'age' de la fila 50\n\nprint(\"Number of null values in each column:\")\nprint(df.isnull().sum(), \"\\n\")\n</code></pre> <pre><code>Number of null values in each column:\nage                  1\nworkclass         1836\nfnlwgt               0\neducation            0\neducation-num        0\nmarital-status       0\noccupation        1843\nrelationship         0\nrace                 0\nsex                  0\ncapital-gain         0\ncapital-loss         0\nhours-per-week       0\nnative-country     583\nincome               0\ndtype: int64 \n</code></pre> <p>En aquest cas, podem tractar-los de tres maneres diferents:</p> <ul> <li>Eliminar les files amb valors nuls.</li> <li>Eliminar la columna amb valors nuls.</li> <li>Inferir els valors nuls.</li> </ul> <p>Depenent de la tipologia de les dades, una opci\u00f3 ser\u00e0 m\u00e9s adequada que una altra.</p>"},{"location":"apunts/03_manipulacio_dades/03_preparacio_dades/#eliminar-les-files-amb-valors-nuls","title":"Eliminar les files amb valors nuls","text":"<p>En el cas que les files amb valors nuls no siguen significatives dins del conjunt de dades, podem eliminar-les.</p> Exemple consulta fila amb <code>age</code> nul\u00b7la <pre><code>print(df[df['age'].isnull()])\n</code></pre> <pre><code>    age workclass  fnlwgt     education  education-num      marital-status       occupation relationship   race     sex  capital-gain  capital-loss  hours-per-week native-country income\n50  NaN   Private   32275  Some-college             10  Married-civ-spouse  Exec-managerial         Wife  Other  Female             0             0              40  United-States\n</code></pre> <p>El m\u00e8tode <code>dropna()</code> ens permet eliminar les files amb valors nuls d'un conjunt de dades.</p> <pre><code>df = df.dropna(inplace=False, subset=None)\n</code></pre> <ul> <li><code>inplace</code>: si <code>True</code>, el conjunt de dades es modificar\u00e0 directament.</li> <li><code>subset</code>: llista de columnes on buscar valors nuls.</li> </ul> <p>Documentaci\u00f3</p> <p>Documentaci\u00f3 de pandas sobre el m\u00e8tode <code>dropna()</code>.</p> Exemple: Eliminar files amb <code>age</code> nul\u00b7la <pre><code>rows = df.shape[0]\ndf.dropna(subset=['age'], inplace=True)\nprint(f\"Deleted {rows - df.shape[0]} rows with null values in 'age' column\")\n</code></pre> <pre><code>Deleted 1 rows with null values in 'age' column\n</code></pre>"},{"location":"apunts/03_manipulacio_dades/03_preparacio_dades/#eliminar-la-columna-amb-valors-nuls","title":"Eliminar la columna amb valors nuls","text":"<p>En el cas que la columna amb valors nuls no siga significativa dins del conjunt de dades, podem eliminar-la completament.</p> <p>El m\u00e8tode <code>drop()</code> ens permet eliminar una columna d'un conjunt de dades.</p> <pre><code>df = df.drop(labels, inplace=False)\n</code></pre> <p>Documentaci\u00f3</p> <p>Documentaci\u00f3 de pandas sobre el m\u00e8tode <code>drop()</code>.</p> Eliminaci\u00f3 de la columna <code>workclass</code> <p>En aquest cas, hagu\u00e9rem pogut eliminar la columna <code>workclass</code> amb valors nuls. <pre><code>df.drop(columns='workclass', inplace=True)\n</code></pre></p> <p>No obstant aix\u00f2, aquests valors podrien ser significatius per a la predicci\u00f3, i s'ha optat per no fer-ho.</p>"},{"location":"apunts/03_manipulacio_dades/03_preparacio_dades/#dades-categoriques","title":"Dades categ\u00f2riques","text":"<p>Els models d'aprenentatge autom\u00e0tic no poden treballar directament amb dades categ\u00f2riques o amb text, per tant, \u00e9s necessari processar-les per poder-les utilitzar.</p> <p>Per identificar les columnes amb dades categ\u00f2riques, podem utilitzar el m\u00e8tode <code>dtypes</code> i filtrar les columnes amb el tipus <code>object</code>.</p> Exemple: Identificar columnes categ\u00f2riques <pre><code>print(\"Categorical columns:\")\nprint(df.select_dtypes(include='object').columns)\n</code></pre> <pre><code>Categorical columns:\nIndex(['workclass', 'education', 'marital-status', 'occupation',\n       'relationship', 'race', 'sex', 'native-country', 'income'],\n      dtype='object')\n</code></pre> <p>Per transformar les dades categ\u00f2riques en dades num\u00e8riques, podem utilitzar diferents m\u00e8todes com:</p> <ul> <li> <p><code>OrdinalEncoder</code> i <code>LabelEncoder</code>: transformen les dades categ\u00f2riques en valors num\u00e8rics.</p> <p>La difer\u00e8ncia principal \u00e9s que <code>OrdinalEncoder</code> est\u00e0 pensat per transformar les caracter\u00edstiques de les dades, mentre que <code>LabelEncoder</code> est\u00e0 pensat per transformar les etiquetes (<code>target</code>).</p> <p>Per aquesta ra\u00f3, <code>OrdinalEncoder</code> permet transformar m\u00e9s d'una columna a la vegada i, en canvi, <code>LabelEncoder</code> nom\u00e9s permet transformar una \u00fanica columna.</p> <p>Aquest tipus de transformaci\u00f3 \u00e9s adequada quan les dades categ\u00f2riques tenen un ordre impl\u00edcit.</p> </li> <li> <p><code>OneHotEncoder</code>: transforma les dades categ\u00f2riques en variables bin\u00e0ries.</p> <p>Aquest m\u00e8tode crea una columna per a cada valor \u00fanic de la columna original, assignant un valor de <code>1</code> si el valor \u00e9s present i <code>0</code> si no ho \u00e9s.</p> <p>Aquest tipus de transformaci\u00f3 \u00e9s adequada quan les dades categ\u00f2riques no tenen un ordre impl\u00edcit.</p> </li> </ul>"},{"location":"apunts/03_manipulacio_dades/03_preparacio_dades/#ordinalencoder","title":"<code>OrdinalEncoder</code>","text":"<p>El <code>OrdinalEncoder</code> transforma les dades categ\u00f2riques en valors ordinals, \u00e9s a dir, assigna un valor num\u00e8ric a cada categoria.</p> <p>Info</p> <p><code>OrdinalEncoder</code> no suporta valors nuls, per tant, \u00e9s necessari tractar-los abans de fer la transformaci\u00f3.</p> Exemple: Transformaci\u00f3 de <code>workclass</code> amb <code>OrdinalEncoder</code> <pre><code># Assignem un valor '?' als valors nuls\ndf.loc[df['workclass'].isnull(), 'workclass'] = '?'\n\nworkclass_oe = OrdinalEncoder()\ndf['workclass_oe'] = workclass_oe.fit_transform(df[['workclass']])\n\n# print each unique value and its corresponding label\nprint(\"Unique values of workclass column:\")\nunique_pairs = df[['workclass', 'workclass_oe']].drop_duplicates().sort_values('workclass_oe').reset_index(drop=True)\nprint(unique_pairs, \"\\n\")\n</code></pre> <pre><code>Unique values of workclass column:\n          workclass  workclass_oe\n0                 ?           0.0\n1       Federal-gov           1.0\n2         Local-gov           2.0\n3      Never-worked           3.0\n4           Private           4.0\n5      Self-emp-inc           5.0\n6  Self-emp-not-inc           6.0\n7         State-gov           7.0\n8       Without-pay           8.0 \n</code></pre>"},{"location":"apunts/03_manipulacio_dades/03_preparacio_dades/#onehotencoder","title":"<code>OneHotEncoder</code>","text":"<p>El <code>OneHotEncoder</code> transforma les dades categ\u00f2riques en m\u00faltiples columnes bin\u00e0ries, que s'indica amb un <code>1</code> si el valor \u00e9s d'aquella categoria i <code>0</code> si no ho \u00e9s.</p> Exemple: Transformaci\u00f3 de <code>sex</code> amb <code>OneHotEncoder</code> <pre><code>encoder = OneHotEncoder()\nencoded_data = encoder.fit_transform(df[['sex']])\nencoded_columns = encoder.get_feature_names_out(['sex'])\ndf_encoded = pd.DataFrame(encoded_data.toarray(), columns=encoded_columns)\ndf = pd.concat([df, df_encoded], axis=1)\n\nprint(\"OneHot encoded columns:\")\nprint(df[['sex', 'sex_Male', 'sex_Female']].head(), \"\\n\")\n</code></pre> <pre><code>OneHot encoded columns:\n      sex  sex_Male  sex_Female\n0    Male       1.0         0.0\n1    Male       1.0         0.0\n2    Male       1.0         0.0\n3    Male       1.0         0.0\n4  Female       0.0         1.0\n</code></pre>"},{"location":"apunts/03_manipulacio_dades/03_preparacio_dades/#codi-font","title":"Codi font","text":"preparacio_adults.py<pre><code>#!/usr/bin/env python\n\nfrom urllib.request import urlopen\nimport pandas as pd\nimport os\n\n\ndef download(url, filepath):\n    http_response = urlopen(url)\n    content = http_response.read()\n    with open(filepath, 'wb') as f:\n        f.write(content)\n\n\nfiles_folder = '../../files/ud3'\nif not os.path.exists(files_folder):\n    os.makedirs(files_folder)\n\nfile_path = os.path.join(files_folder, 'adult.data.csv')\nif not os.path.exists(file_path):\n    adult_dataset_url = 'https://raw.githubusercontent.com/joapuiib/saa-datasets/refs/heads/main/adult.data.csv'\n    print('Downloading dataset...')\n    download(adult_dataset_url, file_path)\nelse:\n    print(f'Dataset found at {file_path}')\n\n\ndf = pd.read_csv(file_path)\nprint(\"Head of the dataset:\")\nprint(df.head(), \"\\n\")\nprint(\"Tail of the dataset:\")\nprint(df.tail(), \"\\n\")\nprint(\"Info of the dataset:\")\ndf.info()\nprint()\n\nprint(\"Shape of the dataset:\")\nprint(df.shape, \"\\n\")\nprint(\"Description of the dataset:\")\nprint(df.describe(), \"\\n\")\nprint(\"Unique values of workclass column:\")\nprint(df['workclass'].unique(), \"\\n\")\nprint(\"Value counts of workclass column:\")\nprint(df['workclass'].value_counts(dropna=False), \"\\n\")\n\n\n## Valors nuls\ndf.loc[50, 'age'] = None # Assignem un valor nul a la columna 'age' de la fila 50\n\nprint(\"Number of null values in each column:\")\nprint(df.isnull().sum(), \"\\n\")\n\n## Eliminar files amb valors nuls\nprint(df[df['age'].isnull()])\n\nrows = df.shape[0]\ndf.dropna(subset=['age'], inplace=True)\nprint(f\"Deleted {rows - df.shape[0]} rows with null values in 'age' column\", \"\\n\")\n\nprint(\"Categorical columns:\")\nprint(df.select_dtypes(include='object').columns, \"\\n\")\n\n# Assignem un valor '?' als valors nuls\ndf.loc[df['workclass'].isnull(), 'workclass'] = '?'\n\nworkclass_oe = OrdinalEncoder()\ndf['workclass_oe'] = workclass_oe.fit_transform(df[['workclass']])\n\n# print each unique value and its corresponding label\nprint(\"Unique values of workclass column:\")\nunique_pairs = df[['workclass', 'workclass_oe']].drop_duplicates().sort_values('workclass_oe').reset_index(drop=True)\nprint(unique_pairs, \"\\n\")\n\nencoder = OneHotEncoder()\nencoded_data = encoder.fit_transform(df[['sex']])\nencoded_columns = encoder.get_feature_names_out(['sex'])\ndf_encoded = pd.DataFrame(encoded_data.toarray(), columns=encoded_columns)\ndf = pd.concat([df, df_encoded], axis=1)\n\nprint(\"OneHot encoded columns:\")\nprint(df[['sex', 'sex_Male', 'sex_Female']].head(), \"\\n\")\n</code></pre>"},{"location":"apunts/03_manipulacio_dades/03_preparacio_dades/#bibliografia","title":"Bibliografia","text":"<ul> <li>Material del m\u00f2dul \"Sistemes d'Aprenentatge Autom\u00e0tic\" de C\u00e9sar Guijarro Rosaleny</li> <li>StackExchange Datascience: Difference between OrdinalEncoder and LabelEncoder</li> </ul>"},{"location":"apunts/03_manipulacio_dades/04_analisi_visual/","title":"An\u00e0lisi visual de les dades","text":""},{"location":"apunts/03_manipulacio_dades/04_analisi_visual/#analisi-visual-de-les-dades","title":"An\u00e0lisi visual de les dades","text":"<p>Un an\u00e0lisi visual de les dades \u00e9s una proc\u00e9s que ens pot resultar \u00fatil per entendre millor les dades amb les que estem treballant.</p> <p>Cal tindre en compte que per poder representar les dades en un gr\u00e0fic, sols podem representar dues dimensions. No existeix cap gr\u00e0fic que ens permeta representar tota la informaci\u00f3 possible, per\u00f2 podem fer combinacions per trobar relacions i patrons en les dades.</p> <p>Instal\u00b7laci\u00f3 de depend\u00e8ncies</p> <p>Aquest material utilitza les seg\u00fcents llibreries de Python per a la visualitzaci\u00f3 de les dades:</p> requirements.txt<pre><code>matplotlib\nseaborn\n</code></pre> <pre><code>import matplotlib.pyplot as plt\nimport seaborn as sns\n</code></pre>"},{"location":"apunts/03_manipulacio_dades/04_analisi_visual/#distribucio-de-les-columnes-respecte-a-les-etiquetes","title":"Distribuci\u00f3 de les columnes respecte a les etiquetes","text":"<p>En els algorismes d'aprenentatge autom\u00e0tic supervisat, utilitzem les etiquetes per indicar l'eixida esperada del model. Una bona manera de comen\u00e7ar a entendre les dades \u00e9s veure com es distribueixen les dades respecte a les etiquetes.</p> <p>Advert\u00e8ncia</p> <p>Aquesta visualitzaci\u00f3 sols \u00e9s v\u00e0lida per les columnes num\u00e8riques.</p> <pre><code>df_numerics = df.select_dtypes(include = ['float64', 'int64'])\n\nfigure=plt.figure(figsize = (15, 6))\n\nfor i, column in enumerate(df_numerics.columns, 1):\n        axes = figure.add_subplot(3,2,i)\n        sns.kdeplot(x = df_numerics[column], hue = df['income'], fill = True, ax = axes)\n        figure.tight_layout()\nplt.show()\n</code></pre> <p>Figura 1. Distribuci\u00f3 de densitat de les columnes respecte a les etiquetes</p> <p></p>"},{"location":"apunts/03_manipulacio_dades/04_analisi_visual/#histograma-de-les-columnes","title":"Histograma de les columnes","text":"<p>Un histograma ens permet veure la distribuci\u00f3 de les dades d'una sola columna.</p> <pre><code>df_objects = df.select_dtypes(include=['object'])\nfigure=plt.figure(figsize = (15, 20))\n\nfor i, column in enumerate(df_objects.columns, 1):\n    axes = figure.add_subplot(3,3,i)\n    sns.histplot(x = df_objects[column], ax = axes, hue=df['income'], multiple='dodge')\n    axes.tick_params(axis='x', rotation=45)\n    for label in axes.get_xticklabels():\n        label.set_ha('right')  # Align labels to the right\n    figure.tight_layout()\n\nplt.show()\n</code></pre> <p>Figura 2. Histograma de les columnes</p> <p></p>"},{"location":"apunts/03_manipulacio_dades/04_analisi_visual/#relacio-entre-les-columnes","title":"Relaci\u00f3 entre les columnes","text":"<p>Per veure la relaci\u00f3 entre les columnes, podem utilitzar un gr\u00e0fic de dispersi\u00f3.</p> <pre><code>n_samples_to_plot = 5000\ncolumns = ['age', 'education-num', 'hours-per-week']\n_ = sns.pairplot(data=df[:n_samples_to_plot], vars=columns,\n                 hue=\"income\", plot_kws={'alpha': 0.2},\n                 height=3, diag_kind='hist', diag_kws={'bins': 30})\n</code></pre> <p>Figura 3. Relaci\u00f3 entre les columnes</p> <p></p>"},{"location":"apunts/03_manipulacio_dades/04_analisi_visual/#fronteres-de-decisio","title":"Fronteres de decisi\u00f3","text":"<p>Fixem-nos en el gr\u00e0fic de les columnes <code>age</code> i <code>hours-per-week</code></p> <p>Figura 3.1. Relaci\u00f3 entre les columnes <code>age</code> i <code>hours-per-week</code></p> <p></p> <p>En aquest cas, podr\u00edem comen\u00e7ar a establir fronteres de decisi\u00f3 per establir si una persona guanya m\u00e9s de 50K o no.</p> <p>Important</p> <p>Aquest proc\u00e9s \u00e9s el que tractarem de realitzar d'una manera autom\u00e0tica mitjan\u00e7ant els algorismes d'aprenentatge autom\u00e0tic.</p> <p>Figura 3.2. Fronteres de decisi\u00f3</p> <p></p>"},{"location":"apunts/03_manipulacio_dades/04_analisi_visual/#correlacio-entre-les-columnes","title":"Correlaci\u00f3 entre les columnes","text":"<p>Podem obtindre i visualitzar la matriu de correlaci\u00f3 entre diferents columnes.</p> <pre><code>corr_df = df.corr(method='pearson')\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(corr_df, annot=True)\n</code></pre> <p>Figura 4. Matriu de correlaci\u00f3</p> <p></p>"},{"location":"apunts/03_manipulacio_dades/04_analisi_visual/#diagrama-de-caixa","title":"Diagrama de caixa","text":"<p>Els diagrames de caixa o box plots s\u00f3n una manera de representar gr\u00e0ficament les dades num\u00e8riques a trav\u00e9s dels seus quartils.</p> <p></p> <p>Figura 5. Caixa dels diagrames de caixa</p> <p>Els limits superior \\(L_s\\) i inferior \\(L_i\\) es calculen amb l'amplitud interquart\u00edlica (IQR o inter-quartile range).</p> \\[ IQR = Q_3 - Q_1 \\] <p>Documentaci\u00f3</p> <ul> <li>Viquip\u00e8dia, Diagrama de caixa</li> <li>Documentaci\u00f3 de Seaborn, <code>boxplot</code></li> <li>Tutorials de Seaborn, <code>boxplot</code></li> </ul> <pre><code>sns.boxplot(x='income', y ='age', hue='income', data=df)\n</code></pre> <p>Figura 6. Diagrama de caixa</p> <p></p>"},{"location":"apunts/03_manipulacio_dades/04_analisi_visual/#codi-font","title":"Codi font","text":"analisi_visual_adults.py<pre><code>#!/usr/bin/env python\n\nfrom urllib.request import urlopen\nimport pandas as pd\nimport os\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\nfrom plotnine import *\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\ndef download(url, filepath):\n    http_response = urlopen(url)\n    content = http_response.read()\n    with open(filepath, 'wb') as f:\n        f.write(content)\n\n\nfiles_folder = '../../files/ud3'\nif not os.path.exists(files_folder):\n    os.makedirs(files_folder)\n\nfile_path = os.path.join(files_folder, 'adult.data.csv')\nif not os.path.exists(file_path):\n    adult_dataset_url = 'https://raw.githubusercontent.com/joapuiib/saa-datasets/refs/heads/main/adult.data.csv'\n    print('Downloading dataset...')\n    download(adult_dataset_url, file_path)\nelse:\n    print(f'Dataset found at {file_path}')\n\n\ndf = pd.read_csv(file_path)\ndf_numerics = df.select_dtypes(include = ['float64', 'int64'])\n\ndef densitat_etiquetes():\n\n    figure=plt.figure(figsize = (15, 6))\n\n    for i, column in enumerate(df_numerics.columns, 1):\n            axes = figure.add_subplot(3,2,i)\n            sns.kdeplot(x = df_numerics[column], hue = df['income'], fill = True, ax = axes)\n            figure.tight_layout()\n\n\ndef histograma():\n    figure=plt.figure(figsize = (15, 20))\n\n    df_objects = df.select_dtypes(include=['object'])\n\n    for i, column in enumerate(df_objects.columns, 1):\n        axes = figure.add_subplot(5,3,i)\n        sns.histplot(x = df_objects[column], ax = axes, hue=df['income'], multiple='dodge')\n        axes.tick_params(axis='x', rotation=45)\n        for label in axes.get_xticklabels():\n            label.set_ha('right')  # Align labels to the right\n        figure.tight_layout()\n\n\ndef relacions_variable():\n    n_samples_to_plot = 5000\n    columns = ['age', 'education-num', 'hours-per-week']\n    _ = sns.pairplot(data=df[:n_samples_to_plot], vars=columns,\n                     hue=\"income\", plot_kws={'alpha': 0.2},\n                     height=3, diag_kind='hist', diag_kws={'bins': 30})\n\ndef scatterplot():\n    ax = sns.scatterplot(\n        x=\"age\", y=\"hours-per-week\", data=df,\n        hue=\"income\", alpha=0.5,\n    )\n\n\ndef matriu_correlacio():\n    corr_df = df_numerics.corr(method='pearson')\n\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(corr_df, annot=True)\n\n\ndef boxplot():\n    sns.boxplot(x='income', y ='age', hue='income', data = df)\n\n\ndensitat_etiquetes()\n# histograma()\n# relacions_variable()\n# scatterplot()\n# matriu_correlacio()\n# boxplot()\nplt.show()\n</code></pre>"},{"location":"apunts/03_manipulacio_dades/04_analisi_visual/#bibliografia","title":"Bibliografia","text":"<ul> <li>Material del m\u00f2dul \"Sistemes d'Aprenentatge Autom\u00e0tic\" de C\u00e9sar Guijarro Rosaleny</li> </ul>"},{"location":"apunts/03_manipulacio_dades/05_analisi_visual_houses/","title":"Soluci\u00f3: An\u00e0lisi visual de house prices","text":""},{"location":"apunts/03_manipulacio_dades/05_analisi_visual_houses/#analisi-visual-de-house-prices","title":"An\u00e0lisi visual de House Prices","text":"<pre><code>import matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf_numerics = house_data.select_dtypes(include = ['float64', 'int64'])\ndf_objects = house_data.select_dtypes(include=['object'])\n\n# Densitat per columna\nfigure=plt.figure(figsize = (30, 40))\n\ncolumns = 3\nrows = df_numerics.shape[1] // columns + 1\n\nfor i, column in enumerate(df_numerics.columns, 1):\n        axes = figure.add_subplot(rows,columns,i)\n        sns.kdeplot(x = df_numerics[column], hue = house_data['SalePriceQ'], fill = True, ax = axes)\n        figure.tight_layout()\nplt.show()\n\n\n# Histograma\nfigure=plt.figure(figsize = (30, 40))\n\ncolumns = 4\nrows = df_objects.shape[1] // columns + 1\n\nfor i, column in enumerate(df_objects.columns, 1):\n    axes = figure.add_subplot(rows,columns,i)\n    sns.histplot(x = df_objects[column], ax = axes, hue=house_data[\"SalePriceQ\"],  multiple='dodge')\n    axes.tick_params(axis='x', rotation=45)\n    for label in axes.get_xticklabels():\n        label.set_ha('right')  # Align labels to the right\n    figure.tight_layout()\nplt.show()\n\n\n# Scatter-plot entre parell de columnes\ncolumns = ['OverallQual', 'OverallCond', 'GarageArea', 'GrLivArea', 'YearBuilt']\n_ = sns.pairplot(data=house_data, vars=columns,\n                 hue=\"SalePriceQ\", plot_kws={'alpha': 0.2},\n                 height=3, diag_kind='kde')\nplt.show()\n\n\n# Single scatter-plot\nax = sns.scatterplot(\n        x=\"GrLivArea\", y=\"YearBuilt\", data=house_data,\n        hue=\"SalePriceQ\", alpha=0.5,\n    )\nplt.show()\n\n\n# Correlation matrix\ncolumns = ['OverallQual', 'OverallCond', 'GarageArea', 'GrLivArea', 'YearBuilt']\ncorr_df = house_data[columns].corr(method='pearson', numeric_only=True)\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(corr_df, annot=True)\nplt.show()\n</code></pre>"},{"location":"apunts/03_manipulacio_dades/06_conjunts/","title":"Conjunts de dades","text":""},{"location":"apunts/03_manipulacio_dades/06_conjunts/#conjunts-de-dades","title":"Conjunts de dades","text":"<p>L'objectiu dels models d'aprenentatge autom\u00e0tic es trobar patrons en les dades de manera autom\u00e0tica per tal de fer prediccions o prendre decisions.</p> <p>Per aconseguir aquest objectiu, \u00e9s necessari disposar de dades per entrenar els models, que cal dividir en diferents conjunts: train (entrenament), validation (validaci\u00f3) i test (prova). Cada conjunt t\u00e9 una finalitat espec\u00edfica durant el proc\u00e9s de creaci\u00f3 i avaluaci\u00f3 del model.</p> <p>La mida de cada conjunt dep\u00e8n de diversos factors, com ara la quantitat de dades disponibles, la complexitat del model, etc. No obstant aix\u00f2, una divisi\u00f3 comuna \u00e9s:</p> <ul> <li>Conjunt d'entrenament: 70-80% de les dades.</li> <li>Conjunt de validaci\u00f3: 10-15% de les dades.</li> <li>Conjunt de prova: 10-15% de les dades.</li> </ul>"},{"location":"apunts/03_manipulacio_dades/06_conjunts/#conjunt-dentrenament","title":"Conjunt d'entrenament","text":"<p>El conjunt d'entrenament (training set) \u00e9s el conjunt de dades que s'utilitza per entrenar el model i ajustar els seus par\u00e0metres.</p> <p>L'objectiu d'aquest conjunt \u00e9s construir un model que siga capa\u00e7 de realitzar prediccions correctes sobre dades que no ha vist abans.</p>"},{"location":"apunts/03_manipulacio_dades/06_conjunts/#conjunt-de-validacio","title":"Conjunt de validaci\u00f3","text":"<p>El conjunt de validaci\u00f3 (validation set) \u00e9s el conjunt de dades que s'utilitza per avaluar el model durant el proc\u00e9s d'entrenament.</p> <p>L'objectiu d'aquest conjunt \u00e9s valorar el rendiment del model en el proc\u00e9s d'entrenament.</p> <p>Aquest conjunt permet ajustar els hiperpar\u00e0metres del model (com ara la taxa d'aprenentatge, nombre de capes de la xarxa neuronal, etc.) per tal de millorar el seu rendiment. Tamb\u00e9 ajuda a detectar problemes com l'sobreajustament (overfitting).</p> <p></p> <p>Autor desconegut</p> <p>Figura 1. Comparaci\u00f3 entre el sobreajustament i l'infraajustament.</p>"},{"location":"apunts/03_manipulacio_dades/06_conjunts/#conjunt-de-prova","title":"Conjunt de prova","text":"<p>El conjunt de prova (test set) \u00e9s el conjunt de dades que s'utilitza per avaluar el model despr\u00e9s d'haver finalitzat el proc\u00e9s d'entrenament.</p> <p>Important</p> <p>Aquest conjunt de dades no s'utilitza mai durant el proc\u00e9s d'entrenament del model.</p> <p>L'objectiu d'aquest conjunt \u00e9s avaluar el rendiment del model amb dades que no ha vist abans i comprovar si \u00e9s capa\u00e7 de generalitzar correctament el problema.</p>"},{"location":"apunts/03_manipulacio_dades/06_conjunts/#importancia-dels-conjunts-de-dades","title":"Import\u00e0ncia dels conjunts de dades","text":"<p>Els conjunts de dades s\u00f3n una part fonamental en el proc\u00e9s d'aprenentatge autom\u00e0tic per diversos motius, entre els quals podem destacar els seg\u00fcents.</p>"},{"location":"apunts/03_manipulacio_dades/06_conjunts/#prevencio-de-lsobreajustament","title":"Prevenci\u00f3 de l'sobreajustament","text":"<p>El sobreajustament (overfitting) ocorre quan un model apr\u00e9n excessivament les caracter\u00edstiques particulars de les dades d'entrenament i no \u00e9s capa\u00e7 de generalitzar correctament a noves dades.</p> <p>Per evitar l'sobreajustament, s'utilitza el conjunt de validaci\u00f3 per ajustar el model i detectar el problema abans de provar-ho amb el conjunt de prova.</p> <p></p> <p>Autor desconegut</p> <p>Figura 2. Evoluci\u00f3 de l'error en els conjunts de dades durant el proc\u00e9s d'entrenament.</p>"},{"location":"apunts/03_manipulacio_dades/06_conjunts/#evitar-el-biaix-en-lavaluacio-del-model","title":"Evitar el biaix en l'avaluaci\u00f3 del model","text":"<p>Si s'utilitza el mateix conjunt de dades per entrenar i avaluar el model, aquest pot donar la falsa impressi\u00f3 que el model \u00e9s millor del que realment \u00e9s, ja que el model ja coneix les dades amb les qual s'ha d'avaluar.</p>"},{"location":"apunts/03_manipulacio_dades/06_conjunts/#divisio-de-les-dades-en-conjunts","title":"Divisi\u00f3 de les dades en conjunts","text":"<p>La divisi\u00f3 de les dades en conjunts es pot realitzar amb diverses llibreries de Python, com ara <code>scikit-learn</code> o <code>pandas</code>.</p> <p>Una consideraci\u00f3 important \u00e9s assegurar la reproductibilitat de la divisi\u00f3 de les dades, per la qual cosa \u00e9s recomanable fixar la llavor (seed) del generador de nombres aleatoris.</p> <code>scikit-learn</code><code>pandas</code> <pre><code>import pandas as pd\n\nfrom sklearn.model_selection import train_test_split\n\nsk_train_df, val_test_df = train_test_split(df, test_size=0.3, random_state=42)\nsk_validation_df, sk_test_df = train_test_split(val_test_df, test_size=0.5, random_state=42)\n\nprint(\"Scikit-learn\")\nprint(f'Train set: {sk_train_df.shape}')\nprint(f'Validation set: {sk_validation_df.shape}')\nprint(f'Test set: {sk_test_df.shape}')\n</code></pre> <pre><code>import pandas as pd\n\ndf_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n\ntrain_size = 0.7\nvalidation_size = 0.15\ntest_size = 0.15\n\ntrain_end = int(len(df_shuffled) * train_size)\nvalidation_end = train_end + int(len(df_shuffled) * validation_size)\n\np_train_df = df_shuffled.iloc[:train_end]\np_validation_df = df_shuffled.iloc[train_end:validation_end]\np_test_df = df_shuffled.iloc[validation_end:]\n\nprint(f'Train set: {p_train_df.shape}')\nprint(f'Validation set: {p_validation_df.shape}')\nprint(f'Test set: {p_test_df.shape}')\nprint()\n</code></pre>"},{"location":"apunts/03_manipulacio_dades/06_conjunts/#codi-font","title":"Codi font","text":"conjunt_dades.py<pre><code>import pandas as pd\n\nfrom sklearn.model_selection import train_test_split\n\n\ndf = pd.read_csv('../../files/ud3/adult.data.csv')\n\ndf_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n\ntrain_size = 0.7\nvalidation_size = 0.15\ntest_size = 0.15\n\ntrain_end = int(len(df_shuffled) * train_size)\nvalidation_end = train_end + int(len(df_shuffled) * validation_size)\n\np_train_df = df_shuffled.iloc[:train_end]\np_validation_df = df_shuffled.iloc[train_end:validation_end]\np_test_df = df_shuffled.iloc[validation_end:]\n\nprint(f'Train set: {p_train_df.shape}')\nprint(f'Validation set: {p_validation_df.shape}')\nprint(f'Test set: {p_test_df.shape}')\nprint()\n\n\nsk_train_df, val_test_df = train_test_split(df, test_size=0.3, random_state=42)\nsk_validation_df, sk_test_df = train_test_split(val_test_df, test_size=0.5, random_state=42)\n\nprint(\"Scikit-learn\")\nprint(f'Train set: {sk_train_df.shape}')\nprint(f'Validation set: {sk_validation_df.shape}')\nprint(f'Test set: {sk_test_df.shape}')\n</code></pre>"},{"location":"apunts/03_manipulacio_dades/06_conjunts/#bibliografia","title":"Bibliografia","text":"<ul> <li>Material del m\u00f2dul \"Sistemes d'Aprenentatge Autom\u00e0tic\" de C\u00e9sar Guijarro de C\u00e9sar Guijarro Rosaleny</li> <li>Wikipedia: Training, validation, and test sets</li> </ul>"},{"location":"apunts/04_regressio/00_metriques/","title":"M\u00e8triques de regressi\u00f3","text":""},{"location":"apunts/04_regressio/00_metriques/#metriques-de-regressio","title":"M\u00e8triques de regressi\u00f3","text":"<p>Les m\u00e8triques s\u00f3n mesures que ens permeten avaluar la qualitat d'un model de regressi\u00f3, que determinen com de b\u00e9 s'ajusta el model a les dades i com de precises s\u00f3n les prediccions.</p> <p>Dades d'exemple</p> Real (\\(Y\\)) Predicci\u00f3 (\\(\\hat{Y}\\)) 50 52 60 58 70 68 80 85 <pre><code>import pandas as pd\n\nY = pd.Series([50, 60, 70, 80])\npred_Y = pd.Series([52, 58, 68, 85])\n</code></pre>"},{"location":"apunts/04_regressio/00_metriques/#mae-error-absolut-mitja","title":"MAE \u2013 Error absolut mitj\u00e0","text":"<p>L'error absolut mitj\u00e0 (Mean Absolute Error o MAE) \u00e9s la mitjana de les difer\u00e8ncies absolutes entre les prediccions (\\(\\hat{y}\\)) i els valors reals (\\(y\\)).</p> <p>La f\u00f3rmula per calcular l'error absolut mitj\u00e0 \u00e9s:</p> <pre>\\[\nMAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n\\]</pre> <p>C\u00e0lcul de l'error absolut mitj\u00e0</p> <code>pandas</code><code>scikit-learn</code> <pre><code>mae = np.abs(Y - pred_Y).mean()\nprint(f'MAE with pandas: {mae:.2f}')\n</code></pre> <pre><code>from sklearn.metrics import mean_absolute_error\n\nmae = mean_absolute_error(Y, pred_Y)\nprint(f'MAE with sklearn: {mae:.2f}')\n</code></pre> <pre><code>MAE: 2.75\n</code></pre> <p>Quan m\u00e9s xicotet siga el MAE, millor ser\u00e0 el model. \u00c9s f\u00e0cil d'interpretar ja que est\u00e0 expressat en les mateixes que la variable dependent.</p>"},{"location":"apunts/04_regressio/00_metriques/#mse-error-quadratic-mitja","title":"MSE \u2013 Error quadr\u00e0tic mitj\u00e0","text":"<p>L'error quadr\u00e0tic mitj\u00e0 (Mean Squared Error o MSE) \u00e9s la mitjana de les difer\u00e8ncies elevades al quadrat entre les prediccions (\\(\\hat{y}\\)) i els valors reals (\\(y\\)).</p> <p>La f\u00f3rmula per calcular l'error quadr\u00e0tic mitj\u00e0 \u00e9s:</p> <pre>\\[\nMSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n\\]</pre> <p>El MSE \u00e9s m\u00e9s sensible als errors grans que el MAE, ja que eleva al quadrat les difer\u00e8ncies. Aix\u00f2 fa que els errors m\u00e9s grans tinguin un pes m\u00e9s gran en la mesura.</p> <p>C\u00e0lcul de l'error quadr\u00e0tic mitj\u00e0</p> <code>pandas</code><code>scikit-learn</code> <pre><code>mse = ((Y - pred_Y) ** 2).mean()\nprint(f'MSE with pandas: {mse:.2f}')\n</code></pre> <pre><code>from sklearn.metrics import mean_squared_error\n\nmse = mean_squared_error(Y, pred_Y)\nprint(f'MSE with sklearn: {mse:.2f}')\n</code></pre> <pre><code>MSE: 9.25\n</code></pre>"},{"location":"apunts/04_regressio/00_metriques/#rmse-arrel-de-lerror-quadratic-mitja","title":"RMSE \u2013 Arrel de l'error quadr\u00e0tic mitj\u00e0","text":"<p>L'arrel de l'error quadr\u00e0tic mitj\u00e0 (Root Mean Squared Error o RMSE) \u00e9s la arrel quadrada del MSE.</p> <pre>\\[\nRMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\n\\]</pre> <p>Aquesta m\u00e8trica \u00e9s equivalent al MSE per\u00f2 m\u00e9s f\u00e0cil d'interpretar, ja que expressada en les mateixes unitats que la variable dependent.</p> <p>C\u00e0lcul de l'arrel de l'error quadr\u00e0tic mitj\u00e0</p> <code>pandas</code><code>scikit-learn</code> <pre><code>rmse = np.sqrt(((Y - pred_Y) ** 2).mean())\nprint(f'RMSE with pandas: {rmse:.2f}')\n</code></pre> <pre><code>from sklearn.metrics import root_mean_squared_error\n\nrmse = root_mean_squared_error(Y, pred_Y)\nprint(f'RMSE with sklearn: {rmse:.2f}')\n</code></pre> <pre><code>RMSE: 3.04\n</code></pre>"},{"location":"apunts/04_regressio/00_metriques/#r2-coeficient-de-determinacio","title":"R\u00b2 \u2013 Coeficient de determinaci\u00f3","text":"<p>El coeficient de determinaci\u00f3 (\\(R^2\\)) \u00e9s una mesura que indica com de b\u00e9 s'ajusta el model als valors reals.</p> <p>El coeficient de determinaci\u00f3 pot prendre valors entre 0 i 1, sent 1 el millor valor possible. Un valor de 0 indica que el model no s'ajusta als valors reals.</p> <p>El coeficient de determinaci\u00f3 es pot calcular com:</p> <pre>\\[\nR^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}\n\\]</pre> <p>On:</p> <ul> <li>\\(y_i\\) s\u00f3n els valors reals.</li> <li>\\(\\hat{y}_i\\) s\u00f3n les prediccions del model.</li> <li>\\(\\bar{y}\\) \u00e9s la mitjana dels valors reals.</li> </ul> <p>C\u00e0lcul del coeficient de determinaci\u00f3 \\(R^2\\)</p> <code>pandas</code><code>scikit-learn</code> <pre><code>r2 = 1 - ((Y - pred_Y) ** 2).sum() / ((Y - Y.mean()) ** 2).sum()\nprint(f'R^2 with pandas: {r2:.2f}')\n</code></pre> <pre><code>from sklearn.metrics import r2_score\n\nr2 = r2_score(Y, pred_Y)\nprint(f'R^2 with sklearn: {r2:.2f}')\n</code></pre> <pre><code>R^2: 0.93\n</code></pre>"},{"location":"apunts/04_regressio/01_lineal/","title":"Regressi\u00f3 lineal","text":""},{"location":"apunts/04_regressio/01_lineal/#regressio-lineal","title":"Regressi\u00f3 lineal","text":"<p>La regressi\u00f3 lineal \u00e9s un m\u00e8tode estad\u00edstic que intenta modelar la relaci\u00f3 entre un conjunt de variables independents \\(X\\) (caracter\u00edstiques o features) i una variable dependent \\(Y\\) (objectiu o target) mitjan\u00e7ant una funci\u00f3 lineal.</p> <p>Quan nom\u00e9s hi ha una variable independent, es parla de regressi\u00f3 lineal simple. En canvi, quan hi ha m\u00e9s d'una variable independent, es parla de regressi\u00f3 lineal m\u00faltiple.</p> <p>Aquest model lineal es pot expressar com:</p> \\[ Y = w_0 + w_1X_1 + w_2X_2 + \\ldots + w_nX_n \\] <p>on:</p> <ul> <li>\\(Y\\) \u00e9s la variable dependent (objectiu o target),</li> <li>\\(X_1, X_2, \\ldots, X_n\\) s\u00f3n les variables independents (caracter\u00edstiques o features),</li> <li>\\(w_0, w_1, w_2, \\ldots, w_n\\) s\u00f3n els coeficients o pesos del model.</li> </ul> <p>L'objectiu de la regressi\u00f3 lineal \u00e9s trobar els valors dels coeficients que millor s'ajusten a les dades.</p> <p>Una vegada s'ha obtingut el model, pot ser utilitzat per fer prediccions sobre noves dades.</p> Exemple de regressi\u00f3 lineal simple <p>Donades les dades:</p> \\(X\\) \\(Y\\) 0 5 1 15 3 35 7 75 20 205 <p></p> <p>Figura 1. Dades representades en un pla cartesi\u00e0.</p> <p>La regressi\u00f3 lineal tracta de trobar la recta que millor s'ajusta a les dades.</p> \\[ Y = 10X + 5 \\] <p></p> <p>Figura 2. Recta de regressi\u00f3 lineal.</p>"},{"location":"apunts/04_regressio/01_lineal/#models-de-regressio-lineal","title":"Models de regressi\u00f3 lineal","text":"<p>Els models de regressi\u00f3 s\u00f3n algoritmes que permeten trobar la recta que millor s'ajusta a les dades.</p> <p>Utilitzant la llibreria <code>scikit-learn</code> podem crear models de regressi\u00f3 lineal de manera senzilla.</p> <p>Dades d'exemple</p> <p>Utilitzarem un conjunt de dades on es tracta de predir la nota d'un examen a partir de les hores d'estudi i nivell de motivaci\u00f3.</p> <pre><code>import pandas as pd\n\nX_train = pd.DataFrame({\n    'hores_estudiades': [1.57, 9.05, 7.95, 6.96, 3.32, 4.96, 3.62, 8.76, 1.18],\n    'motivacio': [93.87, 74.47, 83.88, 51.84, 64.24, 98.59, 65.90, 67.05, 64.49],\n})\n\nY_train = pd.Series(name=\"nota\", data=[63.25, 60.65, 71.27, 50.62, 44.36, 73.50, 51.59, 61.29, 50.41])\n\nX_test = pd.DataFrame({\n    'hores_estudiades': [9.56, 7.59, 2.64, 6.51, 2.26, 4.30, 1.42, 1.88, 7.98],\n    'motivacio': [81.82, 65.72, 81.67, 90.37, 94.80, 55.50, 75.54, 85.15, 61.98],\n})\nY_test = pd.Series(name=\"nota\", data=[71.18, 59.50, 60.22, 67.81, 63.62, 50.48, 46.32, 48.76, 62.21])\n</code></pre>"},{"location":"apunts/04_regressio/01_lineal/#creacio-del-model","title":"Creaci\u00f3 del model","text":"<p>Per crear un model de regressi\u00f3 lineal amb <code>scikit-learn</code> podem utilitzar la classe <code>LinearRegression</code>.</p> <p>Documentaci\u00f3</p> <ul> <li><code>LinearRegression</code></li> </ul> <pre><code>from sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\n</code></pre>"},{"location":"apunts/04_regressio/01_lineal/#entrenament-del-model","title":"Entrenament del model","text":"<p>Per entrenar el model amb les dades, utilitzem el m\u00e8tode <code>fit</code> de la classe <code>LinearRegression</code>.</p> <pre><code>model.fit(X_train, Y_train)\n</code></pre>"},{"location":"apunts/04_regressio/01_lineal/#coeficients-del-model","title":"Coeficients del model","text":"<p>Un cop entrenat el model, podem obtenir els coeficients de la recta.</p> <ul> <li><code>coef_</code>: coeficients de les variables independents.</li> <li><code>intercept_</code>: terme independent de la recta.</li> </ul> <pre><code>print(f'Coeficients: {model.coef_}')\nprint(f'Intercept: {model.intercept_}')\n</code></pre> <pre><code>Coeficients: [1.54284641 0.57396092]\nIntercept: 8.0617676396745\n</code></pre>"},{"location":"apunts/04_regressio/01_lineal/#prediccio-amb-el-model","title":"Predicci\u00f3 amb el model","text":"<p>Per fer prediccions amb el model entrenat, utilitzem el m\u00e8tode <code>predict</code>.</p> <pre><code>pred_Y_test = model.predict(X_test)\n</code></pre>"},{"location":"apunts/04_regressio/01_lineal/#avaluacio-del-model","title":"Avaluaci\u00f3 del model","text":"<p>Per avaluar el model, podem utilitzar les m\u00e8triques de regressi\u00f3.</p> <pre><code>from sklearn.metrics import (\n    mean_absolute_error,\n    mean_squared_error,\n    root_mean_squared_error,\n    r2_score,\n)\n\nmae = mean_absolute_error(Y_test, pred_Y_test)\nmse = mean_squared_error(Y_test, pred_Y_test)\nrmse = root_mean_squared_error(Y_test, pred_Y_test)\nr2 = r2_score(Y_test, pred_Y_test)\n\nprint(f'MAE: {mae:.2f}')\nprint(f'MSE: {mse:.2f}')\nprint(f'RMSE: {rmse:.2f}')\nprint(f'R^2: {r2:.2f}')\n</code></pre> <pre><code>MAE: 4.19\nMSE: 27.56\nRMSE: 5.25\nR^2: 0.58\n</code></pre>"},{"location":"apunts/04_regressio/01_lineal/#visualitzacio-del-model","title":"Visualitzaci\u00f3 del model","text":"<p>Podem visualitzar el model de regressi\u00f3 lineal amb una gr\u00e0fica.</p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\n# Coeficients i intercept\nb0 = model.intercept_\nb1, b2 = model.coef_\n\n# Crear el gr\u00e0fic 3D\nfig = plt.figure(figsize=(10, 7))\nax = fig.add_subplot(111, projection='3d')\n\n# Dades reals: scatter plot\nax.scatter(X_train['hores_estudiades'], X_train['motivacio'], Y_train, color='green', label='Conjunt d\\'entrenament')\nax.scatter(X_test['hores_estudiades'], X_test['motivacio'], Y_test, color='blue', label='Conjunt de prova')\n\n# Crear una graella per a les variables independents\nx1_range = np.linspace(\n    min(X_test['hores_estudiades'].min(), X_train['hores_estudiades'].min()),\n    max(X_test['hores_estudiades'].max(), X_train['hores_estudiades'].max()),\n    10,\n)\nx2_range = np.linspace(\n    min(X_test['motivacio'].min(), X_train['motivacio'].min()),\n    max(X_test['motivacio'].max(), X_train['motivacio'].max()),\n    10,\n)\nx1_grid, x2_grid = np.meshgrid(x1_range, x2_range)\n\n# Predicci\u00f3 dels valors de Y per a la graella (plane de regressi\u00f3)\ny_grid = b0 + b1 * x1_grid + b2 * x2_grid\n\n# Superf\u00edcie de la regressi\u00f3\nax.plot_surface(x1_grid, x2_grid, y_grid, color='red', alpha=0.5)\n\n# Etiquetes dels eixos\nax.set_xlabel('Hores Estudiades')\nax.set_ylabel('Motivaci\u00f3')\nax.set_zlabel('Nota Final')\n\n# T\u00edtol i llegenda\nax.set_title('Gr\u00e0fic 3D de la Regressi\u00f3 Lineal')\nax.legend()\n\nplt.show()\n</code></pre> <p></p> <p>Figura 3. Gr\u00e0fica 3D del model de regressi\u00f3 lineal respecte al conjunt de test.</p>"},{"location":"apunts/04_regressio/01_lineal/#codi-font","title":"Codi font","text":"metriques_regressio.py<pre><code>#!/usr/bin/env python\n\nimport pandas as pd\nimport numpy as np\n\nY = pd.Series([50, 60, 70, 80])\npred_Y = pd.Series([52, 58, 68, 85])\n\nmae = np.abs(Y - pred_Y).mean()\nprint(f'MAE with pandas: {mae:.2f}')\n\nfrom sklearn.metrics import mean_absolute_error\n\nmae = mean_absolute_error(Y, pred_Y)\nprint(f'MAE with sklearn: {mae:.2f}')\n\nmse = ((Y - pred_Y) ** 2).mean()\nprint(f'MSE with pandas: {mse:.2f}')\n\nfrom sklearn.metrics import mean_squared_error\n\nmse = mean_squared_error(Y, pred_Y)\nprint(f'MSE with sklearn: {mse:.2f}')\n\nrmse = np.sqrt(((Y - pred_Y) ** 2).mean())\nprint(f'RMSE with pandas: {rmse:.2f}')\n\nfrom sklearn.metrics import root_mean_squared_error\n\nrmse = root_mean_squared_error(Y, pred_Y)\nprint(f'RMSE with sklearn: {rmse:.2f}')\n\nr2 = 1 - ((Y - pred_Y) ** 2).sum() / ((Y - Y.mean()) ** 2).sum()\nprint(f'R^2 with pandas: {r2:.2f}')\n\nfrom sklearn.metrics import r2_score\n\nr2 = r2_score(Y, pred_Y)\nprint(f'R^2 with sklearn: {r2:.2f}')\n</code></pre> regressio_lineal.py<pre><code>#!/usr/bin/env python\n\nimport pandas as pd\n\nX_train = pd.DataFrame({\n    'hores_estudiades': [1.57, 9.05, 7.95, 6.96, 3.32, 4.96, 3.62, 8.76, 1.18],\n    'motivacio': [93.87, 74.47, 83.88, 51.84, 64.24, 98.59, 65.90, 67.05, 64.49],\n})\n\nY_train = pd.Series(name=\"nota\", data=[63.25, 60.65, 71.27, 50.62, 44.36, 73.50, 51.59, 61.29, 50.41])\n\nX_test = pd.DataFrame({\n    'hores_estudiades': [9.56, 7.59, 2.64, 6.51, 2.26, 4.30, 1.42, 1.88, 7.98],\n    'motivacio': [81.82, 65.72, 81.67, 90.37, 94.80, 55.50, 75.54, 85.15, 61.98],\n})\nY_test = pd.Series(name=\"nota\", data=[71.18, 59.50, 60.22, 67.81, 63.62, 50.48, 46.32, 48.76, 62.21])\n\n\nfrom sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\n\nmodel.fit(X_train, Y_train)\n\npred_Y_test = model.predict(X_test)\n\nprint(f'Coeficients: {model.coef_}')\nprint(f'Intercept: {model.intercept_}')\n\nfrom sklearn.metrics import (\n    mean_absolute_error,\n    mean_squared_error,\n    root_mean_squared_error,\n    r2_score,\n)\n\nmae = mean_absolute_error(Y_test, pred_Y_test)\nmse = mean_squared_error(Y_test, pred_Y_test)\nrmse = root_mean_squared_error(Y_test, pred_Y_test)\nr2 = r2_score(Y_test, pred_Y_test)\n\nprint(f'MAE: {mae:.2f}')\nprint(f'MSE: {mse:.2f}')\nprint(f'RMSE: {rmse:.2f}')\nprint(f'R^2: {r2:.2f}')\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n# Coeficients i intercept\nb0 = model.intercept_\nb1, b2 = model.coef_\n\n# Crear el gr\u00e0fic 3D\nfig = plt.figure(figsize=(10, 7))\nax = fig.add_subplot(111, projection='3d')\n\n# Dades reals: scatter plot\nax.scatter(X_train['hores_estudiades'], X_train['motivacio'], Y_train, color='green', label='Conjunt d\\'entrenament')\nax.scatter(X_test['hores_estudiades'], X_test['motivacio'], Y_test, color='blue', label='Conjunt de prova')\n\n# Crear una graella per a les variables independents\nx1_range = np.linspace(\n    min(X_test['hores_estudiades'].min(), X_train['hores_estudiades'].min()),\n    max(X_test['hores_estudiades'].max(), X_train['hores_estudiades'].max()),\n    10,\n)\nx2_range = np.linspace(\n    min(X_test['motivacio'].min(), X_train['motivacio'].min()),\n    max(X_test['motivacio'].max(), X_train['motivacio'].max()),\n    10,\n)\nx1_grid, x2_grid = np.meshgrid(x1_range, x2_range)\n\n# Predicci\u00f3 dels valors de Y per a la graella (plane de regressi\u00f3)\ny_grid = b0 + b1 * x1_grid + b2 * x2_grid\n\n# Superf\u00edcie de la regressi\u00f3\nax.plot_surface(x1_grid, x2_grid, y_grid, color='red', alpha=0.5)\n\n# Etiquetes dels eixos\nax.set_xlabel('Hores Estudiades')\nax.set_ylabel('Motivaci\u00f3')\nax.set_zlabel('Nota Final')\n\n# T\u00edtol i llegenda\nax.set_title('Gr\u00e0fic 3D de la Regressi\u00f3 Lineal')\nax.legend()\n\nplt.show()\n</code></pre>"},{"location":"apunts/04_regressio/01_lineal/#recursos-addicionals","title":"Recursos addicionals","text":"<ul> <li>Regresi\u00f3n Lineal y M\u00ednimos Cuadrados Ordinarios | DotCSV</li> </ul>"},{"location":"apunts/04_regressio/01_lineal/#bibliografia","title":"Bibliografia","text":"<ul> <li>Material del m\u00f2dul \"Sistemes d'Aprenentatge Autom\u00e0tic\" de C\u00e9sar Guijarro de C\u00e9sar Guijarro Rosaleny</li> <li>Regressi\u00f3 lineal \u2013 Viquip\u00e8dia</li> </ul>"},{"location":"apunts/04_regressio/02_polinomica/","title":"Regressi\u00f3 polin\u00f2mica","text":""},{"location":"apunts/04_regressio/02_polinomica/#regressio-polinomica","title":"Regressi\u00f3 polin\u00f2mica","text":"<p>La regressi\u00f3 polin\u00f2mica \u00e9s un model de regressi\u00f3 que intenta ajustar les dades que no segueixen una relaci\u00f3 lineal mitjan\u00e7ant un polinomi.</p> <p>Un p\u00e0metre important en la regressi\u00f3 polin\u00f2mica \u00e9s el grau del polinomi, que determina el nombre de coeficients per cada variable independent que tindr\u00e0 el model.</p> <p>La f\u00f3rmula general d'un polinomi de grau \\(n\\) per a una variable independent \\(X_1\\) \u00e9s:</p> \\[ Y = w_0 + w_1 X_1 + w_2 X_1^2 + \\ldots + w_n X_1^n \\] <p>on:</p> <ul> <li>\\(Y\\) \u00e9s la variable dependent (objectiu o target),</li> <li>\\(X_1\\) \u00e9s la variable independent (caracter\u00edstica o feature),</li> <li>\\(w_0, w_1, w_2, \\ldots, w_n\\) s\u00f3n els coeficients o pesos del model.</li> </ul> <p>Exemple de formula de grau 2</p> <p>La f\u00f3rmula d'un polinomi de grau 2 \u00e9s amb una variable independent \\(X_1\\) \u00e9s:</p> \\[ Y = w_0 + w_1 X_1 + w_2 X_1^2 \\] <p>En cas de tindre dues variables independents \\(X_1\\) i \\(X_2\\), la f\u00f3rmula general d'un polinomi de grau \\(n\\) \u00e9s:</p> \\[ Y = w_0 + w_1 X_1 + w_2 X_2 + w_3 X_1^2 + w_4 X_1X_2 + w_5 X_2^2 + \\ldots + w_n X_1^n + w_{n+1} X_1^{n-1}X_2 + \\ldots + w_{2n} X_2^n \\] <p>Exemple de formula de grau 2 amb dues variables</p> <p>La f\u00f3rmula d'un polinomi de grau 2 amb dues variables independents \\(X_1\\) i \\(X_2\\) \u00e9s:</p> \\[ Y = w_0 + w_1 X_1 + w_2 X_2 + w_3 X_1^2 + w_4 X_1X_2 + w_5 X_2^2 \\] <p>L'objectiu de la regressi\u00f3 polin\u00f2mica \u00e9s trobar els valors dels coeficients que millor s'ajusten a les dades.</p> Preparaci\u00f3 de les dades <p>A partir del polinomi:</p> \\[ Y = -100 - 5X + 5X^2 + 0.1X^3 \\] <p>Anem a generar un conjunt de dades que s'ajusten a aquest polinomi amb una lleugera desviaci\u00f3.</p> <pre><code>import numpy as np\nfrom sklearn.model_selection import train_test_split\n\ndef f(x):\n    return -100 - 5*x + 5*np.power(x, 2) + 0.1*np.power(x, 3)\n\nnp.random.seed(42)\nn_samples = 100\n\nX = np.random.uniform(-50, 50, n_samples)\nY = f(X) + np.random.randn(n_samples)*1000\nX = X.reshape(-1, 1) # Convertim X en una matriu de 1 columna\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\nX_test, Y_test = zip(*sorted(zip(X_test, Y_test))) # Ordenem les dades de test per visualitzar-les correctament\n</code></pre> <p></p> <p>Figura 1. Dades generades a partir del polinomi</p> Regressi\u00f3 lineal <p>Si intentem ajustar les dades amb un model de regressi\u00f3 lineal, obtenim un model incapa\u00e7 de generalitzar les dades de manera correcta.</p> <pre><code>from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\n\nmodel = LinearRegression()\nmodel.fit(X_train, Y_train)\n\npred_Y = model.predict(X_test)\n\nrmse = mean_squared_error(Y_test, pred_Y)\nr2 = r2_score(Y_test, pred_Y)\nprint(f'RMSE linear: {rmse:.2f}')\nprint(f'R^2 linear: {r2:.2f}')\n</code></pre> <pre><code>RMSE linear: 12671123.84\nR^2 linear: 0.50\n</code></pre> <p></p> <p>Figura 2. Regressi\u00f3 lineal</p>"},{"location":"apunts/04_regressio/02_polinomica/#model-de-regressio-polinomica","title":"Model de regressi\u00f3 polin\u00f2mica","text":"<p>Els models de regressi\u00f3 polin\u00f2mica s\u00f3n capa\u00e7os de trobar la relaci\u00f3 no lineal entre les variables mitjan\u00e7ant un polinomi.</p> <p>Utilitzant la llibreria <code>scikit-learn</code> podem crear un model de regressi\u00f3 polin\u00f2mica de manera senzilla.</p>"},{"location":"apunts/04_regressio/02_polinomica/#creacio-del-model","title":"Creaci\u00f3 del model","text":"<p>Per crear un model de regressi\u00f3 polin\u00f2mica amb <code>scikit-learn</code> podem utilitzarem les seg\u00fcents classes i m\u00e8todes:</p> <ul> <li><code>PolynomialFeatures</code>: Classe que genera noves caracter\u00edstiques polin\u00f2miques donat un grau.</li> <li><code>LinearRegression</code>: Classe que implementa la regressi\u00f3 lineal.</li> <li><code>make_pipeline</code>: Funci\u00f3 que crea una seq\u00fc\u00e8ncia de transformacions a un estimador.</li> </ul> <pre><code>from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline\n\ndegree = 3\npolynomial_features = PolynomialFeatures(degree=degree, include_bias=False)\nmodel = make_pipeline(polynomial_features, LinearRegression())\n</code></pre>"},{"location":"apunts/04_regressio/02_polinomica/#entrenament-del-model","title":"Entrenament del model","text":"<p>Per entrenar el model amb les dades, utilitzem el m\u00e8tode <code>fit</code> de la classe <code>LinearRegression</code>.</p> <pre><code>model.fit(X_train, Y_train)\n</code></pre>"},{"location":"apunts/04_regressio/02_polinomica/#coeficients-del-model","title":"Coeficients del model","text":"<p>Una vegada s'ha entrenat el model, podem obtenir els coeficients del polinomi obtingut.</p> <ul> <li><code>coef_</code>: coeficients de les variables independents.</li> <li><code>intercept_</code>: terme independent de la recta.</li> </ul> <pre><code>print(f'Coeficients: {model.named_steps[\"linearregression\"].coef_}')\nprint(f'Intercept: {model.named_steps[\"linearregression\"].intercept_}')\n</code></pre> <pre><code>Coeficients: [-1.63821771  5.24145621  0.09552926]\nIntercept: -362.88402429981306\n</code></pre> Polinomi originalPolinomi regressi\u00f3 polin\u00f2mica \\[ Y = -100 - 5X + 5X^2 + 0.1X^3 \\] \\[ Y = -93.54 - 5.88X + 5.00X^2 + 0.10X^3 \\]"},{"location":"apunts/04_regressio/02_polinomica/#prediccio-i-avaluacio-amb-el-model","title":"Predicci\u00f3 i avaluaci\u00f3 amb el model","text":"<p>Una vegada entrenat, podem fer prediccions amb el model i avaluar-lo.</p> <pre><code>pred_Y = model.predict(X_test)\n\nrmse = mean_squared_error(Y_test, pred_Y)\nr2 = r2_score(Y_test, pred_Y)\nprint(f'RMSE polin\u00f2mica: {rmse:.2f}')\nprint(f'R^2 polin\u00f2mica: {r2:.2f}')\n</code></pre> <pre><code>RMSE polin\u00f2mica: 642049.3\nR2 polin\u00f2mica: 0.97\n</code></pre>"},{"location":"apunts/04_regressio/02_polinomica/#visualitzacio-del-model","title":"Visualitzaci\u00f3 del model","text":"<p>Podem visualitzar el model de regressi\u00f3 lineal amb una gr\u00e0fica.</p> <pre><code>plt.scatter(X_train, Y_train, color='blue')\nplt.scatter(X_test, Y_test, color='orange')\nplt.plot(X_test, pred_Y, color='red')\nplt.show()\n</code></pre> <p></p> <p>Figura 3. Model de regressi\u00f3 polin\u00f2mica</p>"},{"location":"apunts/04_regressio/02_polinomica/#codi-font","title":"Codi font","text":"regressio_polinomica.py<pre><code>#!/usr/bin/env python\n\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\ndef f(x):\n    return -100 - 5*x + 5*np.power(x, 2) + 0.1*np.power(x, 3)\n\nnp.random.seed(42)\nn_samples = 100\n\nX = np.random.uniform(-50, 50, n_samples)\nY = f(X) + np.random.randn(n_samples)*1000\nX = X.reshape(-1, 1) # Convertim X en una matriu de 1 columna\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\nX_test, Y_test = zip(*sorted(zip(X_test, Y_test))) # Ordenem les dades de test per visualitzar-les correctament\n\nimport matplotlib.pyplot as plt\n\nplt.scatter(X_train, Y_train, color='blue')\nplt.scatter(X_test, Y_test, color='orange')\nplt.show()\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\n\nmodel = LinearRegression()\nmodel.fit(X_train, Y_train)\n\npred_Y = model.predict(X_test)\n\nrmse = mean_squared_error(Y_test, pred_Y)\nr2 = r2_score(Y_test, pred_Y)\nprint(f'RMSE linear: {rmse:.2f}')\nprint(f'R^2 linear: {r2:.2f}')\n\nplt.scatter(X_train, Y_train, color='blue')\nplt.scatter(X_test, Y_test, color='orange')\nplt.plot(X_test, pred_Y, color='red')\nplt.show()\n\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline\n\ndegree = 3\npolynomial_features = PolynomialFeatures(degree=degree, include_bias=False)\nmodel = make_pipeline(polynomial_features, LinearRegression())\n\nmodel.fit(X_train, Y_train)\n\n\nprint(f'Coeficients: {model.named_steps[\"linearregression\"].coef_}')\nprint(f'Intercept: {model.named_steps[\"linearregression\"].intercept_}')\n\npred_Y = model.predict(X_test)\n\nrmse = mean_squared_error(Y_test, pred_Y)\nr2 = r2_score(Y_test, pred_Y)\nprint(f'RMSE polin\u00f2mica: {rmse:.2f}')\nprint(f'R^2 polin\u00f2mica: {r2:.2f}')\n\nplt.scatter(X_train, Y_train, color='blue')\nplt.scatter(X_test, Y_test, color='orange')\nplt.plot(X_test, pred_Y, color='red')\nplt.show()\n</code></pre>"},{"location":"apunts/04_regressio/02_polinomica/#bibliografia","title":"Bibliografia","text":"<ul> <li>Material del m\u00f2dul \"Sistemes d'Aprenentatge Autom\u00e0tic\" de C\u00e9sar Guijarro de C\u00e9sar Guijarro Rosaleny</li> <li>Regressi\u00f3 polin\u00f2mica \u2013 Viquip\u00e8dia</li> <li>Polynomial Regression in Python using scikit-learn (with a practical example)</li> </ul>"},{"location":"apunts/04_regressio/03_arbres_decisio/","title":"Regressi\u00f3 amb arbres de decisi\u00f3","text":""},{"location":"apunts/04_regressio/03_arbres_decisio/#regressio-amb-arbres-de-decisio","title":"Regressi\u00f3 amb arbres de decisi\u00f3","text":"<p>Els arbres de decisi\u00f3 (decision trees o DT) s\u00f3n models d'aprenentatge autom\u00e0tic supervisat que poden resoldre problemes de classificaci\u00f3 i regressi\u00f3.</p> <p>Aquests models es basen l'aprenentatge de decisions simples a partir de les dades en forma d'estructura d'arbre.</p> Classificaci\u00f3Regressi\u00f3 <p></p> <p>scikit-learn: Decision Trees</p> <p>Figura 1. Exemple d'arbre de decisi\u00f3 de classificaci\u00f3 del conjunt de dades Iris.</p> <p></p> <p>scikit-learn: Decision Trees</p> <p>Figura 2. Exemple d'arbre de decisi\u00f3 de regressi\u00f3 de la funci\u00f3 \\(\\sin(x)\\).</p>"},{"location":"apunts/04_regressio/03_arbres_decisio/#model-de-regressio-amb-arbres-de-decisio","title":"Model de regressi\u00f3 amb arbres de decisi\u00f3","text":"<p>Els arbres de decisi\u00f3 poden ser utilitzats per resoldre problemes de regressi\u00f3.</p> <p>Podem crear un model de regressi\u00f3 amb arbres de decisi\u00f3 amb scikit-learn mitjan\u00e7ant la classe <code>DecisionTreeRegressor</code>.</p> <p>Documentaci\u00f3</p> <p>Documentaci\u00f3 oficial de <code>DecisionTreeRegressor</code></p> Preparaci\u00f3 de les dades <p>Anem a generar un conjunt de dades que s'ajusten la funci\u00f3 \\(\\sin(x)\\) amb una lleugera desviaci\u00f3.</p> <pre><code>import numpy as np\nfrom sklearn.model_selection import train_test_split\n\n\ndef f(x):\n    return np.sin(x / 5)\n\nnp.random.seed(42)\nn_samples = 200\n\nX = np.random.uniform(-50, 50, n_samples)\nY = f(X) + np.random.randn(n_samples) * 0.25\nX = X.reshape(-1, 1) # Convertim X en una matriu de 1 columna\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\nX_test, Y_test = zip(*sorted(zip(X_test, Y_test))) # Ordenem les dades de test per visualitzar-les correctament\n</code></pre> <p></p> <p>Figura 3. Dades generades a partir de la funci\u00f3 \\(\\sin(x)\\).</p>"},{"location":"apunts/04_regressio/03_arbres_decisio/#creacio-del-model","title":"Creaci\u00f3 del model","text":"<p>El model <code>DecisionTreeRegressor</code> t\u00e9 el hiperpar\u00e0metre <code>max_depth</code> que determina la profunditat m\u00e0xima de l'arbre de decisi\u00f3.</p> <p>Un valor massa alt d'aquest par\u00e0metre pot provocar sobreajustament (overfitting).</p> <pre><code>from sklearn.tree import DecisionTreeRegressor\n\nmax_depth = 5\nmodel = DecisionTreeRegressor(max_depth=max_depth)\n</code></pre>"},{"location":"apunts/04_regressio/03_arbres_decisio/#entrenament-del-model","title":"Entrenament del model","text":"<p>Per entrenar el model amb les dades, utilitzem el m\u00e8tode <code>fit</code> de la classe <code>DecisionTreeRegressor</code>.</p> <pre><code>model.fit(X_train, Y_train)\n</code></pre>"},{"location":"apunts/04_regressio/03_arbres_decisio/#prediccio-i-avaluacio-del-model","title":"Predicci\u00f3 i avaluaci\u00f3 del model","text":"<p>Una vegada entrenat, podem fer prediccions amb el model i avaluar-lo.</p> <pre><code>from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\n\npred_Y = model.predict(X_test)\n\nrmse = mean_squared_error(Y_test, pred_Y)\nr2 = r2_score(Y_test, pred_Y)\nprint(f'RMSE arbre decisi\u00f3: {rmse:.2f}')\nprint(f'R2 arbre decisi\u00f3: {r2:.2f}')\n</code></pre> <pre><code>RMSE arbre decisi\u00f3: 0.11\nR2 arbre decisi\u00f3: 0.81\n</code></pre>"},{"location":"apunts/04_regressio/03_arbres_decisio/#visualitzacio-de-larbre-de-decisio","title":"Visualitzaci\u00f3 de l'arbre de decisi\u00f3","text":"<p>Podem visualitzar l'arbre de decisi\u00f3 de les dades de prova amb una gr\u00e0fica.</p> <pre><code>import matplotlib.pyplot as plt\n\nplt.scatter(X_train, Y_train, color='blue')\nplt.scatter(X_test, Y_test, color='orange')\nplt.plot(X_test, pred_Y, color='red', lw=2)\nplt.show()\n</code></pre> <p></p> <p>Figura 4. Model de regressi\u00f3 mitjan\u00e7ant arbre de decisi\u00f3.</p> <p>Tamb\u00e9 podem visualitzar l'arbre de decisi\u00f3 amb la llibreria <code>graphviz</code>.</p> <pre><code>from sklearn.tree import export_graphviz\nfrom graphviz import Source\n\n# Export the tree to a DOT format\ndot_data = export_graphviz(\n    model,\n    out_file=None,  # Leave as None to return the DOT data as a string\n    filled=True,  # Color the nodes based on their values\n    rounded=True,  # Round the corners of the boxes\n    special_characters=True  # Allow for special characters in labels\n)\n\n# Render the DOT data to a graph\ngraph = Source(dot_data)\ngraph.format = \"png\"\ngraph.render(\"decision_tree\")\ngraph.view()  # Open the PNG file\n</code></pre> <p></p> <p>Figura 5. Arbre de decisi\u00f3 generat pel model.</p>"},{"location":"apunts/04_regressio/03_arbres_decisio/#codi-font","title":"Codi font","text":"arbres_decisio.py<pre><code>#!/usr/bin/env python\n\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\n\ndef f(x):\n    return np.sin(x / 5)\n\nnp.random.seed(42)\nn_samples = 200\n\nX = np.random.uniform(-50, 50, n_samples)\nY = f(X) + np.random.randn(n_samples) * 0.25\nX = X.reshape(-1, 1) # Convertim X en una matriu de 1 columna\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\nX_test, Y_test = zip(*sorted(zip(X_test, Y_test))) # Ordenem les dades de test per visualitzar-les correctament\n\nimport matplotlib.pyplot as plt\n\nplt.scatter(X_train, Y_train, color='blue')\nplt.scatter(X_test, Y_test, color='orange')\nplt.show()\n\nfrom sklearn.tree import DecisionTreeRegressor\n\nmax_depth = 5\nmodel = DecisionTreeRegressor(max_depth=max_depth)\n\nmodel.fit(X_train, Y_train)\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\n\npred_Y = model.predict(X_test)\n\nrmse = mean_squared_error(Y_test, pred_Y)\nr2 = r2_score(Y_test, pred_Y)\nprint(f'RMSE arbre decisi\u00f3: {rmse:.2f}')\nprint(f'R2 arbre decisi\u00f3: {r2:.2f}')\n\nimport matplotlib.pyplot as plt\n\nplt.scatter(X_train, Y_train, color='blue')\nplt.scatter(X_test, Y_test, color='orange')\nplt.plot(X_test, pred_Y, color='red', lw=2)\nplt.show()\n\nfrom sklearn.tree import export_graphviz\nfrom graphviz import Source\n\n# Export the tree to a DOT format\ndot_data = export_graphviz(\n    model,\n    out_file=None,  # Leave as None to return the DOT data as a string\n    filled=True,  # Color the nodes based on their values\n    rounded=True,  # Round the corners of the boxes\n    special_characters=True  # Allow for special characters in labels\n)\n\n# Render the DOT data to a graph\ngraph = Source(dot_data)\ngraph.format = \"png\"\ngraph.render(\"decision_tree\")\ngraph.view()  # Open the PNG file\n</code></pre>"},{"location":"apunts/04_regressio/03_arbres_decisio/#recursos-addicionals","title":"Recursos addicionals","text":"<ul> <li>\u00bfQu\u00e9 es Decision Tree y Random Forest? | MindMachineTV</li> <li>Decision Tree - Interpretable machine learning</li> <li>Visualizing and interpreting decision trees - TensorFlow Blog</li> </ul>"},{"location":"apunts/04_regressio/03_arbres_decisio/#bibliografia","title":"Bibliografia","text":"<ul> <li>Material del m\u00f2dul \"Sistemes d'Aprenentatge Autom\u00e0tic\" de C\u00e9sar Guijarro de C\u00e9sar Guijarro Rosaleny   </li> <li>Decision Trees - scikit-learn</li> <li>Decision Tree - Wikipedia</li> </ul>"},{"location":"apunts/04_regressio/04_gradient/","title":"Descens del gradient","text":""},{"location":"apunts/04_regressio/04_gradient/#descens-del-gradient","title":"Descens del gradient","text":"<p>L'algorisme del gradient descendent \u00e9s un m\u00e8tode iteratiu d'optimitzaci\u00f3 que permet trobar el m\u00ednim d'una funci\u00f3.</p> <p>Aquest algorisme es basa en utilitzar la derivada de la funci\u00f3 de cost per trobar la direcci\u00f3 en la qual la funci\u00f3 de cost descendeix m\u00e9s r\u00e0pidament.</p> <p>Aquest algorisme \u00e9s molt \u00fatil ja que permet la utilitzaci\u00f3 de diferents funcions de cost i diferents m\u00e8todes de regularitzaci\u00f3.</p>"},{"location":"apunts/04_regressio/04_gradient/#funcio-de-cost","title":"Funci\u00f3 de cost","text":"<p>La funci\u00f3 de cost \u00e9s una funci\u00f3 que mesura la difer\u00e8ncia entre els valors predits pel model i els valors reals de les dades.</p> <p>Aquesta funci\u00f3 \u00e9s la que l'algorisme del gradient descendent tracta d'optimitzar i minimitzar.</p> <p>En el cas de problemes de regressi\u00f3, trobem les seg\u00fcents funcions de cost:</p> <ul> <li><code>squared_loss</code>: MSE \u2013 Error quadr\u00e0tic mitj\u00e0.</li> <li><code>huber</code>: funci\u00f3 de cost robusta a outliers.</li> <li><code>epsilon_insensitive</code>: funci\u00f3 de cost de m\u00e0quina de suport vectorial.</li> </ul>"},{"location":"apunts/04_regressio/04_gradient/#regulitzacio","title":"Regulitzaci\u00f3","text":"<p>La regularitzaci\u00f3 \u00e9s un m\u00e8tode que permet evitar el sobreajustament dels models de regressi\u00f3.</p> <p>Aquest m\u00e8tode consisteix en afegir un terme a la funci\u00f3 de cost que penalitza els pesos del model, evitant que aprenguen massa els valors de les dades d'entrenament.</p> <p>Els dos m\u00e8todes de regularitzaci\u00f3 m\u00e9s comuns s\u00f3n:</p> <ul> <li><code>l1</code>: regularitzaci\u00f3 L1 o Lasso.</li> <li><code>l2</code>: regularitzaci\u00f3 L2 o Ridge.</li> </ul>"},{"location":"apunts/04_regressio/04_gradient/#sgdregressor","title":"<code>SGDRegressor</code>","text":"<p>La classe <code>SGDRegressor</code> de <code>scikit-learn</code> implementa l'algorisme del gradient descendent estoc\u00e0stic (Stochastic Gradient Descent o SGD).</p> <pre><code>from sklearn.linear_model import SGDRegressor\n\nmodel = SGDRegressor(loss='squared_loss', penalty='l2')\n</code></pre> <p>Aquest model t\u00e9 els seg\u00fcents hiperpar\u00e0metres:</p> <ul> <li><code>loss</code>: funci\u00f3 de cost a optimitzar (per defecte: <code>squared_loss</code>).</li> <li><code>penalty</code>: m\u00e8tode de regularitzaci\u00f3 (per defecte: <code>l2</code>).</li> <li><code>alpha</code>: terme de regularitzaci\u00f3 (per defecte: <code>0.0001</code>).</li> <li><code>max_iter</code>: nombre m\u00e0xim d'iteracions (per defecte: <code>1000</code>).</li> <li><code>shuffle</code>: barreja les dades a cada iteraci\u00f3 (per defecte: <code>True</code>).</li> </ul> <p>Documentaci\u00f3</p> <p>Documentaci\u00f3 oficial de <code>SGDRegressor</code></p>"},{"location":"apunts/04_regressio/04_gradient/#codi-font","title":"Codi font","text":"<p>Aquest exemple utilitza el proc\u00e9s de Normalitzaci\u00f3 de les dades mitjan\u00e7ant la classe <code>StandardScaler</code>, que encara no hem estudiat.</p> descens_gradient.py<pre><code>#!/usr/bin/env python\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\ndef f(x):\n    return 3*x + 100\n\nnp.random.seed(42)\nn_samples = 50\n\nX = np.random.uniform(-50, 50, n_samples)\nY = f(X) + np.random.randn(n_samples) * 10\nX = X.reshape(-1, 1) # Convertim X en una matriu de 1 columna\nY[10] = 1000\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nY = scaler.fit_transform(Y.reshape(-1, 1)).ravel()\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\nX_test, Y_test = zip(*sorted(zip(X_test, Y_test))) # Ordenem les dades de test per visualitzar-les correctament\n\n\nfrom sklearn.linear_model import SGDRegressor\n\nmax_iter = 1000\nmodels = {\n    \"huber_small_e\": SGDRegressor(loss='huber', max_iter=max_iter, epsilon=0.1),\n    \"huber_large_e\": SGDRegressor(loss='huber', max_iter=max_iter, epsilon=2.5),\n    \"epsilon_insensitive\": SGDRegressor(loss='epsilon_insensitive', max_iter=max_iter, epsilon=0.1),\n    \"squared_error\": SGDRegressor(loss='squared_error', max_iter=max_iter),\n}\ncolors = ['red', 'green', 'cyan', 'magenta']\n\nimport matplotlib.pyplot as plt\n\nplt.scatter(X_train, Y_train, color='blue')\nplt.scatter(X_test, Y_test, color='orange')\n\nfor i, (title, model) in enumerate(models.items()):\n    model.fit(X_train, Y_train)\n\n    pred_Y = model.predict(X_test)\n\n    from sklearn.metrics import root_mean_squared_error\n    from sklearn.metrics import r2_score\n\n    rmse = root_mean_squared_error(Y_test, pred_Y)\n    r2 = r2_score(Y_test, pred_Y)\n    print(f'RMSE {title}: {rmse:.2f}')\n    print(f'R^2 {title}: {r2:.2f}')\n\n    X_plot = [X.min(), X.max()]\n    Y_plot = model.predict(np.array(X_plot).reshape(-1, 1))\n\n    plt.plot(X_plot, Y_plot, color=colors[i], lw=2)\n\nplt.legend([\"train\", \"test\"] + list(models.keys()))\nplt.show()\n</code></pre>"},{"location":"apunts/04_regressio/04_gradient/#recursos-addicionals","title":"Recursos addicionals","text":"<ul> <li>\u00bfQu\u00e9 es el Descenso del Gradiente? Algoritmo de Inteligencia Artificial | DotCSV </li> <li>IA NOTEBOOK #3 | Descenso del Gradiente (Gradient Descent) | Programando IA </li> </ul>"},{"location":"apunts/04_regressio/04_gradient/#bibliografia","title":"Bibliografia","text":"<ul> <li>Algorisme del gradient descendent \u2013 Viquip\u00e8dia</li> <li>1.5. Stochastic Gradient Descent \u2013 scikit-learn</li> <li>Huber loss - Wikipedia</li> </ul>"},{"location":"apunts/04_regressio/05_altres/","title":"Altres models de regressi\u00f3","text":""},{"location":"apunts/04_regressio/05_altres/#altres-models-de-regressio","title":"Altres models de regressi\u00f3","text":"<p>A part dels models de regressi\u00f3 vistos fins ara, hi ha molts altres models que es poden utilitzar per resoldre problemes de regressi\u00f3.</p> <p>Aquesta p\u00e0gina recull alguns d'aquests models i com es poden utilitzar amb la biblioteca <code>scikit-learn</code>.</p>"},{"location":"apunts/04_regressio/05_altres/#gaussian-process-regression-gpr","title":"Gaussian Process Regression (GPR)","text":"<p>La classe <code>GaussianProcessRegressor</code> de <code>scikit-learn</code> implementa el model de regressi\u00f3 de processos gaussians (Gaussian Process Regression o GPR).</p>"},{"location":"apunts/04_regressio/05_altres/#recursos","title":"Recursos","text":"<ul> <li>Gaussian Process Regression - scikit-learn</li> <li>Gaussian Processes regression: basic introductory example - scikit-learn</li> </ul>"},{"location":"apunts/04_regressio/05_altres/#support-vector-regression-svr","title":"Support Vector Regression (SVR)","text":"<p>La classe <code>SVR</code> de <code>scikit-learn</code> implementa el model de regressi\u00f3 (Support Vector Regression o SVR) de m\u00e0quina de suport vectorial (Support Vector Machine o SVM).</p>"},{"location":"apunts/04_regressio/05_altres/#recursos_1","title":"Recursos","text":"<ul> <li>Support Vector Regression Tutorial for Machine Learning - Analytics Vidhya</li> <li>Support Vector Machine (SVM) - scikit-learn</li> <li>Support Vector Regression (SVR) using linear and non-linear kernels - scikit-learn</li> </ul>"},{"location":"apunts/05_preprocessament/01_normalitat/","title":"An\u00e0lisi de la normalitat","text":""},{"location":"apunts/05_preprocessament/01_normalitat/#analisi-de-la-normalitat","title":"An\u00e0lisi de la normalitat","text":""},{"location":"apunts/05_preprocessament/02_normalitzacio/","title":"Normalitzaci\u00f3","text":""},{"location":"apunts/05_preprocessament/02_normalitzacio/#normalitzacio","title":"Normalitzaci\u00f3","text":""},{"location":"apunts/05_preprocessament/030_reduccio_dimensionalitat/","title":"Reduccio de la dimensionalitat","text":""},{"location":"apunts/05_preprocessament/030_reduccio_dimensionalitat/#reduccio-de-la-dimensionalitat","title":"Reducci\u00f3 de la dimensionalitat","text":"<p>S'ent\u00e9n com reducci\u00f3 de dimensionalitat les diferents t\u00e8cniques que permeten reduir el nombre de caracter\u00edstiques o variables d'un conjunt de dades, per\u00f2 tractant de mantindre la major part de la informaci\u00f3.</p> <p>Reduir la dimensionalitat pot ser \u00fatil per millorar el rendiment dels algoritmes d'aprenentatge autom\u00e0tic, ja que permet:</p> <ul> <li>Simplificar el model, que a m\u00e9s ser\u00e0 m\u00e9s f\u00e0cil d'interpretar.</li> <li>Reduir els requeriments computacionals i temps de c\u00e0lcul.</li> <li>Evitar que les dades siguen excessivament disperses.</li> </ul>"},{"location":"apunts/05_preprocessament/030_reduccio_dimensionalitat/#tecniques-de-reduccio-de-dimensionalitat","title":"T\u00e8cniques de reducci\u00f3 de dimensionalitat","text":"<p>Les t\u00e8cniques de reducci\u00f3 de dimensionalitat es poden dividir en dos grans grups:</p> <ul> <li> <p>Selecci\u00f3 de caracter\u00edstiques (feature selection): Consisteix en seleccionar un subconjunt de les caracter\u00edstiques originals.</p> <p>La principal premisa \u00e9s que no totes les caracter\u00edstiques s\u00f3n rellevants per a la tasca de predicci\u00f3, ja que les dades poden contindre caracter\u00edstiques que s\u00f3n irrelevants o redundants. Aquestes caracter\u00edstiques poden ser eliminades sense afectar la informaci\u00f3 del conjunt de dades.</p> </li> <li> <p>Extracci\u00f3 de caracter\u00edstiques (feature extraction): Consisteix en transformar les caracter\u00edstiques originals en un nou conjunt     de caracter\u00edstiques, que s\u00f3n una combinaci\u00f3 de les caracter\u00edstiques originals. Aquestes noves caracter\u00edstiques     s\u00f3n anomenades components i emmagatzemen la major part de la informaci\u00f3 de les caracter\u00edstiques originals.</p> </li> </ul>"},{"location":"apunts/05_preprocessament/030_reduccio_dimensionalitat/#seleccio-de-caracteristiques","title":"Selecci\u00f3 de caracter\u00edstiques","text":"<p>Dins de les t\u00e8cniques de selecci\u00f3 de caracter\u00edstiques, podem classificar-les en diferents categories:</p> <ul> <li> <p>M\u00e9todes de filtre: S\u00f3n m\u00e8todes que analitzen la relev\u00e0ncia de les caracter\u00edstiques a partir d'una funci\u00f3 sobre les dades.     Aquesta funci\u00f3 pot ser una mesura estad\u00edstica com la varian\u00e7a o la correlaci\u00f3, i \u00e9s independent de l'algoritme d'aprenentatge     autom\u00e0tic que s'utilitzar\u00e0.</p> <p>Aquests m\u00e8todes poden ser:</p> <ul> <li> <p>Univariats, que analitzen les caracter\u00edstiques de manera individual.</p> <p>Exemple VarianceThreshold: Elimina les caracter\u00edstiques amb baixa vari\u00e0ncia.</p> </li> <li> <p>Multivariats, que analitzen les caracter\u00edstiques de manera conjunta.</p> <p>Exemple Correlation-based Feature Selection: Elimina les caracter\u00edstiques amb alta correlaci\u00f3.</p> </li> </ul> </li> <li> <p>M\u00e8todes d'envoltura: S\u00f3n m\u00e8todes que seleccionen les caracter\u00edstiques basant-se     en el rendiment d'un model d'aprenentatge autom\u00e0tic.</p> <p>Aquests m\u00e8todes poden ser:</p> <ul> <li>Forward selection: Comen\u00e7a amb un conjunt buit de caracter\u00edstiques i va afegint-ne una a una.</li> <li>Backward elimination: Comen\u00e7a amb totes les caracter\u00edstiques i va eliminant-ne una a una.</li> <li>Bidirectional selection: Combina els dos m\u00e8todes anteriors.</li> </ul> </li> </ul>"},{"location":"apunts/05_preprocessament/030_reduccio_dimensionalitat/#extraccio-de-caracteristiques","title":"Extracci\u00f3 de caracter\u00edstiques","text":"<p>Alguns dels m\u00e8todes m\u00e9s comuns d'extracci\u00f3 de caracter\u00edstiques num\u00e8riques s\u00f3n:</p> <ul> <li> <p>PCA (Principal Component Analysis): \u00c9s una t\u00e8cnica de reducci\u00f3 de dimensionalitat que transforma les caracter\u00edstiques originals     en un nou conjunt de caracter\u00edstiques no correlacionades anomenades components principals.</p> </li> <li> <p>LDA (Linear Discriminant Analysis): \u00c9s una t\u00e8cnica de reducci\u00f3 de dimensionalitat que transforma les caracter\u00edstiques originals     en un nou conjunt de caracter\u00edstiques que maximitzen la separaci\u00f3 entre les classes.</p> </li> </ul>"},{"location":"apunts/05_preprocessament/030_reduccio_dimensionalitat/#bibliografia","title":"Bibliografia","text":"<ul> <li>Viquip\u00e8dia - Reducci\u00f3 de dimensionalitat</li> <li>Stats StackExchange - Should we normalize before using VarianceThreshold in sklearn?</li> </ul>"},{"location":"apunts/05_preprocessament/031_filtre/","title":"Selecci\u00f3 de caracter\u00edstiques: M\u00e8todes de filtre","text":""},{"location":"apunts/05_preprocessament/031_filtre/#seleccio-de-caracteristiques-metodes-de-filtre","title":"Selecci\u00f3 de caracter\u00edstiques: M\u00e8todes de filtre","text":"<p>Els m\u00e8todes de filtre s\u00f3n una t\u00e8cnica de reducci\u00f3 de dimensionalitat basada en la selecci\u00f3 de caracter\u00edstiques que analitzen la relev\u00e0ncia de les caracter\u00edstiques a partir d'una funci\u00f3 sobre les dades.</p>"},{"location":"apunts/05_preprocessament/031_filtre/#umbral-de-variancia","title":"Umbral de vari\u00e0ncia","text":"<p>L'umbral de vari\u00e0ncia \u00e9s una t\u00e8cnica de filtre univariada que es basa en eliminar les caracter\u00edstiques amb baixa vari\u00e0ncia, ja que aquestes no aporten informaci\u00f3 rellevant al model.</p> <p>La classe <code>VarianceThreshold</code> de <code>scikit-learn</code> permet eliminar les caracter\u00edstiques amb baixa vari\u00e0ncia.</p> <pre><code>constant_filter = VarianceThreshold(threshold=0)\nconstant_filter.fit_transform(X_train)\nconstant_filter.transform(X_test)\n</code></pre> <p>El par\u00e0metre <code>threshold</code> indica el valor de la vari\u00e0ncia per sobre del qual les caracter\u00edstiques seran considerades.</p> <ul> <li>Si <code>threshold=0</code>, es eliminaran les caracter\u00edstiques amb vari\u00e0ncia zero.</li> <li>Si <code>threshold</code> \u00e9s un valor diferent de zero, es eliminaran les caracter\u00edstiques amb vari\u00e0ncia inferior a aquest valor.</li> </ul> <p>En aquest cas, \u00e9s important normalitzar les dades mitjan\u00e7ant <code>MinMaxScaler</code>    per evitar que l'escala afecte al c\u00e0lcul de la vari\u00e0ncia.</p>"},{"location":"apunts/05_preprocessament/031_filtre/#basada-en-correlacio","title":"Basada en correlaci\u00f3","text":"<p>La selecci\u00f3 de caracter\u00edstiques basada en correlaci\u00f3 \u00e9s una t\u00e8cnica de filtre multivariada que elimina les caracter\u00edstiques amb alta correlaci\u00f3, ja que aquestes aporten la mateixa informaci\u00f3 al model.</p> <p>Per eliminar les caracter\u00edstiques amb alta correlaci\u00f3, cal seguir els seg\u00fcents passos:</p> <ol> <li>Obtindre la matriu de correlaci\u00f3 de les caracter\u00edstiques.</li> </ol> <pre><code>corr_matrix = X_train.corr().abs()\n</code></pre> <ol> <li>Seleccionar la part superior de la matriu de correlaci\u00f3,    ja que la matriu \u00e9s sim\u00e8trica i la diagonal principal cont\u00e9    la correlaci\u00f3 de cada caracter\u00edstica amb ella mateixa.</li> </ol> <pre><code>upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n</code></pre> <ol> <li>Trobar les caracter\u00edstiques amb una correlaci\u00f3 superior a un determinat umbral,    que seran les que eliminarem.</li> </ol> <pre><code>corr_threshold = 0.7\nto_drop = [column for column in upper.columns if any(upper[column] &gt; corr_threshold)]\n</code></pre> <ol> <li>Eliminar les caracter\u00edstiques amb alta correlaci\u00f3.</li> </ol> <pre><code># Drop features\nX_train = X_train.drop(columns=to_drop, axis=1)\nX_test = X_test.drop(columns=to_drop, axis=1)\n</code></pre>"},{"location":"apunts/05_preprocessament/031_filtre/#codi-font","title":"Codi font","text":"reduccio_filtres.py<pre><code>import pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\ndf = pd.read_csv('./../files/ud5/laptop_pricing_cleaned.csv', index_col=0)\ndf = df.iloc[:, 1:]\ndf = df.select_dtypes(include=['number'])\n\nX = df.drop(columns = 'Price', axis = 1)\ny = df['Price']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size   = 0.7)\n\n# scaler = preprocessing.MinMaxScaler()\n# X_train = scaler.fit_transform(X_train)\n\n# print(X_train)\n\n# Filtre univariant - Variables costants (VarianceThreshold)\nconstant_filter = VarianceThreshold(threshold=0)\nconstant_filter.fit(X_train)\n\nprint(X_train.var())\nprint(\"Columnas originales: \", len(X_train.columns))\nprint(\"Columnas despr\u00e9s del threshold: \", len(X_train.columns[constant_filter.get_support()]))\nprint(X_train.columns[constant_filter.get_support()])\n\n# Filtre multivariant - Variables correlacionades entre si\nfigure = plt.figure(figsize = (15, 10))\naxes = figure.add_subplot()\ncorr_features = X_train.corr()\n_ = sns.heatmap(corr_features, annot=True, cmap=plt.cm.coolwarm, axes = axes)\n# plt.show()\n\ncorr_threshold = 0.7\ncorr_matrix = X_train.corr().abs()\n\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\nprint(upper)\n\nto_drop = [column for column in upper.columns if any(upper[column] &gt; corr_threshold)]\nprint(to_drop)\n\n# Drop features\nX_train = X_train.drop(columns=to_drop, axis=1)\nX_test = X_test.drop(columns=to_drop, axis=1)\n\nprint(X_train.shape)\n</code></pre>"},{"location":"apunts/05_preprocessament/031_filtre/#bibliografia","title":"Bibliografia","text":"<ul> <li>Material del m\u00f2dul \"Sistemes d'Aprenentatge Autom\u00e0tic\" de C\u00e9sar Guijarro de C\u00e9sar Guijarro Rosaleny</li> </ul>"},{"location":"apunts/05_preprocessament/032_envoltura/","title":"Selecci\u00f3 de caracter\u00edstiques: M\u00e8todes d'envoltura","text":""},{"location":"apunts/05_preprocessament/032_envoltura/#seleccio-de-caracteristiques-metodes-denvoltura","title":"Selecci\u00f3 de caracter\u00edstiques: M\u00e8todes d'envoltura","text":"<p>Els m\u00e8todes d'envoltura s\u00f3n una t\u00e8cnica de reducci\u00f3 de dimensionalitat basada en la selecci\u00f3 de caracter\u00edstiques que seleccionen les caracter\u00edstiques basant-se en el rendiment d'un model d'aprenentatge autom\u00e0tic.</p>"},{"location":"apunts/05_preprocessament/032_envoltura/#seleccio-cap-endavant","title":"Selecci\u00f3 cap endavant","text":"<p>La selecci\u00f3 cap endavant (forward selection) \u00e9s un m\u00e8tode d'envoltura que es basa en seleccionar les caracter\u00edstiques d'una a una, afegint la caracter\u00edstica que millora m\u00e9s el rendiment del model en cada pas.</p> <p>La classe <code>SequentialFeatureSelector</code> de <code>mlxtend</code> implementa aquest m\u00e8tode, utilitzant el par\u00e0metre <code>forward=True</code>.</p> <pre><code>from mlxtend.feature_selection import SequentialFeatureSelector as SFS\nfrom sklearn.linear_model import LinearRegression\n\nk_features = 5\nsfs = SFS(LinearRegression(),\n          k_features=k_features,\n          forward=True,\n          floating=False,\n          scoring = 'r2',\n          cv = 0)\nsfs.fit(X_train, y_train)\n\ninitial_features = X_train.columns.tolist()\nselected_features = list(sfs.k_feature_names_)\nremoved_features = list(set(initial_features)-set(selected_features))\n\nprint(\"Initial features: \", initial_features)\nprint()\nprint(f\"## Forward selection (k = {k_features})\")\nprint(\"Selected features: \", selected_features)\nprint(\"Removed features: \", removed_features)\n</code></pre>"},{"location":"apunts/05_preprocessament/032_envoltura/#seleccio-cap-enrere","title":"Selecci\u00f3 cap enrere","text":"<p>La selecci\u00f3 cap enrere (backward elimination) \u00e9s un m\u00e8tode d'envoltura que parteix de totes les caracter\u00edstiques i va eliminant-ne una a una, eliminant la caracter\u00edstica que m\u00e9s empitjora el rendiment del model en cada pas.</p> <p>Aquest m\u00e8tode tamb\u00e9 es pot implementar amb la classe <code>SequentialFeatureSelector</code> de <code>mlxtend</code>, utilitzant el par\u00e0metre <code>forward=False</code>.</p> <pre><code>k_features = 5\nsfs = SFS(LinearRegression(),\n          k_features=k_features,\n          forward=False,\n          floating=False,\n          scoring = 'r2',\n          cv = 0)\nsfs.fit(X_train, y_train)\n\nselected_features = list(sfs.k_feature_names_)\nremoved_features = list(set(initial_features)-set(selected_features))\n\nprint()\nprint(f\"## Backward elimination (k = {k_features})\")\nprint(\"Selected features: \", selected_features)\nprint(\"Removed features: \", removed_features)\n</code></pre>"},{"location":"apunts/05_preprocessament/032_envoltura/#seleccio-bidireccional","title":"Selecci\u00f3 bidireccional","text":"<p>La selecci\u00f3 bidireccional (bidirectional selection) \u00e9s un m\u00e8tode d'envoltura que combina els dos m\u00e8todes anteriors, afegint i eliminant caracter\u00edstiques en cada pas.</p> <p>Aquest m\u00e8tode tamb\u00e9 es pot implementar amb la classe <code>SequentialFeatureSelector</code> de <code>mlxtend</code>, utilitzant el par\u00e0metre floating=True`.</p> <ul> <li><code>forward=True</code> i <code>floating=True</code>: Selecci\u00f3 cap endavant amb possibilitat     d'eliminar caracter\u00edstiques seleccionades.</li> </ul> <pre><code>k_features = 5\nsfs = SFS(LinearRegression(),\n          k_features=k_features,\n          forward=True,\n          floating=True, # Bi-directional\n          scoring = 'r2',\n          cv = 0)\nsfs.fit(X_train, y_train)\n\nselected_features = list(sfs.k_feature_names_)\nremoved_features = list(set(initial_features)-set(selected_features))\n\nprint()\nprint(f\"## Bidirectional forward (k = {k_features})\")\nprint(\"Selected features: \", selected_features)\nprint(\"Removed features: \", removed_features)\n</code></pre> <ul> <li><code>forward=False</code> i <code>floating=True</code>: Selecci\u00f3 cap enrere amb possibilitat     de tornar a afegir caracter\u00edstiques eliminades.</li> </ul> <pre><code>k_features = 5\nsfs = SFS(LinearRegression(),\n          k_features=k_features,\n          forward=False, # Backward\n          floating=True, # Bi-directional\n          scoring = 'r2',\n          cv = 0)\nsfs.fit(X_train, y_train)\n\nselected_features = list(sfs.k_feature_names_)\nremoved_features = list(set(initial_features)-set(selected_features))\n\nprint()\nprint(f\"## Bidirectional backward (k = {k_features})\")\nprint(\"Selected features: \", selected_features)\nprint(\"Removed features: \", removed_features)\n</code></pre>"},{"location":"apunts/05_preprocessament/032_envoltura/#codi-font","title":"Codi font","text":"reduccio_envoltura.py<pre><code>import pandas as pd\n\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.model_selection import train_test_split\n\nfrom mlxtend.feature_selection import SequentialFeatureSelector as SFS\nfrom sklearn.linear_model import LinearRegression\n\ncalifornia = fetch_california_housing()\nX = pd.DataFrame(california.data, columns=california.feature_names)\nY = california.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, train_size = 0.7)\nprint(X_train.shape)\nprint(X_test.shape)\n\nk_features = 5\nsfs = SFS(LinearRegression(),\n          k_features=k_features,\n          forward=True,\n          floating=False,\n          scoring = 'r2',\n          cv = 0)\nsfs.fit(X_train, y_train)\n\ninitial_features = X_train.columns.tolist()\nselected_features = list(sfs.k_feature_names_)\nremoved_features = list(set(initial_features)-set(selected_features))\n\nprint(\"Initial features: \", initial_features)\nprint()\nprint(f\"## Forward selection (k = {k_features})\")\nprint(\"Selected features: \", selected_features)\nprint(\"Removed features: \", removed_features)\n\nk_features = 5\nsfs = SFS(LinearRegression(),\n          k_features=k_features,\n          forward=False,\n          floating=False,\n          scoring = 'r2',\n          cv = 0)\nsfs.fit(X_train, y_train)\n\nselected_features = list(sfs.k_feature_names_)\nremoved_features = list(set(initial_features)-set(selected_features))\n\nprint()\nprint(f\"## Backward elimination (k = {k_features})\")\nprint(\"Selected features: \", selected_features)\nprint(\"Removed features: \", removed_features)\n\nk_features = 5\nsfs = SFS(LinearRegression(),\n          k_features=k_features,\n          forward=True,\n          floating=True, # Bi-directional\n          scoring = 'r2',\n          cv = 0)\nsfs.fit(X_train, y_train)\n\nselected_features = list(sfs.k_feature_names_)\nremoved_features = list(set(initial_features)-set(selected_features))\n\nprint()\nprint(f\"## Bidirectional forward (k = {k_features})\")\nprint(\"Selected features: \", selected_features)\nprint(\"Removed features: \", removed_features)\n\nk_features = 5\nsfs = SFS(LinearRegression(),\n          k_features=k_features,\n          forward=False, # Backward\n          floating=True, # Bi-directional\n          scoring = 'r2',\n          cv = 0)\nsfs.fit(X_train, y_train)\n\nselected_features = list(sfs.k_feature_names_)\nremoved_features = list(set(initial_features)-set(selected_features))\n\nprint()\nprint(f\"## Bidirectional backward (k = {k_features})\")\nprint(\"Selected features: \", selected_features)\nprint(\"Removed features: \", removed_features)\n</code></pre>"},{"location":"apunts/05_preprocessament/032_envoltura/#bibliografia","title":"Bibliografia","text":"<ul> <li>Material del m\u00f2dul \"Sistemes d'Aprenentatge Autom\u00e0tic\" de C\u00e9sar Guijarro de C\u00e9sar Guijarro Rosaleny</li> <li>w3schools - Data Science - Regression Table: P-Value</li> <li><code>mlxtemd</code> - <code>SequentialFeatureSelector</code>: The popular forward and backward feature selection approaches</li> </ul>"},{"location":"apunts/05_preprocessament/033_extraccio/","title":"Extracci\u00f3 de caracter\u00edstiques: PCA i LDA","text":""},{"location":"apunts/05_preprocessament/033_extraccio/#extraccio-de-caracteristiques","title":"Extracci\u00f3 de caracter\u00edstiques","text":"<p>El proc\u00e9s d'extracci\u00f3 de caracter\u00edstiques en la reducci\u00f3 de dimensionalitat consisteix en transformar les caracter\u00edstiques originals en un nou conjunt de caracter\u00edstiques m\u00e9s redu\u00eft, que emmagatzemen la major part de la informaci\u00f3 de les caracter\u00edstiques originals.</p>"},{"location":"apunts/05_preprocessament/033_extraccio/#pca-principal-component-analysis","title":"PCA - Principal Component Analysis","text":"<p>El PCA (Principal Component Analysis) \u00e9s una t\u00e8cnica d'extracci\u00f3 de caracter\u00edstiques que permet reduir la dimensionalitat d'un conjunt de dades, transformant les caracter\u00edstiques originals en un nou conjunt de caracter\u00edstiques no correlacionades anomenades components principals.</p> <pre><code>from sklearn.decomposition import PCA\n\npca = PCA(n_components=n_components)\nX_train_pca = pca.fit_transform(X_train)\nX_test_pca = pca.transform(X_test)\nprint(f\"PCA shape:\", X_train_pca.shape)\n</code></pre>"},{"location":"apunts/05_preprocessament/033_extraccio/#lda-linear-discriminant-analysis","title":"LDA - Linear Discriminant Analysis","text":"<p>El LDA (Linear Discriminant Analysis) \u00e9s una t\u00e8cnica d'extracci\u00f3 de caracter\u00edstiques que permet reduir la dimensionalitat d'un conjunt de dades, transformant les caracter\u00edstiques originals en un nou conjunt de caracter\u00edstiques que maximitzen la separaci\u00f3 entre les classes.</p> <pre><code>from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n\nlda = LDA(n_components=n_components)\nX_train_lda = lda.fit_transform(X_train, y_train)\nX_test_lda = lda.transform(X_test)\nprint(f\"LDA shape:\", X_train_lda.shape)\n</code></pre>"},{"location":"apunts/05_preprocessament/033_extraccio/#codi-font","title":"Codi font","text":"reduccio_extraccio.py<pre><code>import pandas as pd\nfrom sklearn.decomposition import PCA\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import datasets\nfrom sklearn.metrics import accuracy_score\n\nwine = datasets.load_wine()\n\nX = pd.DataFrame(wine.data, columns=wine.feature_names)\ny = wine.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\nprint(\"Original shape:\", X_train.shape)\n\ndef train_test_model(name, X_train, X_test, y_train, y_test):\n    model_knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n    model_knn.fit(X_train, y_train)\n\n    y_pred_rf = model_knn.predict(X_test)\n    print(name, model_knn.__class__.__name__, float(\"{0:.4f}\".format(accuracy_score(y_test, y_pred_rf))))\n\nn_components = 2\n\npca = PCA(n_components=n_components)\nX_train_pca = pca.fit_transform(X_train)\nX_test_pca = pca.transform(X_test)\nprint(f\"PCA shape:\", X_train_pca.shape)\ntrain_test_model(\"PCA\", X_train_pca, X_test_pca, y_train, y_test)\n\nlda = LDA(n_components=n_components)\nX_train_lda = lda.fit_transform(X_train, y_train)\nX_test_lda = lda.transform(X_test)\nprint(f\"LDA shape:\", X_train_lda.shape)\ntrain_test_model(\"LDA\", X_train_lda, X_test_lda, y_train, y_test)\n</code></pre>"},{"location":"apunts/05_preprocessament/033_extraccio/#bibliografia","title":"Bibliografia","text":""},{"location":"programacio/","title":"Programaci\u00f3 did\u00e0ctica","text":"<ul> <li> <p> IABD: Intel\u00b7lig\u00e8ncia Artificial i Big Data.</p> <p>Modalitat presencial. Curs 2024/2025.</p> <p>  Presentaci\u00f3 del m\u00f2dul</p> <p>  Programaci\u00f3 did\u00e0ctica</p> </li> </ul>"},{"location":"programacio/presentacio/","title":"Presentaci\u00f3 del m\u00f2dul","text":""},{"location":"programacio/presentacio/#sistemes-daprenentatge-automatic","title":"Sistemes d'Aprenentatge Autom\u00e0tic","text":""},{"location":"programacio/presentacio/#curs-despecialitazcio-intelligencia-artificial-i-big-data","title":"Curs d'especialitazci\u00f3: Intel\u00b7lig\u00e8ncia Artificial i Big Data","text":""},{"location":"programacio/presentacio/#curs-2024-2025","title":"Curs 2024-2025","text":""},{"location":"programacio/presentacio/#horari","title":"Horari","text":"<p>4 hores setmanals</p> <ul> <li>Dilluns de 19:00 a 20:50</li> <li>Dimecres de 15:55 a 17:45</li> </ul>"},{"location":"programacio/presentacio/#professorat","title":"Professorat","text":"<ul> <li> <p>Joan Puigcerver Ib\u00e1\u00f1ez</p> <p>j.puigcerveribanez@edu.gva.es</p> </li> <li> <p>Andreas Lloyd</p> <p>alloyd@fpmislata.com</p> </li> </ul>"},{"location":"programacio/presentacio/#unitats-didactiques","title":"Unitats did\u00e0ctiques","text":""},{"location":"programacio/presentacio/#1r-trimestre","title":"1r trimestre","text":"<ul> <li>UD1: Introducci\u00f3 a la Intel\u00b7lig\u00e8ncia Artificial</li> <li>UD2: Estad\u00edstica</li> <li>UD3: Manipulaci\u00f3 i visualicaci\u00f3 de dades</li> <li>UD4: Regressi\u00f3</li> </ul>"},{"location":"programacio/presentacio/#unitats-didactiques_1","title":"Unitats did\u00e0ctiques","text":""},{"location":"programacio/presentacio/#2n-trimestre","title":"2n trimestre","text":"<ul> <li>UD5: Preprocessament de dades</li> <li>UD6: Classificaci\u00f3</li> </ul>"},{"location":"programacio/presentacio/#avaluacio-i-qualificacio","title":"Avaluaci\u00f3 i qualificaci\u00f3","text":"<ul> <li>Ex\u00e0mens (40%)</li> <li>Pr\u00e0ctiques (60%)<ul> <li>S'han d'entregar en temps i forma.</li> <li>Han de ser originals.</li> </ul> </li> </ul> <p>En cas contrari, la qualificaci\u00f3 ser\u00e0 de 0.</p> <p>Per m\u00e9s informaci\u00f3, consulta la Programaci\u00f3 did\u00e0ctica</p>"},{"location":"programacio/presentacio/#criteris-minims","title":"Criteris m\u00ednims","text":"<ul> <li>Qualificaci\u00f3 dels ex\u00e0mens major o igual a 5.</li> <li>Qualificaci\u00f3 de les pr\u00e0ctiques major o igual a 5.</li> <li>Superar cada avaluaci\u00f3 per separat.</li> </ul>"},{"location":"programacio/presentacio/#convocatories","title":"Convocat\u00f2ries","text":""},{"location":"programacio/presentacio/#ordinaria","title":"Ordin\u00e0ria","text":"<ul> <li>Ex\u00e0men de cada avaluaci\u00f3 per separat.</li> <li>Pot presentar-se tot l'alumnat.</li> <li>Es mantenen les avaluacions superades.</li> <li>La qualificaci\u00f3 de cada avaluaci\u00f3 major o igual a 5.</li> </ul> <p>Programaci\u00f3 did\u00e0ctica: Avaluaci\u00f3 ordin\u00e0ria</p>"},{"location":"programacio/presentacio/#extraordinaria","title":"Extraordin\u00e0ria","text":"<ul> <li>Examen de cada avaluaci\u00f3 per separat.</li> <li>Es mantenen les avalucions superades.</li> <li>La qualificaci\u00f3 ha de ser major o igual a 5.</li> </ul> <p>Programaci\u00f3 did\u00e0ctica: Avaluaci\u00f3 extraordin\u00e0ria</p>"},{"location":"programacio/programacio/","title":"Programaci\u00f3 did\u00e0ctica","text":"<p>Control de versions:</p> Data Descripci\u00f3 2024-09-18 Primera versi\u00f3 2024-09-24 Correccions a l'apartat Avaluaci\u00f3 2024-10-01 Proposta de millora del curs anterior"},{"location":"programacio/programacio/#1-propostes-de-millora-del-curs-anterior","title":"1. Propostes de millora del curs anterior","text":"<p>Les propostes de millora del curs anterior i les accions realitzades s\u00f3n les seg\u00fcents:</p> <ul> <li> <p>Incorporar conceptes d'estad\u00edstica bayesiana, sobretot en les m\u00e8triques dels models de classificaci\u00f3.</p> <p>En la mesura del possible, es tractar\u00e0 d'introduir algun concepte d'estad\u00edstica bayesiana.</p> </li> </ul>"},{"location":"programacio/programacio/#2-marc-normatiu","title":"2. Marc normatiu","text":"<ul> <li> <p>Llei Org\u00e0nica 3/2022, de 31 de mar\u00e7, d'ordenaci\u00f3 i integraci\u00f3 de la Formaci\u00f3     Professional</p> </li> <li> <p>Reial decret 279/2021, de 20 d'abril, pel qual s'estableix el Curs d'especialitzaci\u00f3     en Intel\u00b7lig\u00e8ncia Artificial i Big Data i es fixen els aspectes b\u00e0sics del     curr\u00edculum.</p> </li> <li> <p>RESOLUCI\u00d3 de 8 d\u2019agost de 2024, de la Secretaria Auton\u00f2mica d\u2019Educaci\u00f3, per la qual es dicten instruccions sobre     ordenaci\u00f3 acad\u00e8mica i d\u2019organitzaci\u00f3 dels centres que impartixen Formaci\u00f3 Professional durant el curs 2024-2025 a la     Comunitat Valenciana</p> </li> </ul>"},{"location":"programacio/programacio/#3-contextualitzacio","title":"3. Contextualitzaci\u00f3","text":"<ul> <li>Codi: 5072</li> <li>Durada: 90 hores</li> <li>Cr\u00e8dits ECTS: 5</li> </ul> <p>Aquest m\u00f2dul professional cont\u00e9 la informaci\u00f3 necess\u00e0ria per a dur a terme les funcions d'analitzar i  relacionar les t\u00e8cniques d'aprenentatge autom\u00e0tic amb la predicci\u00f3 de comportaments futurs que  permeten a les organitzacions i empreses l'efici\u00e8ncia operativa.</p> <p>Les funcions esmentades anteriorment inclouen aspectes com ara:</p> <ul> <li>Caracteritzar sistemes d'aprenentatge autom\u00e0tic.</li> <li>Fer prediccions de comportaments futurs utilitzant models d'aprenentatge autom\u00e0tic.</li> </ul> <p>La formaci\u00f3 del m\u00f2dul contribueix a assolir els objectius generals a), b), c), d), e), f), g), j), k), m), n), \u00f1), o) i p), aix\u00ed com les compet\u00e8ncies professionals i socials a), c), d), e), f), g), j), k), m), n), \u00f1), o), p), q), r) i s) del curs d'especialitzaci\u00f3.</p> <p>Les l\u00ednies d'actuaci\u00f3 en el proc\u00e9s d'ensenyament-aprenentatge que permeten assolir els objectius del m\u00f2dul estan relacionades amb:</p> <ul> <li>La caracteritzaci\u00f3 de sistemes d'aprenentatge autom\u00e0tic.</li> <li>L'aplicaci\u00f3 d'aquests sistemes d'aprenentatge autom\u00e0tic en la presa de decisions a les organitzacions i empreses.</li> </ul>"},{"location":"programacio/programacio/#5-continguts","title":"5. Continguts","text":""},{"location":"programacio/programacio/#bloc-1-caracteritzacio-de-la-intelligencia-artificial-forta-i-debil","title":"Bloc 1 - Caracteritzaci\u00f3 de la Intel\u00b7lig\u00e8ncia Artificial forta i d\u00e8bil","text":"<ul> <li> <p>Intel\u00b7lig\u00e8ncia Artificial D\u00e8bil:</p> <ul> <li>Caracter\u00edstiques i aplicacions.</li> <li>Avantatges i inconvenients.</li> <li>Usos i possibilitats.</li> </ul> </li> <li> <p>Intel\u00b7lig\u00e8ncia Artificial Forta:</p> <ul> <li>Caracter\u00edstiques i aplicacions.</li> <li>Avantatges i inconvenients.</li> <li>Usos i possibilitats.</li> </ul> </li> </ul>"},{"location":"programacio/programacio/#bloc-2-determinacio-de-sistemes-daprenentatge-automatic-machine-learning","title":"Bloc 2 Determinaci\u00f3 de sistemes d'aprenentatge autom\u00e0tic (Machine Learning):","text":"<ul> <li>Classificaci\u00f3 de sistemes d'aprenentatge autom\u00e0tic: Supervisat i no supervisat.</li> <li>Principals t\u00e8cniques per desenvolupar l'aprenentatge autom\u00e0tic:     Xarxes neuronals, aprenentatge inductiu, raonament basat en casos, entre altres.</li> <li>Algoritmes o models aplicats a l'aprenentatge autom\u00e0tic:<ul> <li>Algoritmes de classificaci\u00f3.</li> <li>Algoritmes de detecci\u00f3 d'anomalies.</li> <li>Algoritmes de regressi\u00f3.</li> <li>Algoritmes de clustering.</li> <li>Algoritmes de refor\u00e7 de l'aprenentatge.</li> <li>Arbres i regles de decisi\u00f3.</li> <li>Altres algoritmes relacionats amb l'aprenentatge autom\u00e0tic.</li> </ul> </li> <li>Procediments del Machine Learning: Dades, identificaci\u00f3 de patrons i presa de decisions.</li> <li>Eines d'aprenentatge autom\u00e0tic.</li> <li>Aplicacions del Machine Learning.</li> </ul>"},{"location":"programacio/programacio/#bloc-3-algoritmes-aplicats-a-laprenentatge-supervisat-i-optimitzacio-del-model","title":"Bloc 3: Algoritmes aplicats a l'aprenentatge supervisat i optimitzaci\u00f3 del model:","text":"<ul> <li>Determinaci\u00f3 d'elements i eines d'aprenentatge supervisat.</li> <li>Dades etiquetades.</li> <li>Variables d'entrada (input data). Etiquetes de sortida.</li> <li>Plataformes d'aprenentatge autom\u00e0tic supervisat.</li> <li>Fases de l'aprenentatge autom\u00e0tic:<ul> <li>Selecci\u00f3 de l'algoritme d'aprenentatge supervisat.</li> <li>Selecci\u00f3 de dades.</li> <li>Construcci\u00f3 del model.</li> <li>Validaci\u00f3 del model.</li> <li>Ajust de caracter\u00edstiques o par\u00e0metres.</li> <li>Implementaci\u00f3 del model proposat.</li> <li>Verificaci\u00f3 del model de prova.</li> <li>Optimitzaci\u00f3 del model.</li> </ul> </li> </ul>"},{"location":"programacio/programacio/#bloc-4-aplicacio-de-tecniques-daprenentatge-no-supervisat","title":"Bloc 4: Aplicaci\u00f3 de t\u00e8cniques d'aprenentatge no supervisat:","text":"<ul> <li>T\u00e8cniques d'aprenentatge no supervisat.</li> <li>Algoritmes d'aprenentatge no supervisat: Agrupaci\u00f3 de cl\u00fasters, reducci\u00f3 de dimensi\u00f3, entre altres.</li> <li>Determinaci\u00f3 d'elements i eines d'aprenentatge no supervisat.</li> <li>Plataformes d'aprenentatge autom\u00e0tic no supervisat.</li> <li>Fases de l'aprenentatge autom\u00e0tic no supervisat.</li> </ul>"},{"location":"programacio/programacio/#bloc-5-aplicacio-de-models-computacionals-de-xarxes-neuronals-i-comparacio-amb-altres-models","title":"Bloc 5: Aplicaci\u00f3 de models computacionals de xarxes neuronals i comparaci\u00f3 amb altres models:","text":"<ul> <li>Aprenentatge autom\u00e0tic versus aprenentatge profund.</li> <li>Com apr\u00e8n una xarxa neuronal.</li> <li>Models de xarxes neuronals artificials: Xarxes neuronals convolucionals (CNN).</li> </ul>"},{"location":"programacio/programacio/#bloc-6-valoracio-de-la-qualitat-dels-resultats-obtinguts-en-la-practica-amb-sistemes-daprenentatge-automatic","title":"Bloc 6: Valoraci\u00f3 de la qualitat dels resultats obtinguts en la pr\u00e0ctica amb sistemes d'aprenentatge autom\u00e0tic:","text":"<ul> <li>Capacitat de generalitzaci\u00f3.</li> <li>Test.</li> <li>Validaci\u00f3.</li> <li>Matriu de confusi\u00f3.</li> </ul>"},{"location":"programacio/programacio/#6-distribucio-temporal","title":"6. Distribuci\u00f3 temporal","text":"Blocs Unitats did\u00e0ctiques Avaluaci\u00f3 1 2 3 4 5 6 X X X UD1: Introducci\u00f3 a la Intel\u00b7lig\u00e8ncia Artificial 1 X UD2: Estad\u00edstica X X X UD3: Manipulaci\u00f3 i visualitzaci\u00f3 de dades X UD4: Regressi\u00f3 X X X X X UD5: Preprocessament de dades 2 X UD6: Classificaci\u00f3"},{"location":"programacio/programacio/#7-metodologia-didactica","title":"7. Metodologia did\u00e0ctica","text":"<p>Aquest m\u00f2dul \u00e9s sobretot pr\u00e0ctic. Considerem que la manera millor manera d\u2019aprendre \u00e9s realitzant i resolent els problemes de manera pr\u00e0ctica.</p> <p>Es realitzaran breus explicacions dels continguts combinats amb molts exemples resolts, afavorint la participaci\u00f3 activa de l\u2019alumnat (exposici\u00f3 participativa).</p> <p>A mesura que es va avan\u00e7ant en la unitat, es proporcionaran activitats que vagen augmentant progressivament de dificultat.</p>"},{"location":"programacio/programacio/#8-avaluacio","title":"8. Avaluaci\u00f3","text":""},{"location":"programacio/programacio/#81-criteris-davaluacio","title":"8.1. Criteris d'avaluaci\u00f3","text":"<p>Els resultats d'aprenentatge i els seus corresponents criteris d'avaluaci\u00f3 del m\u00f2dul professional s\u00f3n:</p> <ol> <li> <p>Caracteritza la Intel\u00b7lig\u00e8ncia Artificial forta i d\u00e8bil, determinant-ne els usos i possibilitats.</p> <ol> <li>S'han determinat les especificitats de la Intel\u00b7lig\u00e8ncia Artificial forta i d\u00e8bil.</li> <li>S'han establert les barreres entre la Intel\u00b7lig\u00e8ncia Artificial i l'aprenentatge autom\u00e0tic (Machine Learning).</li> <li>S'han diferenciat els \u00e0mbits d'aplicaci\u00f3 de la Intel\u00b7lig\u00e8ncia Artificial forta i d\u00e8bil.</li> <li>S'han identificat els problemes als quals pot fer front la Intel\u00b7lig\u00e8ncia Artificial d\u00e8bil.</li> <li>S'han identificat els problemes als quals pot fer front la Intel\u00b7lig\u00e8ncia Artificial forta.</li> <li>S'han reconegut els avantatges que proporciona cada tipus en la resoluci\u00f3 de problemes.</li> </ol> </li> <li> <p>Determina t\u00e8cniques i eines de sistemes d'aprenentatge autom\u00e0tic (Machine Learning), testant-ne l'aplicabilitat per a la resoluci\u00f3 de problemes.</p> <ol> <li>S'han identificat els principis dels sistemes d'aprenentatge autom\u00e0tic.</li> <li>S'han determinat tipus i usos dels sistemes d'aprenentatge autom\u00e0tic.</li> <li>S'han determinat t\u00e8cniques i eines de sistemes d'aprenentatge autom\u00e0tic.</li> <li>S'han trobat difer\u00e8ncies entre els tipus de sistemes d'aprenentatge autom\u00e0tic.</li> <li>S'han associat t\u00e8cniques i eines a cada tipus de sistema d'aprenentatge autom\u00e0tic.</li> </ol> </li> <li> <p>Aplica algoritmes d'aprenentatge supervisat, optimitzant el resultat del model i minimitzant els riscos associats.</p> <ol> <li>S'han proporcionat les dades etiquetades al model.</li> <li>S'han seleccionat les dades d'entrada, ja siguin per a la fase d'entrenament, fase de validaci\u00f3 o fase de test, entre altres.</li> <li>S'han utilitzat les dades en la fase d'entrenament per a la construcci\u00f3 del model aplicant les caracter\u00edstiques rellevants obtingudes.</li> <li>S'ha avaluat el model amb les dades obtingudes en la fase de validaci\u00f3.</li> <li>S'han ajustat les dades d'aprenentatge supervisat en la fase d'ajust per millorar el rendiment de les diferents caracter\u00edstiques o par\u00e0metres.</li> <li>S'ha implementat el model per fer prediccions sobre noves dades.</li> <li>S'han detectat i minimitzat els riscos associats al model.</li> <li>S'ha optimitzat el model d'aprenentatge supervisat validant dades de prova.</li> </ol> </li> <li> <p>Aplica t\u00e8cniques d'aprenentatge no supervisat relacionant-les amb els tipus de problemes que tracten de resoldre.</p> <ol> <li>S'han caracteritzat els tipus de problemes que l'aprenentatge no supervisat tracta de resoldre.</li> <li>S'han caracteritzat les t\u00e8cniques d'aprenentatge no supervisat utilitzades per a la resoluci\u00f3 d'aquests tipus de problemes.</li> <li>S'han aplicat algoritmes utilitzats en l'aprenentatge no supervisat.</li> <li>S'ha optimitzat el model d'aprenentatge no supervisat validant dades de prova.</li> </ol> </li> <li> <p>Aplica models computacionals de xarxes neuronals comparant-los amb altres m\u00e8todes d'intel\u00b7lig\u00e8ncia artificial.</p> <ol> <li>S'han avaluat els models neuronals per triar el m\u00e9s adequat per a cada classe de problema.</li> <li>S'han aplicat t\u00e8cniques d'aprenentatge profund (deep learning) per entrenar xarxes neuronals.</li> <li>S'han comparat les xarxes neuronals artificials amb altres m\u00e8todes d'intel\u00b7lig\u00e8ncia artificial.</li> <li>S'ha reconegut una xarxa neuronal entrenada a partir d'un conjunt de dades.</li> </ol> </li> <li> <p>Valora la qualitat dels resultats obtinguts en la pr\u00e0ctica amb sistemes d'aprenentatge autom\u00e0tic integrant els principis fonamentals de la computaci\u00f3.</p> <ol> <li>S'ha valorat la conveni\u00e8ncia dels algoritmes proposats per resoldre els problemes plantejats.</li> <li>S'ha avaluat l'aplicaci\u00f3 pr\u00e0ctica dels principis i t\u00e8cniques b\u00e0siques dels sistemes intel\u00b7ligents.</li> <li>S'han integrat els principis fonamentals de la computaci\u00f3 en la pr\u00e0ctica per seleccionar, valorar i crear nous desenvolupaments tecnol\u00f2gics.</li> <li>S'han desenvolupat sistemes i aplicacions inform\u00e0tiques que utilitzen t\u00e8cniques dels sistemes intel\u00b7ligents.</li> <li>S'han desenvolupat t\u00e8cniques d'aprenentatge computacional dedicades a l'extracci\u00f3 autom\u00e0tica d'informaci\u00f3 a partir de grans volums de dades.</li> </ol> </li> </ol>"},{"location":"programacio/programacio/#82-procediments-i-instruments-de-qualificacio","title":"8.2. Procediments i instruments de qualificaci\u00f3","text":"CIPFP Mislata Figura 1: Diagrama de convocat\u00f2ries"},{"location":"programacio/programacio/#821-avaluacio-continua","title":"8.2.1. Avaluaci\u00f3 cont\u00ednua","text":"<p>L\u2019avaluaci\u00f3 es realitzar\u00e0 amb els seg\u00fcents instruments d'avaluaci\u00f3:</p> <ul> <li>Ex\u00e0mens: Ex\u00e0mens de car\u00e0cter pr\u00e0ctic sobre      els continguts de cada avaluaci\u00f3.</li> <li>Pr\u00e0ctiques: Treball te\u00f2ric o pr\u00e0ctic, on s\u2019avalua el      treball diari i els continguts que s\u2019estan treballant.</li> </ul> <p>Tots els instruments d'avaluaci\u00f3 s'han d'entregar a temps i ha de complir amb els requisits d'entrega. Si aquest no s'entrega en temps i forma, es considerar\u00e0 com a no presentat.</p> <p>La manca d'autenticitat en l'autoria o d'originalitat de les proves d'avaluaci\u00f3; la c\u00f2pia o el plagi; l'intent fraudulent d'obtenir un resultat acad\u00e8mic millor; la col\u00b7laboraci\u00f3, l'encobriment o l'afavoriment de la c\u00f2pia, o la utilitzaci\u00f3 de material, aplicacions o dispositius no autoritzats durant l'avaluaci\u00f3, entre d'altres, s\u00f3n conductes irregulars que poden tenir conseq\u00fc\u00e8ncies acad\u00e8miques i disciplin\u00e0ries greus. </p> <p>D'una banda, si es detecta alguna d'aquestes conductes irregulars, pot comportar el suspens en les activitats avaluables o en la qualificaci\u00f3 final de l'assignatura. </p> <p>D'altra banda, i d'acord amb la normativa acad\u00e8mica, les conductes irregulars en l'avaluaci\u00f3, a m\u00e9s de comportar el suspens de l'assignatura, poden donar lloc a la incoaci\u00f3 d'un procediment disciplinari i a l'aplicaci\u00f3, si escau, de la sanci\u00f3 corresponent.</p>"},{"location":"programacio/programacio/#qualificacio","title":"Qualificaci\u00f3","text":"<p>La nota de cada avaluaci\u00f3 (\\(A_i\\)) es calcular\u00e0 de la seg\u00fcent manera:</p> <ul> <li>Nota de l'examen (\\(E_i\\)): Nota de l'examen realitzat     en l'avaluaci\u00f3. Comptara un 40%.</li> <li>Nota de pr\u00e0ctiques (\\(P_i\\)): Nota mitjana de les      pr\u00e0ctiques realitzades en l\u2019avaluaci\u00f3.     Comptar\u00e0 un 60%.</li> </ul> \\[ A_i = 0.4 \\times E_i + 0.6 \\times P_i \\] <p>Perqu\u00e8 un alumne supere una avaluaci\u00f3, la qualificaci\u00f3  d\u2019aquesta ha de ser igual o superior a 5.</p> \\[ A_i \\ge 5 \\] <p>La qualificaci\u00f3 del m\u00f2dul (\\(M\\)) es calcular\u00e0 mitjan\u00e7ant la mitjana  de la nota de totes les avaluacions. En cas que alguna avaluaci\u00f3  no estiga superada, la qualificaci\u00f3 del m\u00f2dul ser\u00e0 com a m\u00e0xim un 4.</p> \\[ M = \\frac{A_1 + A_2}{2}\\\\\\ \\] <p>Per norma general les notes s'arredoniran amb la f\u00f3rmula general: &gt;.5. No obstant aix\u00f2, en l'interval \\([4, 5)\\) la nota s'arredonir\u00e0 a 5 sols a partir de 4.75.</p>"},{"location":"programacio/programacio/#822-convocatoria-ordinaria","title":"8.2.2. Convocat\u00f2ria ordin\u00e0ria","text":"<p>Abans de finalitzar el curs, els alumnes amb alguna avaluaci\u00f3 suspesa tenen el dret a presentar-se a la examen de convocat\u00f2ria ordin\u00e0ria. Aquesta examen t\u00e9 com a objectiu superar cada avaluaci\u00f3 suspesa per separat.</p> <p>Tamb\u00e9 es permet que estudiants que hagen aprovat un trimestre, es presenten a per millorar la seua nota. En aquest cas, la nota de la convocat\u00f2ria ordin\u00e0ria ser\u00e0 la que es t\u00e9 en compte (on es pot donar el cas que baixe la nota o no s'aprove). Es donar\u00e0 l'opci\u00f3 de no entregar la examen si es creu que aquesta empitjorar\u00e0 el resultat anterior.</p> <p>En la convocat\u00f2ria, es mantindran les notes de les avaluacions aprovades en l'avaluaci\u00f3 cont\u00ednua. Per a superar la convocat\u00f2ria ordin\u00e0ria:</p> <ul> <li>La mitjana total de les notes de les avaluacions ha de ser superior o igual a 5.</li> <li>La nota de cada avaluaci\u00f3 ha de ser superior o igual a 5.</li> </ul>"},{"location":"programacio/programacio/#823-convocatoria-extraordinaria","title":"8.2.3 Convocat\u00f2ria extraordin\u00e0ria","text":"<p>L\u2019alumnat que no supere el m\u00f2dul en la convocat\u00f2ria ordin\u00e0ria,  t\u00e9 dret a la convocat\u00f2ria extraordin\u00e0ria, que tractar\u00e0 els continguts de tot el curs, independentment de les avaluacions aprovades anteriorment.</p>"},{"location":"programacio/programacio/#824-avaluacio-de-la-practica-docent","title":"8.2.4 Avaluaci\u00f3 de la pr\u00e0ctica docent","text":"<p>Al final del curs es realitzar\u00e0 un q\u00fcestionari per avaluar la pr\u00e0ctica docent i la qualitat dels materials i el proc\u00e9s d'aprenentatge.</p>"},{"location":"programacio/programacio/#83-criteris-davaluacio-minims-per-superar-el-modul","title":"8.3 Criteris d\u2019avaluaci\u00f3 m\u00ednims per superar el m\u00f2dul","text":"<p>Per poder superar el m\u00f2dul, l\u2019alumnat haur\u00e0 de:</p> <ul> <li>Superar els ex\u00e0mens que es realitzaran en cada de les avaluacions.    Per poder superar cada avaluaci\u00f3, la mitjana dels ex\u00e0mens   haur\u00e0 de ser major o igual que 5.</li> <li>Superar les pr\u00e0ctiques realitzades en cada avaluaci\u00f3.    Per poder superar cada avaluaci\u00f3, la mitjana de les pr\u00e0ctiques   haur\u00e0 de ser major o igual que 5.</li> <li>Tindre un comportament adequat a l\u2019aula i complir les    normes de conviv\u00e8ncia.</li> <li>Superar cada avaluaci\u00f3 per separat.</li> </ul>"},{"location":"programacio/programacio/#84-quadre-resum","title":"8.4. Quadre resum","text":"Instruments de qualificaci\u00f3 % Consideracions 1a Avaluaci\u00f3 Ex\u00e0mens 40% <p>En cada avaluaci\u00f3:</p> <ul> <li>La nota mitjana dels ex\u00e0mens ha de ser igual o superior a 5.</li> <li>La nota mitjana de les pr\u00e0ctiques ha de ser igual o superior a 5.</li> <li>En el butllet\u00ed s'arredonir\u00e0 la nota, per\u00f2 s'utilitzaran els decimals pel c\u00f2mput de la nota del m\u00f2dul.</li> </ul> Pr\u00e0ctiques 60% 2a Avaluaci\u00f3 Ex\u00e0mens 40% Pr\u00e0ctiques 60% Ordin\u00e0ria        Examen de la mat\u00e8ria de la 1a avaluaci\u00f3.      50% <p>En cas d'haver aprovat alguna avaluaci\u00f3, es pot guardar aquesta qualificaci\u00f3 en compte de realitzar l'examen corresponent.</p> <ul> <li>La nota de cada examen ha de ser igual o superior a 5.</li> </ul>        Examen de la mat\u00e8ria de la 2a avaluaci\u00f3.      50% Extraordin\u00e0ria        Examen de tota la mat\u00e8ria      100 Examen de tota la mat\u00e8ria del m\u00f2dul. La nota obtinguda ser\u00e0 la nota del m\u00f2dul."},{"location":"programacio/programacio/#9-materials-i-recursos-didactics","title":"9. Materials i recursos did\u00e0ctics","text":"<ul> <li>Pantalla digital</li> <li>Pissarra</li> <li>Plataforma educativa: Aules: Publicaci\u00f3 de material, continguts, activitats, correccions i r\u00fabriques.</li> <li>Ordinadors amb Windows.</li> <li>Acc\u00e9s a internet.</li> <li>Correu corporatiu.</li> <li>Entorns de desenvolupament integrats: PyCharm, Google Colab.</li> <li>Eines de control de versions: Git</li> <li>Llocs d'allotjament de repositoris Git: GitHub</li> </ul>"},{"location":"programacio/programacio/#10-activitats-complementaries-i-extraescolars","title":"10. Activitats complement\u00e0ries i extraescolars","text":"<p>No s'ha contemplat cap activitat complementaria espec\u00edfica per aquest m\u00f2dul professional.</p>"},{"location":"programacio/programacio/#11-temes-transversals","title":"11. Temes transversals","text":"<p>Els temes transversals a tractar al m\u00f2dul professional al llarg del curs estan relacionats amb el desenvolupament de les capacitats de relacions socials i comunicatives dels alumnes, enteses com un complement necessari i important a incloure en qualsevol titulaci\u00f3 de tipus t\u00e8cnica.</p> <p>Els temes transversals concrets a tractar s\u00f3n els seg\u00fcents:</p> <ul> <li>Desenvolupar habilitats de relaci\u00f3 social i interpersonal.</li> <li>Potenciar les actituds comunicatives, de negociaci\u00f3 i de treball en grup.</li> <li>Fomentar la motivaci\u00f3.</li> <li>Saber afrontar conflictes provocats per les limitacions     tecnol\u00f2giques sempre presents en un entorn tecnol\u00f2gic tan din\u00e0mic i en continua evoluci\u00f3     com \u00e9s el sector inform\u00e0tic.</li> </ul>"},{"location":"programacio/programacio/#12-mesures-de-resposta-educativa-per-a-la-inclusio","title":"12. Mesures de resposta educativa per a la inclusi\u00f3","text":"<p>Es tindr\u00e0 en compte a l'alumnat que necessite m\u00e9s atenci\u00f3, de manera que es garantir\u00e0 l'accessibilitat a tots els mitjans comuns.</p> <p>Accions que es portaran a terme:</p> <ul> <li>Elaboraci\u00f3 d'exercicis complementaris per aquells estudiants que ho precisen,     tant de suport com d'aprofundiment en la mat\u00e8ria.</li> <li>Estimulaci\u00f3 del treball en grup de manera remota. La composici\u00f3 dels grups     ser\u00e0 supervisada pel docent per aconseguir grups amb nivells heterogenis.</li> <li>Facilitar la accessibilitat dels materials i recursos did\u00e0ctics.</li> <li>Flexibilitzaci\u00f3 en les temporitzacions de les activitats     (realitzaci\u00f3 d'ex\u00e0mens, entrega de pr\u00e0ctiques, treball personal, etc.).</li> </ul>"}]}